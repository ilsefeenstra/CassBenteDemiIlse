{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f23610",
   "metadata": {},
   "source": [
    "# Milestone 1: Basic model\n",
    "In this chapter we will make a basic model that is able to predict the Pawpularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vRjBTUzjlmKA",
   "metadata": {
    "id": "vRjBTUzjlmKA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import chdir, listdir\n",
    "import zipfile\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFZWcvRBvYv_",
   "metadata": {
    "id": "LFZWcvRBvYv_"
   },
   "source": [
    "# Import zip with the data\n",
    "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fANqjfPxoHI7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fANqjfPxoHI7",
    "outputId": "a5d6d89e-1b1f-4433-815e-2bc152d8ab67"
   },
   "outputs": [],
   "source": [
    "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
    "\n",
    "# Get zip file from Github URL\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
    "    -O \"/tmp/pawpularity_data.zip\"\n",
    "\n",
    "# Opens the zip file in read mode and extract files into /tmp folder\n",
    "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae29a8e",
   "metadata": {
    "id": "0ae29a8e"
   },
   "source": [
    "# Import tabular data\n",
    "\n",
    "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae10a3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8ae10a3a",
    "outputId": "7fb808da-0920-41be-d2fd-6297bf57bd00"
   },
   "outputs": [],
   "source": [
    "# Import the CSV tables\n",
    "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
    "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
    "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "csv_train_data.head()\n",
    "\n",
    "# Drop rows with missing values (if NaN values are in dataframe)\n",
    "# No missing values present, so no samples dropped\n",
    "csv_train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRYM1P29o8k1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "SRYM1P29o8k1",
    "outputId": "93b321ce-9cbb-41b3-815f-449d1b3219fb"
   },
   "outputs": [],
   "source": [
    "# Create a plot that shows the distribution of the output of the training samples\n",
    "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
    "plt.title(\"Data distribution of the tabular data\")\n",
    "plt.xlabel(\"Pawpularity score\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccde6f",
   "metadata": {
    "id": "5eccde6f"
   },
   "source": [
    "# Import image data\n",
    "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8970b3",
   "metadata": {
    "id": "6a8970b3"
   },
   "outputs": [],
   "source": [
    "def reshape_images(path, n):\n",
    "    \"\"\"\n",
    "    This function returns a list of images, which are reshaped to 64 x 64 \n",
    "    and a list with the names of the images.\n",
    "    \"\"\"\n",
    "    # Set the current path\n",
    "    chdir(path)\n",
    "    \n",
    "    # Preset the lists\n",
    "    images = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Go over all the files in the path\n",
    "    for i in listdir():\n",
    "        \n",
    "        # Get the name of the image, without .jpg\n",
    "        image_names.append(i[:-4])\n",
    "        \n",
    "        # Get the image and reshape to n x n\n",
    "        file = cv2.imread(i)\n",
    "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Rescale the pixels and store in the list\n",
    "        images.append(file/255)\n",
    "        \n",
    "    return images, image_names\n",
    "\n",
    "# Reshape train and test images\n",
    "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
    "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcac655",
   "metadata": {
    "id": "2bcac655"
   },
   "outputs": [],
   "source": [
    "# Make numpy arrays of images\n",
    "train_imgs_array = np.array(train_imgs)\n",
    "test_imgs_array = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b818ae9",
   "metadata": {
    "id": "8b818ae9"
   },
   "source": [
    "# Combine tabular data with images\n",
    "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85185f99",
   "metadata": {
    "id": "85185f99"
   },
   "outputs": [],
   "source": [
    "def sort_dataframe(data, images, names):\n",
    "    \"\"\"\n",
    "    This function sorts the dataframe of the csv data according to the image names.\n",
    "    \"\"\"\n",
    "    data_sorted = pd.DataFrame()\n",
    "\n",
    "    # Iterate over images and get index of each image\n",
    "    for img, name in zip(images, names):\n",
    "        location = data[data['Id'] == name].index[0]\n",
    "\n",
    "        # Sort dataframe according to index of images\n",
    "        data_sorted = data_sorted.append([data.loc[location]])\n",
    "        \n",
    "    return data_sorted\n",
    "\n",
    "# Sort training and testing data\n",
    "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
    "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
    "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9206b4b",
   "metadata": {
    "id": "e9206b4b"
   },
   "source": [
    "# Processing tabular data\n",
    "Create seperate numpy arrays of the input and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a824c4",
   "metadata": {
    "id": "14a824c4"
   },
   "outputs": [],
   "source": [
    "# Select x-values (the 12 input features) from training data\n",
    "x_train_tabular = train_data_sorted.iloc[:,1:13].to_numpy()\n",
    "\n",
    "# Select y-values (pawpularity) from training data\n",
    "y_train = train_data_sorted.iloc[:,13].to_numpy()\n",
    "\n",
    "# Select x-values (12 input features) from testing data\n",
    "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
    "\n",
    "# Select y-values (pawpularity) from testing data\n",
    "y_test = sample_submission_sorted.iloc[:,1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNE8NWL7xgmp",
   "metadata": {
    "id": "RNE8NWL7xgmp"
   },
   "source": [
    "# Create seperate neural networks\n",
    "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1cb99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccf1cb99",
    "outputId": "8e80494b-e6d6-4960-cb12-567e33d5e293"
   },
   "outputs": [],
   "source": [
    "def build_neural_net(input_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number of \n",
    "    hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Create a hidden layer\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create neural network for tabular data and get summary of model \n",
    "# with 12 inputs and 100 hidden nodes\n",
    "hidden_nodes = 20\n",
    "tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
    "tabular_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18b2f9",
   "metadata": {
    "id": "bd18b2f9"
   },
   "outputs": [],
   "source": [
    "def build_convol_net(image_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number \n",
    "    of hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Create a convolutional layer \n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
    "    \n",
    "    # Create a maxpool layer\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    \n",
    "    # Create a convolutional layer \n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "    # Create a maxpool layer\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    \n",
    "    # Create a flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Create a dense layer with relu activations\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc6959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7adc6959",
    "outputId": "a42fd035-764f-4724-ab59-427b3cc1a367"
   },
   "outputs": [],
   "source": [
    "# Create neural network for image data and get summary of model\n",
    "image_size = (64, 64, 3)\n",
    "image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
    "image_NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vtZpIRuAue4B",
   "metadata": {
    "id": "vtZpIRuAue4B"
   },
   "source": [
    "## Concatenate tabular and image data models\n",
    "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441c455",
   "metadata": {
    "id": "1441c455"
   },
   "outputs": [],
   "source": [
    "def concatenate_models(model1, model2, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Concatenate two neural network models, model1 and model2, and create\n",
    "    a concatenated model with dense layers with some hidden nodes.\n",
    "    \"\"\"\n",
    "    # Input for concatenated model is retrieved by concatenating the output\n",
    "    # of both models\n",
    "    concat_input = layers.concatenate([model1.output, model2.output])\n",
    "\n",
    "    # Create hidden layers of the concatenated model\n",
    "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\")(concat_input)\n",
    "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\")(hidden_layer_1)\n",
    "    output_layer = layers.Dense(1, activation=\"linear\")(hidden_layer_2)\n",
    "\n",
    "    # Create concatenated model with inputs of both models and output of the\n",
    "    # concatenated model\n",
    "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
    "\n",
    "    return concat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92ca47",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Train the concatenated model and plot the MSE of the training and validation data for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DZ58i65PvawJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DZ58i65PvawJ",
    "outputId": "7fa1956d-2642-4734-eada-fde2f683063d"
   },
   "outputs": [],
   "source": [
    "# Part of code from: https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "# Concatenate tabular and image neural networks\n",
    "concat_model = concatenate_models(tabular_NN, image_NN, hidden_nodes=20)\n",
    "\n",
    "# Compile model and use mean squared error as loss\n",
    "concat_model.compile(loss=MeanSquaredError())\n",
    "\n",
    "# Train the model by fitting both tabular and image data at the same time\n",
    "history = concat_model.fit(x=[x_train_tabular, train_imgs_array], y=y_train, batch_size=20, epochs=20, validation_split=.2)\n",
    "\n",
    "# Store loss during training in DataFrame\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\n",
    "def plot_loss(history):\n",
    "    \"\"\"\n",
    "    Plot loss during epochs of training a neural network.\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "# Plot loss during training of concatenated model\n",
    "plot_loss(history)\n",
    "\n",
    "# See how the model scored\n",
    "loss = concat_model.evaluate(x=[x_test_tabular, test_imgs_array], y=y_test)\n",
    "\n",
    "# Print to 3 decimals\n",
    "print(f'Test loss: {loss:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9-K3Mgs8weVG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9-K3Mgs8weVG",
    "outputId": "1e01af49-73de-4561-9d25-16a588385e15"
   },
   "outputs": [],
   "source": [
    "# Create overview of layers in model\n",
    "tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Milestone_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
