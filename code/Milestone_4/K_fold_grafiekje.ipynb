{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3915ca73",
      "metadata": {
        "id": "3915ca73"
      },
      "source": [
        "# Linear output\n",
        "In this chapter we will limit the linear output between 0 and 100, so the model will be more realistic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "vRjBTUzjlmKA",
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras import backend as K\n",
        "from keras import activations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFZWcvRBvYv_",
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fANqjfPxoHI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "d10cd7ba-6ecf-47e2-8b3b-be34097adab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 09:21:40--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-25 09:21:40--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [                 <=>] 993.21M  23.0MB/s    in 47s     \n",
            "\n",
            "2022-01-25 09:22:27 (21.3 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1041460659]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8ae10a3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8ae10a3a",
        "outputId": "4d4478d5-855e-49f4-8253-a0a63efd71f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-92429e63-0ab2-4160-9c5a-5b47ddf71748\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92429e63-0ab2-4160-9c5a-5b47ddf71748')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92429e63-0ab2-4160-9c5a-5b47ddf71748 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92429e63-0ab2-4160-9c5a-5b47ddf71748');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "SRYM1P29o8k1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "c18531c5-0e77-4822-f0e7-e864b70cbcfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99"
      },
      "outputs": [],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)\n",
        "\n",
        "# train_data_sorted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select x-values (the 12 input features) and y-values from training data\n",
        "x_tabular = train_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y = train_data_sorted.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
        "\n",
        "# Create numpy array of image data \n",
        "x_images = np.array(train_imgs)\n",
        "test_imgs_array = np.array(test_imgs)"
      ],
      "metadata": {
        "id": "Agl1YxFwNcKo"
      },
      "id": "Agl1YxFwNcKo",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "RNE8NWL7xgmp",
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99"
      },
      "outputs": [],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create neural network for tabular data and get summary of model \n",
        "# with 12 inputs and 100 hidden nodes\n",
        "tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "# tabular_NN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7adc6959",
      "metadata": {
        "id": "7adc6959"
      },
      "outputs": [],
      "source": [
        "# Create neural network for image data and get summary of model\n",
        "image_size = (64, 64, 3)\n",
        "image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "# image_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtZpIRuAue4B",
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ZKkweNdcNXLl",
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "outputs": [],
      "source": [
        "def linear_limit(x):\n",
        "    \"\"\"\n",
        "    Create a linear activation function that clips the output at 0 and 100.\n",
        "    \"\"\"\n",
        "    activation_x = activations.linear(x)\n",
        "    activation_x_new = K.clip(activation_x, 0, 100)\n",
        "\n",
        "    return activation_x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "DZ58i65PvawJ",
      "metadata": {
        "id": "DZ58i65PvawJ"
      },
      "outputs": [],
      "source": [
        "# Part of code from: https://www.tensorflow.org/tutorials/keras/regression\n",
        "\n",
        "def plot_loss(history):\n",
        "    \"\"\"\n",
        "    Plot loss during epochs of training a neural network.\n",
        "    \"\"\"\n",
        "    \n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    for i, metric in enumerate(['loss', 'root_mean_squared_error']):\n",
        "        axs[i].plot(history.history[metric])\n",
        "        axs[i].plot(history.history['val_'+metric])\n",
        "        axs[i].legend(['training', 'validation'], loc='best')\n",
        "\n",
        "        axs[i].set_title('Model '+metric)\n",
        "        axs[i].set_ylabel(metric)\n",
        "        axs[i].set_xlabel('epoch')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "    \"\"\"\n",
        "    This function trains and evaluated a model. It first compiles the model with \n",
        "    the loss and metrics. It then makes a train and validation generator for the \n",
        "    image data, based on the preprocess and augment input. \n",
        "    It then trains the model on both the image and tabular data for epochs times. \n",
        "    The values of the loss and metric are plotted and printed.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Preprocess the image data\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(image_x)\n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(image_x)\n",
        "\n",
        "    # Train the model by fitting both tabular and image data at the same time\n",
        "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs = epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "    # Plot the loss and metric\n",
        "    # plot_loss(history)\n",
        "\n",
        "\n",
        "\n",
        "    # print(f\"Validation Accuracy: {model.evaluate(val_gen.flow([x_val_imgs, x_val_tabular], val_y))[1]}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7eJp3actWxsB",
      "metadata": {
        "id": "7eJp3actWxsB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "c42f5255-be58-4fde-f273-4e1b45b636c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1e891fdffb49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_train_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_val_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'featurewise_center'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'featurewise_std_normalization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;31m# display(loss_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1e891fdffb49>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(num_folds, x_tabular, y, x_imgs, epochs, preprocess, augment)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx_tabular_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tabular\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx_imgs_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0my_val_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
        "    \"\"\"\n",
        "    Train and evaluate the data for num-folds times, and return the average \n",
        "    training and validation loss. First the data is split in num-folds batches\n",
        "    and then the model is trained on the data, where a different batch is the \n",
        "    validation data each time.\n",
        "    \"\"\"\n",
        "    losses = {}\n",
        "\n",
        "    # Create kfold object to later split the data\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "    x_indices = np.array(range(len(x_tabular)))\n",
        "    y_indices = np.array(range(len(y)))\n",
        "\n",
        "    # Preset arrays to add the loss for training and validation\n",
        "    train_loss1 = np.array([0.0, 0.0])\n",
        "    val_loss1 = np.array([0.0, 0.0])\n",
        "\n",
        "    # Train and evaluate the model for num-fold times on a different training \n",
        "    # and validation set each time\n",
        "    count = 0 \n",
        "\n",
        "    train_loss = np.array(np.zeros(epochs))\n",
        "    train_acc = np.array(np.zeros(epochs))\n",
        "    val_loss = np.array(np.zeros(epochs))\n",
        "    val_acc = np.array(np.zeros(epochs))\n",
        "    \n",
        "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
        "        \n",
        "        # Make Neural Networks before concatenation\n",
        "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "        image_size = (64, 64, 3)\n",
        "        image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "\n",
        "        # Create subset training and validation data\n",
        "        x_tabular_train = x_tabular[id_train]\n",
        "        x_imgs_train = x_imgs[id_train]\n",
        "        y_train = y[id_train]\n",
        "        \n",
        "        x_tabular_val = x_tabular[id_val]\n",
        "        x_imgs_val = x_imgs[id_val]\n",
        "        y_val_2 = y[id_val]\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
        "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
        "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs,  preprocess={}, augment={})\n",
        "\n",
        "        # Add the evaluation loss each time\n",
        "        train_loss1 += concat_model.evaluate([x_imgs_train, x_tabular_train], y_train)\n",
        "        val_loss1 += concat_model.evaluate([x_imgs_val, x_tabular_val], y_val_2)\n",
        "        \n",
        "        # print(history.history['loss'])\n",
        "\n",
        "        # Add all the losses and metrics\n",
        "        train_loss += history.history['loss']\n",
        "        train_acc += history.history['root_mean_squared_error']\n",
        "        val_loss += history.history['val_loss']\n",
        "        val_acc += history.history['val_root_mean_squared_error']\n",
        "\n",
        "        losses[count] = history.history\n",
        "        count += 1 \n",
        "\n",
        "    # Calculate average loss and metric\n",
        "    avg_train_loss = train_loss / num_folds\n",
        "    avg_val_loss = val_loss / num_folds\n",
        "    avg_train_acc = train_acc / num_folds\n",
        "    avg_val_acc = val_acc / num_folds\n",
        "\n",
        "    print(train_loss, avg_train_loss)\n",
        "\n",
        "    # Calculate average evaluation\n",
        "    avg_train_loss1 = train_loss / num_folds\n",
        "    avg_val_loss1 = val_loss / num_folds\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Plot MSE\n",
        "    axs[0].plot(avg_train_loss)\n",
        "    axs[0].plot(avg_val_loss)\n",
        "    axs[0].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[0].set_title('Model MSE')\n",
        "    axs[0].set_ylabel('MSE')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "\n",
        "    # Plot RMSE\n",
        "    axs[1].plot(avg_train_acc)\n",
        "    axs[1].plot(avg_val_acc)\n",
        "    axs[1].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[1].set_title('Model RMSE')\n",
        "    axs[1].set_ylabel('RMSE')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return avg_train_loss1, avg_val_loss1, losses\n",
        "\n",
        "avg_train_loss, avg_val_loss, loss_df = k_fold(5, x_tabular, y, x_images, epochs=60, preprocess={'featurewise_center': True, 'featurewise_std_normalization': True})\n",
        "# display(loss_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'The average training loss is {avg_train_loss[0]} and the average training RMSE is {avg_train_loss[1]}')\n",
        "# print(f'The average validation loss is {avg_val_loss[0]} and the average validation RMSE is {avg_val_loss[1]}')\n",
        "\n",
        "# See how the model scored on the testing data\n",
        "# loss = concat_model.evaluate([test_imgs_array, x_test_tabular], y_test)\n",
        "# print(f'Test loss: {loss}')"
      ],
      "metadata": {
        "id": "HlZsEhYcKBjb"
      },
      "id": "HlZsEhYcKBjb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9-K3Mgs8weVG",
      "metadata": {
        "id": "9-K3Mgs8weVG"
      },
      "outputs": [],
      "source": [
        "# Create overview of layers in model\n",
        "# tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = np.array(np.zeros(2))\n",
        "train_val = np.array(np.zeros(2))\n",
        "test_loss = np.array(np.zeros(2))\n",
        "test_val = np.array(np.zeros(2))\n",
        "\n",
        "for epoch in loss_df.items():\n",
        "  train_loss += epoch[1]['loss']\n",
        "  train_val += epoch[1]['root_mean_squared_error']\n",
        "  test_loss += epoch[1]['val_loss']\n",
        "  test_val += epoch[1]['val_root_mean_squared_error']\n",
        "\n",
        "display(test_val)"
      ],
      "metadata": {
        "id": "DCDlt7aXKX16"
      },
      "id": "DCDlt7aXKX16",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "K_fold_grafiekje.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}