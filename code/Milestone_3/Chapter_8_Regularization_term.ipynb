{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError"
      ],
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "id": "vRjBTUzjlmKA",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ],
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "id": "LFZWcvRBvYv_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "0ba8c1f0-b73d-42c7-b3b1-feb8b605276d"
      },
      "id": "fANqjfPxoHI7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-20 08:45:56--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-20 08:45:56--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [  <=>               ] 987.18M  14.7MB/s    in 49s     \n",
            "\n",
            "2022-01-20 08:46:46 (20.0 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1035137866]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ae10a3a",
      "metadata": {
        "id": "8ae10a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "b2f70805-9cf9-45d3-bd51-77d25b6db138"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46ad1e9e-1b03-41d8-a2c7-67bb3ddf0d0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46ad1e9e-1b03-41d8-a2c7-67bb3ddf0d0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46ad1e9e-1b03-41d8-a2c7-67bb3ddf0d0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46ad1e9e-1b03-41d8-a2c7-67bb3ddf0d0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "49065f55-7f15-455b-ef69-9f6e6c532e4c"
      },
      "id": "SRYM1P29o8k1",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip train image data and names\n",
        "combined = list(zip(train_imgs, train_names))\n",
        "\n",
        "# Make sure shuffle is the same each time\n",
        "random.seed(4)\n",
        "\n",
        "# Shuffle the image data\n",
        "random.shuffle(combined)\n",
        "\n",
        "# Unzip the train images and names\n",
        "train_imgs, train_names = zip(*combined)"
      ],
      "metadata": {
        "id": "ETCcGce5_P41"
      },
      "id": "ETCcGce5_P41",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "dce5a083-3822-47b1-b795-7b91b495c999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2a0e3ab1-aa6f-4077-836a-cc14be636df9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38f19ceba149ba0bbc1602211e24c14b</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a1ece3037f353dced1f1b3257b1fb891</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a688976b47df3243167b4ffa9a0128fc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f5cc76e712921ed08038d6801bb1808a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>282a949413dd82a756c96dfdfe9fbc62</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a0e3ab1-aa6f-4077-836a-cc14be636df9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a0e3ab1-aa6f-4077-836a-cc14be636df9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a0e3ab1-aa6f-4077-836a-cc14be636df9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0  38f19ceba149ba0bbc1602211e24c14b              0  ...     0           87\n",
              "1  a1ece3037f353dced1f1b3257b1fb891              0  ...     0           50\n",
              "2  a688976b47df3243167b4ffa9a0128fc              0  ...     0           45\n",
              "3  f5cc76e712921ed08038d6801bb1808a              0  ...     0           30\n",
              "4  282a949413dd82a756c96dfdfe9fbc62              0  ...     0           98\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)\n",
        "\n",
        "train_data_sorted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "First we split the data in a train and validation set, where 20% of the data is put in the validation set. Then the image data is converted to numpy arrays, so they can be used in the neural networks. The tabular data is split in the x and y values and also converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into training and validation set\n",
        "split_threshold = int(0.2 * len(train_names))\n",
        "\n",
        "val_tabular = train_data_sorted[:split_threshold]\n",
        "train_tabular = train_data_sorted[split_threshold:]\n",
        "\n",
        "val_images = train_imgs[:split_threshold]\n",
        "train_images = train_imgs[split_threshold:]"
      ],
      "metadata": {
        "id": "FFrWouIp2Iha"
      },
      "id": "FFrWouIp2Iha",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2bcac655",
      "metadata": {
        "id": "2bcac655"
      },
      "outputs": [],
      "source": [
        "# Make numpy arrays of images for further analysis\n",
        "train_imgs_array = np.array(train_images)\n",
        "val_imgs_array = np.array(val_images)\n",
        "test_imgs_array = np.array(test_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "14a824c4",
      "metadata": {
        "id": "14a824c4"
      },
      "outputs": [],
      "source": [
        "# Select x (the 12 input features) and y (pawpularity) values from training data\n",
        "x_train_tabular = train_tabular.iloc[:,1:13].to_numpy()\n",
        "y_train = train_tabular.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from validation data\n",
        "x_val_tabular = val_tabular.iloc[:,1:13].to_numpy()\n",
        "y_val = val_tabular.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ],
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "id": "RNE8NWL7xgmp"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95214fb1-378a-43c4-c9a0-86888627a35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                260       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,100\n",
            "Trainable params: 1,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create neural network for tabular data and get summary of model \n",
        "# with 12 inputs and 100 hidden nodes\n",
        "tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "tabular_NN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\",\n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "7adc6959",
      "metadata": {
        "id": "7adc6959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21adf96-5e92-46cf-f44e-17859f1571af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 32, 32, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 8, 8, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 20)                327700    \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 700,728\n",
            "Trainable params: 699,832\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create neural network for image data and get summary of model\n",
        "image_size = (64, 64, 3)\n",
        "image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "image_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ],
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "id": "vtZpIRuAue4B"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras import activations\n",
        "\n",
        "def linear_limit(x):\n",
        "  activation_x = activations.linear(x)\n",
        "  activation_x_new = K.clip(activation_x, 0, 100)\n",
        "  return activation_x_new"
      ],
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "id": "ZKkweNdcNXLl",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_1 = layers.Dropout(.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\",\n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_2 = layers.Dropout(.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\",\n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part of code from: https://www.tensorflow.org/tutorials/keras/regression\n",
        "\n",
        "def plot_loss(history):\n",
        "    \"\"\"\n",
        "    Plot loss during epochs of training a neural network.\n",
        "    \"\"\"\n",
        "    \n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    for i, metric in enumerate(['loss', 'root_mean_squared_error']):\n",
        "        axs[i].plot(history.history[metric])\n",
        "        axs[i].plot(history.history['val_'+metric])\n",
        "        axs[i].legend(['training', 'validation'], loc='best')\n",
        "\n",
        "        axs[i].set_title('Model '+metric)\n",
        "        axs[i].set_ylabel(metric)\n",
        "        axs[i].set_xlabel('epoch')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "  \"\"\"\n",
        "  This function trains and evaluated a model. It first compiles the model with \n",
        "  the loss and metrics. It then makes a train and validation generator for the \n",
        "  image data, based on the preprocess and augment input. \n",
        "  It then trains the model on both the image and tabular data for epochs times. \n",
        "  The values of the loss and metric are plotted and printed.\n",
        "  \"\"\"\n",
        "\n",
        "  # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "  model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "  # Preprocess the image data\n",
        "  train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "  train_gen.fit(image_x)\n",
        "\n",
        "  val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "  val_gen.fit(image_x)\n",
        "\n",
        "  # Train the model by fitting both tabular and image data at the same time\n",
        "  history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs=epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "  # Plot the loss and metric\n",
        "  plot_loss(history)\n",
        "\n",
        "  print(f\"Validation Accuracy: {model.evaluate(val_gen.flow([x_val_imgs, x_val_tabular], val_y))[1]}\")\n",
        "\n",
        "# Concatenate tabular and image neural networks\n",
        "concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
        "\n",
        "# Train model on both tabular and image data and preprocess\n",
        "train_and_evaluate(concat_model, train_imgs_array, x_train_tabular, y_train, \n",
        "                   x_val_tabular, val_imgs_array, y_val,\n",
        "                   preprocess={'featurewise_center': True, 'featurewise_std_normalization': True}, epochs=60)\n",
        "\n",
        "# See how the model scored on the testing data\n",
        "loss = concat_model.evaluate([test_imgs_array, x_test_tabular], y_test)\n",
        "print(f'Test loss: {loss}')\n"
      ],
      "metadata": {
        "id": "DZ58i65PvawJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "bf82c709-d633-4b96-e79b-130b5331d37f"
      },
      "id": "DZ58i65PvawJ",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 35ms/step - loss: 977.7213 - root_mean_squared_error: 28.0163 - val_loss: 691.4398 - val_root_mean_squared_error: 24.7720\n",
            "Epoch 2/60\n",
            "247/248 [============================>.] - ETA: 0s - loss: 735.4125 - root_mean_squared_error: 24.9384"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36m_get_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-0e12cb110630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m train_and_evaluate(concat_model, train_imgs_array, x_train_tabular, y_train, \n\u001b[1;32m     54\u001b[0m                    \u001b[0mx_val_tabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_imgs_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                    preprocess={'featurewise_center': True, 'featurewise_std_normalization': True}, epochs=60)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# See how the model scored on the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-0e12cb110630>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs, preprocess, augment)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# Train the model by fitting both tabular and image data at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_tabular\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m# Plot the loss and metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \"\"\"\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/tape.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \"\"\"\n\u001b[1;32m    114\u001b[0m   strategy, context = (\n\u001b[0;32m--> 115\u001b[0;31m       distribution_strategy_context.get_strategy_and_replica_context())\n\u001b[0m\u001b[1;32m    116\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36mget_strategy_and_replica_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_strategy_and_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m   \u001b[0mper_thread_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mper_thread_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_thread_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplica_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36m_get_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_default_replica_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create overview of layers in model\n",
        "tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
      ],
      "metadata": {
        "id": "9-K3Mgs8weVG"
      },
      "id": "9-K3Mgs8weVG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7eJp3actWxsB"
      },
      "id": "7eJp3actWxsB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "Milestone_3_outputlimit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}