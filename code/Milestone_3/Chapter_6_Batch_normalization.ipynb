{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29272a67",
   "metadata": {},
   "source": [
    "# Batch normalization\n",
    "In this chapter we will add batch normalization to the layers, so the model will learn faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vRjBTUzjlmKA",
   "metadata": {
    "id": "vRjBTUzjlmKA"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from os import chdir, listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFZWcvRBvYv_",
   "metadata": {
    "id": "LFZWcvRBvYv_"
   },
   "source": [
    "# Import zip with the data\n",
    "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fANqjfPxoHI7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fANqjfPxoHI7",
    "outputId": "44c36150-dedd-46c7-e037-4bc650b0d4f6"
   },
   "outputs": [],
   "source": [
    "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
    "\n",
    "# Get zip file from Github URL\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
    "    -O \"/tmp/pawpularity_data.zip\"\n",
    "\n",
    "# Opens the zip file in read mode and extract files into /tmp folder\n",
    "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae29a8e",
   "metadata": {
    "id": "0ae29a8e"
   },
   "source": [
    "# Import tabular data\n",
    "\n",
    "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae10a3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "8ae10a3a",
    "outputId": "9d44946b-8ea8-49f4-ee8e-852b8cb29792"
   },
   "outputs": [],
   "source": [
    "# Import the CSV tables\n",
    "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
    "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
    "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "csv_train_data.head()\n",
    "\n",
    "# Drop rows with missing values (if NaN values are in dataframe)\n",
    "# No missing values present, so no samples dropped\n",
    "csv_train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRYM1P29o8k1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "SRYM1P29o8k1",
    "outputId": "68d2f44c-182c-413f-c47d-ae7a94c1cb04"
   },
   "outputs": [],
   "source": [
    "# Create a plot that shows the distribution of the output of the training samples\n",
    "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
    "plt.title(\"Data distribution of the tabular data\")\n",
    "plt.xlabel(\"Pawpularity score\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccde6f",
   "metadata": {
    "id": "5eccde6f"
   },
   "source": [
    "# Import image data\n",
    "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8970b3",
   "metadata": {
    "id": "6a8970b3"
   },
   "outputs": [],
   "source": [
    "def reshape_images(path, n):\n",
    "    \"\"\"\n",
    "    This function returns a list of images, which are reshaped to 64 x 64 \n",
    "    and a list with the names of the images.\n",
    "    \"\"\"\n",
    "    # Set the current path\n",
    "    chdir(path)\n",
    "    \n",
    "    # Preset the lists\n",
    "    images = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Go over all the files in the path\n",
    "    for i in listdir():\n",
    "        \n",
    "        # Get the name of the image, without .jpg\n",
    "        image_names.append(i[:-4])\n",
    "        \n",
    "        # Get the image and reshape to n x n\n",
    "        file = cv2.imread(i)\n",
    "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Rescale the pixels and store in the list\n",
    "        images.append(file/255)\n",
    "        \n",
    "    return images, image_names\n",
    "\n",
    "# Reshape train and test images\n",
    "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
    "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ETCcGce5_P41",
   "metadata": {
    "id": "ETCcGce5_P41"
   },
   "outputs": [],
   "source": [
    "# Zip train image data and names\n",
    "combined = list(zip(train_imgs, train_names))\n",
    "\n",
    "# Make sure shuffle is the same each time\n",
    "random.seed(4)\n",
    "\n",
    "# Shuffle the image data\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip the train images and names\n",
    "train_imgs, train_names = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b818ae9",
   "metadata": {
    "id": "8b818ae9"
   },
   "source": [
    "# Combine tabular data with images\n",
    "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85185f99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "85185f99",
    "outputId": "0fe8feaa-bbc2-4336-e9ca-dbcf87aefd1b"
   },
   "outputs": [],
   "source": [
    "def sort_dataframe(data, images, names):\n",
    "    \"\"\"\n",
    "    This function sorts the dataframe of the csv data according to the image names.\n",
    "    \"\"\"\n",
    "    data_sorted = pd.DataFrame()\n",
    "\n",
    "    # Iterate over images and get index of each image\n",
    "    for img, name in zip(images, names):\n",
    "        location = data[data['Id'] == name].index[0]\n",
    "\n",
    "        # Sort dataframe according to index of images\n",
    "        data_sorted = data_sorted.append([data.loc[location]])\n",
    "\n",
    "        # Reset the index of the dataframe\n",
    "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
    "        \n",
    "    return data_sorted\n",
    "\n",
    "# Sort training and testing data\n",
    "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
    "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
    "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)\n",
    "\n",
    "train_data_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9206b4b",
   "metadata": {
    "id": "e9206b4b"
   },
   "source": [
    "# Processing data\n",
    "First we split the data in a train and validation set, where 20% of the data is put in the validation set. Then the image data is converted to numpy arrays, so they can be used in the neural networks. The tabular data is split in the x and y values and also converted to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FFrWouIp2Iha",
   "metadata": {
    "id": "FFrWouIp2Iha"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation set\n",
    "validation_portion = 0.2\n",
    "split_threshold = int(validation_portion * len(train_names))\n",
    "\n",
    "val_tabular = train_data_sorted[:split_threshold]\n",
    "train_tabular = train_data_sorted[split_threshold:]\n",
    "\n",
    "val_images = train_imgs[:split_threshold]\n",
    "train_images = train_imgs[split_threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcac655",
   "metadata": {
    "id": "2bcac655"
   },
   "outputs": [],
   "source": [
    "# Make numpy arrays of images for further analysis\n",
    "train_imgs_array = np.array(train_images)\n",
    "val_imgs_array = np.array(val_images)\n",
    "test_imgs_array = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a824c4",
   "metadata": {
    "id": "14a824c4"
   },
   "outputs": [],
   "source": [
    "# Select x (the 12 input features) and y (pawpularity) values from training data\n",
    "x_train_tabular = train_tabular.iloc[:,1:13].to_numpy()\n",
    "y_train = train_tabular.iloc[:,13].to_numpy()\n",
    "\n",
    "# Select x (the 12 input features) and y (pawpularity) values from validation data\n",
    "x_val_tabular = val_tabular.iloc[:,1:13].to_numpy()\n",
    "y_val = val_tabular.iloc[:,13].to_numpy()\n",
    "\n",
    "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
    "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
    "y_test = sample_submission_sorted.iloc[:,1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNE8NWL7xgmp",
   "metadata": {
    "id": "RNE8NWL7xgmp"
   },
   "source": [
    "# Create seperate neural networks\n",
    "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1cb99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccf1cb99",
    "outputId": "0b0cc32e-5df1-42d6-d201-235c9f5e614f"
   },
   "outputs": [],
   "source": [
    "def build_neural_net(input_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number of \n",
    "    hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Create hidden layer\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
    "\n",
    "    # Create hidden layer\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "\n",
    "    # Create hidden layer\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create neural network for tabular data and get summary of model \n",
    "# with 12 inputs and 100 hidden nodes\n",
    "tabular_NN = build_neural_net(input_size=12, hidden_nodes=20)\n",
    "tabular_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18b2f9",
   "metadata": {
    "id": "bd18b2f9"
   },
   "outputs": [],
   "source": [
    "def build_convol_net(image_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number \n",
    "    of hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Create a convolutional layer\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Create a convolutional layer\n",
    "    model.add(layers.Dropout(.4))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Create a convolutional layer\n",
    "    model.add(layers.Dropout(.4))\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Create a flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Create a dense layer\n",
    "    model.add(layers.Dropout(.3))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "\n",
    "    # Create a dense layer\n",
    "    model.add(layers.Dropout(.3))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc6959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7adc6959",
    "outputId": "859fd06d-c1b3-47dc-b9f3-910a90d451f3"
   },
   "outputs": [],
   "source": [
    "# Create neural network for image data and get summary of model\n",
    "image_size = (64, 64, 3)\n",
    "image_NN = build_convol_net(image_size=image_size, hidden_nodes=20)\n",
    "image_NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vtZpIRuAue4B",
   "metadata": {
    "id": "vtZpIRuAue4B"
   },
   "source": [
    "## Concatenate tabular and image data models\n",
    "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441c455",
   "metadata": {
    "id": "1441c455"
   },
   "outputs": [],
   "source": [
    "def concatenate_models(model1, model2, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Concatenate two neural network models, model1 and model2, and create\n",
    "    a concatenated model with dense layers with some hidden nodes.\n",
    "    \"\"\"\n",
    "    # Input for concatenated model is retrieved by concatenating the output\n",
    "    # of both models\n",
    "    concat_input = layers.concatenate([model1.output, model2.output])\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\")(concat_input)\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    drop_out_1 = layers.Dropout(.4)(hidden_layer_1)    \n",
    "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\")(drop_out_1)\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    drop_out_2 = layers.Dropout(.4)(hidden_layer_2)\n",
    "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\")(drop_out_2)\n",
    "\n",
    "    # Create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"linear\")(hidden_layer_3)\n",
    "\n",
    "    # Create concatenated model with inputs of both models and output of the\n",
    "    # concatenated model\n",
    "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
    "\n",
    "    return concat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ab638",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Train the concatenated model and plot the MSE and RMSE of the training and validation data for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DZ58i65PvawJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DZ58i65PvawJ",
    "outputId": "904e2c71-a8a9-4bcf-d513-807c39f9c8af"
   },
   "outputs": [],
   "source": [
    "# Part of code from: https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "def plot_loss(history):\n",
    "    \"\"\"\n",
    "    Plot loss during epochs of training a neural network.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,5))\n",
    "    \n",
    "    # Set y-limits for MSE and RMSE plots\n",
    "    ylimits = [[0, 2000], [0, 60]]\n",
    "\n",
    "    # Iterate over metrics and create plot for each\n",
    "    for i, metric in enumerate(['loss', 'root_mean_squared_error']):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].plot(history.history['val_'+metric])\n",
    "        axs[i].legend(['training', 'validation'], loc='best')\n",
    "\n",
    "        axs[i].set_title('Model '+metric)\n",
    "        axs[i].set_ylabel(metric)\n",
    "        axs[i].set_xlabel('epoch')\n",
    "        axs[i].set_ylim(ylimits[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess={}, augment={}):\n",
    "    \"\"\"\n",
    "    This function trains and evaluated a model. It first compiles the model with \n",
    "    the loss and metrics. It then makes a train and validation generator for the \n",
    "    image data, based on the preprocess and augment input. \n",
    "    It then trains the model on both the image and tabular data for epochs times. \n",
    "    The values of the loss and metric are plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
    "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "    # Preprocess the image data\n",
    "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
    "    train_gen.fit(image_x)\n",
    "\n",
    "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
    "    val_gen.fit(image_x)\n",
    "\n",
    "    # Train the model by fitting both tabular and image data at the same time\n",
    "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs=epochs, \n",
    "                      validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
    "\n",
    "    # Plot the loss and metric\n",
    "    plot_loss(history)\n",
    "    \n",
    "    val_loss = model.evaluate(val_gen.flow([x_val_imgs, x_val_tabular], val_y))[1]\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "# Concatenate tabular and image neural networks\n",
    "concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
    "\n",
    "# Train model on both tabular and image data and preprocess\n",
    "val_loss = train_and_evaluate(concat_model, train_imgs_array, x_train_tabular, y_train, \n",
    "                   x_val_tabular, val_imgs_array, y_val,\n",
    "                   preprocess={'featurewise_center': True, 'featurewise_std_normalization': True}, epochs=60)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_loss}\")\n",
    "\n",
    "# See how the model scored on the testing data\n",
    "loss = concat_model.evaluate([test_imgs_array, x_test_tabular], y_test)\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9-K3Mgs8weVG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9-K3Mgs8weVG",
    "outputId": "9bc21592-f893-4ba0-95ab-660604ef65c4"
   },
   "outputs": [],
   "source": [
    "# Create overview of layers in model\n",
    "tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Milestone_3_batch_norm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
