{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3915ca73",
      "metadata": {
        "id": "3915ca73"
      },
      "source": [
        "# Removing outliers and use k-fold cross-validation\n",
        "In this chapter we will remove outliers (data with a Pawpularity score of 100) to see if this improves the model performance. We use k-fold cross-validation for more reliable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vRjBTUzjlmKA",
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFZWcvRBvYv_",
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fANqjfPxoHI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "31d5ca20-eec3-4c81-dd40-e8aa4e2da494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-01-25 19:46:17--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-25 19:46:18--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [             <=>    ] 993.53M  22.5MB/s    in 54s     \n",
            "\n",
            "2022-01-25 19:47:11 (18.5 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1041789822]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae10a3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "8ae10a3a",
        "outputId": "ffbe439d-02c5-4135-b7d1-c255249c2967"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c98badce-19b2-4f59-9906-44ffc383d98e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c98badce-19b2-4f59-9906-44ffc383d98e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c98badce-19b2-4f59-9906-44ffc383d98e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c98badce-19b2-4f59-9906-44ffc383d98e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SRYM1P29o8k1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "03dbae3c-15bf-4d6c-ba6a-2143a2b5e812"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99"
      },
      "outputs": [],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CxecT9dhMfbF",
      "metadata": {
        "id": "CxecT9dhMfbF"
      },
      "outputs": [],
      "source": [
        "# Remove samples with pawpularity score of 100\n",
        "indexNames = train_data_sorted[train_data_sorted['Pawpularity'] == 100].index\n",
        "train_data_new = train_data_sorted.drop(indexNames)\n",
        "train_imgs_new = np.delete(train_imgs, indexNames, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Agl1YxFwNcKo",
      "metadata": {
        "id": "Agl1YxFwNcKo"
      },
      "outputs": [],
      "source": [
        "# Select x-values (the 12 input features) and y-values from training data\n",
        "x_tabular = train_data_new.iloc[:,1:13].to_numpy()\n",
        "y = train_data_new.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
        "\n",
        "# Create numpy array of image data \n",
        "x_images = np.array(train_imgs_new)\n",
        "test_imgs_array = np.array(test_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RNE8NWL7xgmp",
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99"
      },
      "outputs": [],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtZpIRuAue4B",
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZKkweNdcNXLl",
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "outputs": [],
      "source": [
        "def linear_limit(x):\n",
        "    \"\"\"\n",
        "    Create a linear activation function that clips the output at 0 and 100.\n",
        "    \"\"\"\n",
        "    activation_x = activations.linear(x)\n",
        "    activation_x_new = K.clip(activation_x, 0, 100)\n",
        "\n",
        "    return activation_x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with regularization\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu dropout and regularization\n",
        "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu dropout and regularization\n",
        "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer with linear limit activation function\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DZ58i65PvawJ",
      "metadata": {
        "id": "DZ58i65PvawJ"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "    \"\"\"\n",
        "    This function trains and evaluated a model. It first compiles the model with \n",
        "    the loss and metrics. It then makes a train and validation generator for the \n",
        "    image data, based on the preprocess and augment input. \n",
        "    It then trains the model on both the image and tabular data for epochs times. \n",
        "    The values of the loss and metric are plotted and printed.\n",
        "    \"\"\"\n",
        "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Preprocess the image data\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(image_x)\n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(image_x)\n",
        "\n",
        "    # Train the model by fitting both tabular and image data at the same time\n",
        "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs = epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eJp3actWxsB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eJp3actWxsB",
        "outputId": "cd7a834f-e92f-4ed2-88bc-e06c7e0acb34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "241/241 [==============================] - 24s 46ms/step - loss: 932.2542 - root_mean_squared_error: 27.7589 - val_loss: 729.6071 - val_root_mean_squared_error: 26.0223\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 650.5536 - root_mean_squared_error: 23.3337 - val_loss: 608.3318 - val_root_mean_squared_error: 23.5243\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 568.6594 - root_mean_squared_error: 22.1758 - val_loss: 538.9647 - val_root_mean_squared_error: 22.3678\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 503.5292 - root_mean_squared_error: 21.1442 - val_loss: 462.3998 - val_root_mean_squared_error: 20.5745\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 455.9534 - root_mean_squared_error: 20.3631 - val_loss: 417.7380 - val_root_mean_squared_error: 19.8203\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 406.9405 - root_mean_squared_error: 19.4167 - val_loss: 362.4495 - val_root_mean_squared_error: 18.4528\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 378.6949 - root_mean_squared_error: 18.8426 - val_loss: 349.3435 - val_root_mean_squared_error: 18.1663\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 358.8575 - root_mean_squared_error: 18.3876 - val_loss: 335.7694 - val_root_mean_squared_error: 17.7908\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 354.1377 - root_mean_squared_error: 18.2977 - val_loss: 336.2710 - val_root_mean_squared_error: 17.8539\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 351.6757 - root_mean_squared_error: 18.2822 - val_loss: 333.3582 - val_root_mean_squared_error: 17.8039\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 347.3937 - root_mean_squared_error: 18.1747 - val_loss: 333.6352 - val_root_mean_squared_error: 17.8222\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 11s 43ms/step - loss: 346.4516 - root_mean_squared_error: 18.1779 - val_loss: 331.0407 - val_root_mean_squared_error: 17.7531\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 345.2108 - root_mean_squared_error: 18.1683 - val_loss: 332.0802 - val_root_mean_squared_error: 17.8358\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 341.6788 - root_mean_squared_error: 18.1044 - val_loss: 330.9092 - val_root_mean_squared_error: 17.8241\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 340.8402 - root_mean_squared_error: 18.1002 - val_loss: 328.2015 - val_root_mean_squared_error: 17.7608\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 338.4269 - root_mean_squared_error: 18.0504 - val_loss: 327.6228 - val_root_mean_squared_error: 17.7546\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 336.8071 - root_mean_squared_error: 18.0120 - val_loss: 327.3724 - val_root_mean_squared_error: 17.7617\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 333.7877 - root_mean_squared_error: 17.9448 - val_loss: 327.2314 - val_root_mean_squared_error: 17.7663\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 334.6205 - root_mean_squared_error: 17.9794 - val_loss: 326.6821 - val_root_mean_squared_error: 17.7601\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 332.8251 - root_mean_squared_error: 17.9413 - val_loss: 325.9401 - val_root_mean_squared_error: 17.7534\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 333.1319 - root_mean_squared_error: 17.9623 - val_loss: 327.7641 - val_root_mean_squared_error: 17.8274\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 332.4534 - root_mean_squared_error: 17.9491 - val_loss: 326.7323 - val_root_mean_squared_error: 17.7946\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.9429 - root_mean_squared_error: 17.9137 - val_loss: 328.9815 - val_root_mean_squared_error: 17.8721\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 329.7764 - root_mean_squared_error: 17.8916 - val_loss: 325.5819 - val_root_mean_squared_error: 17.7679\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.3173 - root_mean_squared_error: 17.9099 - val_loss: 324.9305 - val_root_mean_squared_error: 17.7575\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 329.0708 - root_mean_squared_error: 17.8767 - val_loss: 328.3417 - val_root_mean_squared_error: 17.8738\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.7131 - root_mean_squared_error: 17.8728 - val_loss: 324.3899 - val_root_mean_squared_error: 17.7561\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 329.5320 - root_mean_squared_error: 17.9012 - val_loss: 324.0360 - val_root_mean_squared_error: 17.7505\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 328.7608 - root_mean_squared_error: 17.8835 - val_loss: 324.0367 - val_root_mean_squared_error: 17.7474\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 328.5767 - root_mean_squared_error: 17.8802 - val_loss: 326.1065 - val_root_mean_squared_error: 17.8201\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.5947 - root_mean_squared_error: 17.8884 - val_loss: 323.5774 - val_root_mean_squared_error: 17.7508\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 327.9695 - root_mean_squared_error: 17.8706 - val_loss: 324.9302 - val_root_mean_squared_error: 17.7913\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.3492 - root_mean_squared_error: 17.8882 - val_loss: 323.4372 - val_root_mean_squared_error: 17.7524\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.8641 - root_mean_squared_error: 17.8460 - val_loss: 323.7591 - val_root_mean_squared_error: 17.7662\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 327.3203 - root_mean_squared_error: 17.8611 - val_loss: 324.2238 - val_root_mean_squared_error: 17.7758\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 327.1214 - root_mean_squared_error: 17.8574 - val_loss: 323.8872 - val_root_mean_squared_error: 17.7682\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 327.3331 - root_mean_squared_error: 17.8704 - val_loss: 323.1534 - val_root_mean_squared_error: 17.7541\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 10s 43ms/step - loss: 326.7590 - root_mean_squared_error: 17.8546 - val_loss: 323.3252 - val_root_mean_squared_error: 17.7625\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 326.2958 - root_mean_squared_error: 17.8482 - val_loss: 323.4876 - val_root_mean_squared_error: 17.7621\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.6543 - root_mean_squared_error: 17.8588 - val_loss: 322.5586 - val_root_mean_squared_error: 17.7478\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.8543 - root_mean_squared_error: 17.8616 - val_loss: 323.3828 - val_root_mean_squared_error: 17.7699\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.5751 - root_mean_squared_error: 17.8626 - val_loss: 322.8907 - val_root_mean_squared_error: 17.7660\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.6975 - root_mean_squared_error: 17.8429 - val_loss: 322.9603 - val_root_mean_squared_error: 17.7645\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.2682 - root_mean_squared_error: 17.8616 - val_loss: 322.2841 - val_root_mean_squared_error: 17.7564\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.1971 - root_mean_squared_error: 17.8663 - val_loss: 321.9099 - val_root_mean_squared_error: 17.7484\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.8126 - root_mean_squared_error: 17.8562 - val_loss: 322.7897 - val_root_mean_squared_error: 17.7702\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.0477 - root_mean_squared_error: 17.8340 - val_loss: 323.0385 - val_root_mean_squared_error: 17.7791\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.4819 - root_mean_squared_error: 17.8509 - val_loss: 322.0248 - val_root_mean_squared_error: 17.7559\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.3989 - root_mean_squared_error: 17.8512 - val_loss: 322.3269 - val_root_mean_squared_error: 17.7697\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.0882 - root_mean_squared_error: 17.8452 - val_loss: 322.8755 - val_root_mean_squared_error: 17.7724\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.3732 - root_mean_squared_error: 17.8526 - val_loss: 323.4653 - val_root_mean_squared_error: 17.7989\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.1712 - root_mean_squared_error: 17.8510 - val_loss: 321.7246 - val_root_mean_squared_error: 17.7580\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.9841 - root_mean_squared_error: 17.8457 - val_loss: 322.7178 - val_root_mean_squared_error: 17.7838\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 325.1246 - root_mean_squared_error: 17.8478 - val_loss: 323.1494 - val_root_mean_squared_error: 17.7933\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.0750 - root_mean_squared_error: 17.8525 - val_loss: 322.0991 - val_root_mean_squared_error: 17.7721\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 324.7479 - root_mean_squared_error: 17.8413 - val_loss: 322.0322 - val_root_mean_squared_error: 17.7681\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 324.6952 - root_mean_squared_error: 17.8453 - val_loss: 321.2455 - val_root_mean_squared_error: 17.7516\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.7445 - root_mean_squared_error: 17.8493 - val_loss: 322.1076 - val_root_mean_squared_error: 17.7737\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.7572 - root_mean_squared_error: 17.8523 - val_loss: 321.9178 - val_root_mean_squared_error: 17.7716\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.4362 - root_mean_squared_error: 17.8415 - val_loss: 321.4394 - val_root_mean_squared_error: 17.7586\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 323.9790 - root_mean_squared_error: 17.8321\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 321.3701 - root_mean_squared_error: 17.7588\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 14s 48ms/step - loss: 818.7900 - root_mean_squared_error: 25.6705 - val_loss: 628.0297 - val_root_mean_squared_error: 23.7378\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 627.8615 - root_mean_squared_error: 22.9212 - val_loss: 618.0559 - val_root_mean_squared_error: 23.9721\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 548.5795 - root_mean_squared_error: 21.7893 - val_loss: 494.8317 - val_root_mean_squared_error: 21.4197\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 481.2526 - root_mean_squared_error: 20.6803 - val_loss: 452.3207 - val_root_mean_squared_error: 20.6017\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 429.2690 - root_mean_squared_error: 19.7942 - val_loss: 390.8486 - val_root_mean_squared_error: 19.1925\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 384.6057 - root_mean_squared_error: 18.9134 - val_loss: 354.2491 - val_root_mean_squared_error: 18.2593\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 360.5362 - root_mean_squared_error: 18.4074 - val_loss: 348.6046 - val_root_mean_squared_error: 18.1140\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 350.6094 - root_mean_squared_error: 18.1896 - val_loss: 346.6614 - val_root_mean_squared_error: 18.1186\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 351.1688 - root_mean_squared_error: 18.2440 - val_loss: 346.5863 - val_root_mean_squared_error: 18.1532\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 346.6581 - root_mean_squared_error: 18.1454 - val_loss: 348.5327 - val_root_mean_squared_error: 18.2057\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 342.2596 - root_mean_squared_error: 18.0516 - val_loss: 344.0293 - val_root_mean_squared_error: 18.1300\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 340.4205 - root_mean_squared_error: 18.0375 - val_loss: 342.6489 - val_root_mean_squared_error: 18.1071\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 335.0568 - root_mean_squared_error: 17.9083 - val_loss: 341.6525 - val_root_mean_squared_error: 18.1166\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 336.3610 - root_mean_squared_error: 17.9750 - val_loss: 340.1861 - val_root_mean_squared_error: 18.1007\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 334.3165 - root_mean_squared_error: 17.9338 - val_loss: 340.7404 - val_root_mean_squared_error: 18.1165\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 332.1182 - root_mean_squared_error: 17.8859 - val_loss: 339.7491 - val_root_mean_squared_error: 18.1160\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 332.3676 - root_mean_squared_error: 17.9114 - val_loss: 339.5807 - val_root_mean_squared_error: 18.1186\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 331.5077 - root_mean_squared_error: 17.8943 - val_loss: 339.4404 - val_root_mean_squared_error: 18.1273\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 329.3209 - root_mean_squared_error: 17.8436 - val_loss: 338.5529 - val_root_mean_squared_error: 18.1100\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.7944 - root_mean_squared_error: 17.8339 - val_loss: 339.1144 - val_root_mean_squared_error: 18.1255\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.7080 - root_mean_squared_error: 17.8403 - val_loss: 337.8086 - val_root_mean_squared_error: 18.0993\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.4975 - root_mean_squared_error: 17.8446 - val_loss: 337.6850 - val_root_mean_squared_error: 18.1098\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 328.2255 - root_mean_squared_error: 17.8464 - val_loss: 337.2982 - val_root_mean_squared_error: 18.1058\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.7064 - root_mean_squared_error: 17.8090 - val_loss: 339.5832 - val_root_mean_squared_error: 18.1664\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.1974 - root_mean_squared_error: 17.8002 - val_loss: 337.1304 - val_root_mean_squared_error: 18.1192\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.3282 - root_mean_squared_error: 17.8091 - val_loss: 336.6822 - val_root_mean_squared_error: 18.1107\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.7892 - root_mean_squared_error: 17.8035 - val_loss: 336.4697 - val_root_mean_squared_error: 18.1104\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 324.8441 - root_mean_squared_error: 17.7789 - val_loss: 336.3274 - val_root_mean_squared_error: 18.1017\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 325.1420 - root_mean_squared_error: 17.7900 - val_loss: 336.3823 - val_root_mean_squared_error: 18.1064\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 324.6610 - root_mean_squared_error: 17.7834 - val_loss: 336.0053 - val_root_mean_squared_error: 18.1078\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.4567 - root_mean_squared_error: 17.7841 - val_loss: 335.8406 - val_root_mean_squared_error: 18.1005\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 324.1255 - root_mean_squared_error: 17.7752 - val_loss: 336.1764 - val_root_mean_squared_error: 18.1165\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 323.7551 - root_mean_squared_error: 17.7652 - val_loss: 335.9698 - val_root_mean_squared_error: 18.1092\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 323.9100 - root_mean_squared_error: 17.7741 - val_loss: 336.2971 - val_root_mean_squared_error: 18.1155\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 323.8921 - root_mean_squared_error: 17.7751 - val_loss: 335.8719 - val_root_mean_squared_error: 18.1179\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 323.1292 - root_mean_squared_error: 17.7641 - val_loss: 335.4219 - val_root_mean_squared_error: 18.1116\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 323.3640 - root_mean_squared_error: 17.7770 - val_loss: 335.0731 - val_root_mean_squared_error: 18.1006\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 322.8024 - root_mean_squared_error: 17.7634 - val_loss: 335.4642 - val_root_mean_squared_error: 18.1216\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 322.4789 - root_mean_squared_error: 17.7585 - val_loss: 335.0888 - val_root_mean_squared_error: 18.1065\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 322.6911 - root_mean_squared_error: 17.7634 - val_loss: 334.6315 - val_root_mean_squared_error: 18.1023\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 322.5736 - root_mean_squared_error: 17.7669 - val_loss: 335.2226 - val_root_mean_squared_error: 18.1186\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 321.9662 - root_mean_squared_error: 17.7511 - val_loss: 334.3799 - val_root_mean_squared_error: 18.0976\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 322.5207 - root_mean_squared_error: 17.7688 - val_loss: 334.5018 - val_root_mean_squared_error: 18.1101\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 322.0820 - root_mean_squared_error: 17.7583 - val_loss: 334.9522 - val_root_mean_squared_error: 18.1185\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 321.8687 - root_mean_squared_error: 17.7544 - val_loss: 334.3956 - val_root_mean_squared_error: 18.1041\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 322.1537 - root_mean_squared_error: 17.7624 - val_loss: 334.0966 - val_root_mean_squared_error: 18.0910\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 322.2217 - root_mean_squared_error: 17.7675 - val_loss: 334.3851 - val_root_mean_squared_error: 18.1114\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 321.5424 - root_mean_squared_error: 17.7530 - val_loss: 334.5799 - val_root_mean_squared_error: 18.1160\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 321.8769 - root_mean_squared_error: 17.7564 - val_loss: 335.0738 - val_root_mean_squared_error: 18.1159\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 321.8829 - root_mean_squared_error: 17.7623 - val_loss: 334.4236 - val_root_mean_squared_error: 18.1086\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 321.8055 - root_mean_squared_error: 17.7585 - val_loss: 333.9426 - val_root_mean_squared_error: 18.1035\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 320.9799 - root_mean_squared_error: 17.7399 - val_loss: 334.3582 - val_root_mean_squared_error: 18.1173\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 321.0613 - root_mean_squared_error: 17.7438 - val_loss: 333.9849 - val_root_mean_squared_error: 18.1071\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 320.6555 - root_mean_squared_error: 17.7312 - val_loss: 333.7511 - val_root_mean_squared_error: 18.1010\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 320.6302 - root_mean_squared_error: 17.7344 - val_loss: 333.6806 - val_root_mean_squared_error: 18.1019\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 320.7399 - root_mean_squared_error: 17.7358 - val_loss: 334.2811 - val_root_mean_squared_error: 18.1164\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 320.5377 - root_mean_squared_error: 17.7332 - val_loss: 333.0388 - val_root_mean_squared_error: 18.0795\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 320.7867 - root_mean_squared_error: 17.7421 - val_loss: 333.1344 - val_root_mean_squared_error: 18.0873\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 320.6782 - root_mean_squared_error: 17.7395 - val_loss: 332.8761 - val_root_mean_squared_error: 18.0812\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 320.6602 - root_mean_squared_error: 17.7379 - val_loss: 333.6001 - val_root_mean_squared_error: 18.1002\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 319.7210 - root_mean_squared_error: 17.7168\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 334.2662 - root_mean_squared_error: 18.1227\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 13s 46ms/step - loss: 834.6734 - root_mean_squared_error: 25.8543 - val_loss: 588.8763 - val_root_mean_squared_error: 22.5245\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 642.1373 - root_mean_squared_error: 23.2791 - val_loss: 561.0531 - val_root_mean_squared_error: 22.5564\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 566.3947 - root_mean_squared_error: 22.1559 - val_loss: 555.2898 - val_root_mean_squared_error: 22.8004\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 500.3832 - root_mean_squared_error: 21.1380 - val_loss: 478.1962 - val_root_mean_squared_error: 21.2490\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 449.2418 - root_mean_squared_error: 20.2496 - val_loss: 399.4361 - val_root_mean_squared_error: 19.3897\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 406.3901 - root_mean_squared_error: 19.4491 - val_loss: 360.8312 - val_root_mean_squared_error: 18.4392\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 378.0436 - root_mean_squared_error: 18.8608 - val_loss: 337.5325 - val_root_mean_squared_error: 17.8509\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 357.7224 - root_mean_squared_error: 18.3969 - val_loss: 330.5354 - val_root_mean_squared_error: 17.6903\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 352.2511 - root_mean_squared_error: 18.2924 - val_loss: 327.2727 - val_root_mean_squared_error: 17.6109\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 348.3824 - root_mean_squared_error: 18.2226 - val_loss: 325.9244 - val_root_mean_squared_error: 17.6132\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 347.5929 - root_mean_squared_error: 18.2186 - val_loss: 325.5662 - val_root_mean_squared_error: 17.6377\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 344.1125 - root_mean_squared_error: 18.1622 - val_loss: 323.6514 - val_root_mean_squared_error: 17.6020\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 342.5234 - root_mean_squared_error: 18.1331 - val_loss: 323.6892 - val_root_mean_squared_error: 17.6264\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 339.7537 - root_mean_squared_error: 18.0752 - val_loss: 322.3888 - val_root_mean_squared_error: 17.6073\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 339.9533 - root_mean_squared_error: 18.1019 - val_loss: 322.0172 - val_root_mean_squared_error: 17.6093\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 339.5663 - root_mean_squared_error: 18.1017 - val_loss: 326.1944 - val_root_mean_squared_error: 17.7468\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 336.9371 - root_mean_squared_error: 18.0370 - val_loss: 321.4781 - val_root_mean_squared_error: 17.6169\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 336.0927 - root_mean_squared_error: 18.0257 - val_loss: 320.5053 - val_root_mean_squared_error: 17.5909\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 334.1036 - root_mean_squared_error: 17.9837 - val_loss: 319.9036 - val_root_mean_squared_error: 17.5865\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 333.8342 - root_mean_squared_error: 17.9814 - val_loss: 319.3781 - val_root_mean_squared_error: 17.5760\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 332.9859 - root_mean_squared_error: 17.9605 - val_loss: 320.4768 - val_root_mean_squared_error: 17.6210\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 332.9199 - root_mean_squared_error: 17.9735 - val_loss: 319.1432 - val_root_mean_squared_error: 17.5905\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 332.0550 - root_mean_squared_error: 17.9546 - val_loss: 319.5862 - val_root_mean_squared_error: 17.6175\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.9892 - root_mean_squared_error: 17.9364 - val_loss: 319.8705 - val_root_mean_squared_error: 17.6289\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.5070 - root_mean_squared_error: 17.9301 - val_loss: 318.2619 - val_root_mean_squared_error: 17.5870\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.2101 - root_mean_squared_error: 17.9274 - val_loss: 319.9387 - val_root_mean_squared_error: 17.6473\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 330.1434 - root_mean_squared_error: 17.9256 - val_loss: 318.8992 - val_root_mean_squared_error: 17.6101\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 329.2371 - root_mean_squared_error: 17.9023 - val_loss: 318.9046 - val_root_mean_squared_error: 17.6079\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 11s 44ms/step - loss: 329.6509 - root_mean_squared_error: 17.9172 - val_loss: 319.6310 - val_root_mean_squared_error: 17.6349\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 329.5408 - root_mean_squared_error: 17.9175 - val_loss: 317.6339 - val_root_mean_squared_error: 17.5925\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.7981 - root_mean_squared_error: 17.9026 - val_loss: 318.3888 - val_root_mean_squared_error: 17.6199\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.7206 - root_mean_squared_error: 17.9075 - val_loss: 317.4372 - val_root_mean_squared_error: 17.5980\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.7451 - root_mean_squared_error: 17.9115 - val_loss: 317.6401 - val_root_mean_squared_error: 17.6045\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 328.6230 - root_mean_squared_error: 17.9133 - val_loss: 317.1968 - val_root_mean_squared_error: 17.5954\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.3970 - root_mean_squared_error: 17.9103 - val_loss: 317.1855 - val_root_mean_squared_error: 17.6024\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.1382 - root_mean_squared_error: 17.9059 - val_loss: 317.9235 - val_root_mean_squared_error: 17.6087\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 327.9184 - root_mean_squared_error: 17.9087 - val_loss: 316.3087 - val_root_mean_squared_error: 17.5845\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 327.3847 - root_mean_squared_error: 17.8913 - val_loss: 315.5947 - val_root_mean_squared_error: 17.5623\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 327.7505 - root_mean_squared_error: 17.9089 - val_loss: 316.6440 - val_root_mean_squared_error: 17.6019\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 327.2164 - root_mean_squared_error: 17.8951 - val_loss: 316.4428 - val_root_mean_squared_error: 17.5944\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 327.5236 - root_mean_squared_error: 17.9033 - val_loss: 316.1720 - val_root_mean_squared_error: 17.5876\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 327.0346 - root_mean_squared_error: 17.8985 - val_loss: 316.2252 - val_root_mean_squared_error: 17.5933\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.7991 - root_mean_squared_error: 17.8905 - val_loss: 317.4099 - val_root_mean_squared_error: 17.6187\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.6471 - root_mean_squared_error: 17.8884 - val_loss: 316.2424 - val_root_mean_squared_error: 17.5967\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.6802 - root_mean_squared_error: 17.8879 - val_loss: 320.7044 - val_root_mean_squared_error: 17.7029\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 327.0163 - root_mean_squared_error: 17.9026 - val_loss: 315.3506 - val_root_mean_squared_error: 17.5780\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.3605 - root_mean_squared_error: 17.8831 - val_loss: 317.5604 - val_root_mean_squared_error: 17.6328\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.5844 - root_mean_squared_error: 17.8912 - val_loss: 318.2522 - val_root_mean_squared_error: 17.6540\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.4113 - root_mean_squared_error: 17.8901 - val_loss: 315.9194 - val_root_mean_squared_error: 17.5984\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.0345 - root_mean_squared_error: 17.8823 - val_loss: 315.6132 - val_root_mean_squared_error: 17.5921\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.9154 - root_mean_squared_error: 17.8769 - val_loss: 315.2185 - val_root_mean_squared_error: 17.5801\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.6740 - root_mean_squared_error: 17.8721 - val_loss: 316.0171 - val_root_mean_squared_error: 17.6020\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.2917 - root_mean_squared_error: 17.8932 - val_loss: 315.3979 - val_root_mean_squared_error: 17.5895\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.2407 - root_mean_squared_error: 17.8626 - val_loss: 316.1515 - val_root_mean_squared_error: 17.6057\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.2841 - root_mean_squared_error: 17.8626 - val_loss: 316.6069 - val_root_mean_squared_error: 17.6169\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.7690 - root_mean_squared_error: 17.8780 - val_loss: 316.1817 - val_root_mean_squared_error: 17.6121\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.1056 - root_mean_squared_error: 17.8607 - val_loss: 317.4940 - val_root_mean_squared_error: 17.6463\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.8915 - root_mean_squared_error: 17.8561 - val_loss: 316.2786 - val_root_mean_squared_error: 17.6098\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.2589 - root_mean_squared_error: 17.8633 - val_loss: 317.4653 - val_root_mean_squared_error: 17.6417\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 323.7929 - root_mean_squared_error: 17.8220 - val_loss: 319.7973 - val_root_mean_squared_error: 17.7071\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 327.2544 - root_mean_squared_error: 17.9230\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 317.6887 - root_mean_squared_error: 17.6539\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 13s 46ms/step - loss: 900.7636 - root_mean_squared_error: 27.0284 - val_loss: 590.8939 - val_root_mean_squared_error: 22.7147\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 659.4075 - root_mean_squared_error: 23.4580 - val_loss: 575.3741 - val_root_mean_squared_error: 22.9106\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 554.7717 - root_mean_squared_error: 21.8086 - val_loss: 522.6583 - val_root_mean_squared_error: 22.0145\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 496.4877 - root_mean_squared_error: 20.9962 - val_loss: 422.0950 - val_root_mean_squared_error: 19.7073\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 444.1033 - root_mean_squared_error: 20.0923 - val_loss: 378.8469 - val_root_mean_squared_error: 18.7456\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 401.3374 - root_mean_squared_error: 19.2720 - val_loss: 349.7683 - val_root_mean_squared_error: 18.0587\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 376.9221 - root_mean_squared_error: 18.8010 - val_loss: 342.6068 - val_root_mean_squared_error: 17.9636\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 363.4791 - root_mean_squared_error: 18.5162 - val_loss: 340.1601 - val_root_mean_squared_error: 17.9151\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 350.4726 - root_mean_squared_error: 18.2065 - val_loss: 336.4924 - val_root_mean_squared_error: 17.8585\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 350.8499 - root_mean_squared_error: 18.2508 - val_loss: 337.4247 - val_root_mean_squared_error: 17.9176\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 346.1976 - root_mean_squared_error: 18.1546 - val_loss: 334.6620 - val_root_mean_squared_error: 17.8648\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 345.9033 - root_mean_squared_error: 18.1569 - val_loss: 334.9807 - val_root_mean_squared_error: 17.8583\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 346.0285 - root_mean_squared_error: 18.1854 - val_loss: 333.5464 - val_root_mean_squared_error: 17.8624\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 339.9159 - root_mean_squared_error: 18.0457 - val_loss: 332.3773 - val_root_mean_squared_error: 17.8545\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 338.2654 - root_mean_squared_error: 18.0271 - val_loss: 332.4036 - val_root_mean_squared_error: 17.8667\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 337.3443 - root_mean_squared_error: 18.0139 - val_loss: 332.0320 - val_root_mean_squared_error: 17.8735\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 335.6773 - root_mean_squared_error: 17.9853 - val_loss: 331.5526 - val_root_mean_squared_error: 17.8641\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 335.2536 - root_mean_squared_error: 17.9773 - val_loss: 330.3446 - val_root_mean_squared_error: 17.8359\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 334.0957 - root_mean_squared_error: 17.9580 - val_loss: 330.6178 - val_root_mean_squared_error: 17.8752\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 332.8369 - root_mean_squared_error: 17.9368 - val_loss: 330.5284 - val_root_mean_squared_error: 17.8695\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 331.5378 - root_mean_squared_error: 17.9088 - val_loss: 329.3937 - val_root_mean_squared_error: 17.8629\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 332.0692 - root_mean_squared_error: 17.9330 - val_loss: 329.0482 - val_root_mean_squared_error: 17.8549\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 329.7769 - root_mean_squared_error: 17.8782 - val_loss: 328.5497 - val_root_mean_squared_error: 17.8596\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 330.3068 - root_mean_squared_error: 17.9045 - val_loss: 328.2697 - val_root_mean_squared_error: 17.8529\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 329.4634 - root_mean_squared_error: 17.8828 - val_loss: 328.3305 - val_root_mean_squared_error: 17.8576\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 329.4274 - root_mean_squared_error: 17.8913 - val_loss: 329.5949 - val_root_mean_squared_error: 17.8959\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 328.6552 - root_mean_squared_error: 17.8715 - val_loss: 327.9477 - val_root_mean_squared_error: 17.8624\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 328.3280 - root_mean_squared_error: 17.8647 - val_loss: 327.7078 - val_root_mean_squared_error: 17.8556\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 328.4052 - root_mean_squared_error: 17.8733 - val_loss: 327.6690 - val_root_mean_squared_error: 17.8594\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 327.9194 - root_mean_squared_error: 17.8622 - val_loss: 328.5135 - val_root_mean_squared_error: 17.8743\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 327.4363 - root_mean_squared_error: 17.8560 - val_loss: 327.7964 - val_root_mean_squared_error: 17.8647\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.7122 - root_mean_squared_error: 17.8382 - val_loss: 328.1751 - val_root_mean_squared_error: 17.8785\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.9671 - root_mean_squared_error: 17.8448 - val_loss: 327.7390 - val_root_mean_squared_error: 17.8720\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 326.6212 - root_mean_squared_error: 17.8380 - val_loss: 327.6299 - val_root_mean_squared_error: 17.8613\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 326.7698 - root_mean_squared_error: 17.8441 - val_loss: 326.8452 - val_root_mean_squared_error: 17.8620\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.1712 - root_mean_squared_error: 17.8401 - val_loss: 326.8612 - val_root_mean_squared_error: 17.8621\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.9246 - root_mean_squared_error: 17.8291 - val_loss: 327.7845 - val_root_mean_squared_error: 17.8816\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.8792 - root_mean_squared_error: 17.8319 - val_loss: 326.6216 - val_root_mean_squared_error: 17.8627\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 325.7397 - root_mean_squared_error: 17.8371 - val_loss: 326.7936 - val_root_mean_squared_error: 17.8697\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.3237 - root_mean_squared_error: 17.8272 - val_loss: 326.9777 - val_root_mean_squared_error: 17.8743\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.4178 - root_mean_squared_error: 17.8294 - val_loss: 327.0554 - val_root_mean_squared_error: 17.8804\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.8961 - root_mean_squared_error: 17.8159 - val_loss: 325.9887 - val_root_mean_squared_error: 17.8461\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.4774 - root_mean_squared_error: 17.8314 - val_loss: 326.6773 - val_root_mean_squared_error: 17.8716\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.3726 - root_mean_squared_error: 17.8318 - val_loss: 326.6132 - val_root_mean_squared_error: 17.8703\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 325.2278 - root_mean_squared_error: 17.8308 - val_loss: 326.3917 - val_root_mean_squared_error: 17.8716\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 325.2640 - root_mean_squared_error: 17.8336 - val_loss: 326.9800 - val_root_mean_squared_error: 17.8864\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.1496 - root_mean_squared_error: 17.8365 - val_loss: 326.1309 - val_root_mean_squared_error: 17.8644\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.6346 - root_mean_squared_error: 17.8209 - val_loss: 325.8728 - val_root_mean_squared_error: 17.8455\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.9844 - root_mean_squared_error: 17.8328 - val_loss: 325.8805 - val_root_mean_squared_error: 17.8679\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.0835 - root_mean_squared_error: 17.8116 - val_loss: 326.4390 - val_root_mean_squared_error: 17.8821\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.6866 - root_mean_squared_error: 17.8297 - val_loss: 325.8777 - val_root_mean_squared_error: 17.8635\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.4996 - root_mean_squared_error: 17.8221 - val_loss: 325.5486 - val_root_mean_squared_error: 17.8546\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.8641 - root_mean_squared_error: 17.8365 - val_loss: 324.8062 - val_root_mean_squared_error: 17.8407\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.2151 - root_mean_squared_error: 17.8200 - val_loss: 324.9005 - val_root_mean_squared_error: 17.8432\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 324.3539 - root_mean_squared_error: 17.8271 - val_loss: 324.9349 - val_root_mean_squared_error: 17.8503\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.4951 - root_mean_squared_error: 17.8070 - val_loss: 324.9190 - val_root_mean_squared_error: 17.8493\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 11s 45ms/step - loss: 324.0025 - root_mean_squared_error: 17.8167 - val_loss: 325.5486 - val_root_mean_squared_error: 17.8588\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.6740 - root_mean_squared_error: 17.8087 - val_loss: 325.1295 - val_root_mean_squared_error: 17.8539\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 323.6879 - root_mean_squared_error: 17.8127 - val_loss: 325.0431 - val_root_mean_squared_error: 17.8556\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 322.8707 - root_mean_squared_error: 17.7901 - val_loss: 325.1435 - val_root_mean_squared_error: 17.8566\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 323.6187 - root_mean_squared_error: 17.8188\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 327.3888 - root_mean_squared_error: 17.9243\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 14s 49ms/step - loss: 883.4442 - root_mean_squared_error: 26.7904 - val_loss: 561.9047 - val_root_mean_squared_error: 21.9305\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 638.3016 - root_mean_squared_error: 23.0053 - val_loss: 563.9607 - val_root_mean_squared_error: 22.6186\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 552.9645 - root_mean_squared_error: 21.8377 - val_loss: 495.4548 - val_root_mean_squared_error: 21.3673\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 488.2773 - root_mean_squared_error: 20.8411 - val_loss: 473.4068 - val_root_mean_squared_error: 21.1858\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 438.1160 - root_mean_squared_error: 19.9755 - val_loss: 392.0297 - val_root_mean_squared_error: 19.1018\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 403.3642 - root_mean_squared_error: 19.3482 - val_loss: 360.7094 - val_root_mean_squared_error: 18.4358\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 370.7295 - root_mean_squared_error: 18.6433 - val_loss: 342.9189 - val_root_mean_squared_error: 17.9721\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 359.0286 - root_mean_squared_error: 18.3968 - val_loss: 341.2455 - val_root_mean_squared_error: 17.9192\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 354.1685 - root_mean_squared_error: 18.2987 - val_loss: 340.4513 - val_root_mean_squared_error: 17.9230\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 347.8782 - root_mean_squared_error: 18.1511 - val_loss: 337.7195 - val_root_mean_squared_error: 17.8939\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 347.0638 - root_mean_squared_error: 18.1698 - val_loss: 336.1432 - val_root_mean_squared_error: 17.8967\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 344.1053 - root_mean_squared_error: 18.1175 - val_loss: 335.3568 - val_root_mean_squared_error: 17.9046\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 340.8806 - root_mean_squared_error: 18.0580 - val_loss: 334.8284 - val_root_mean_squared_error: 17.9064\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 339.1745 - root_mean_squared_error: 18.0286 - val_loss: 334.8826 - val_root_mean_squared_error: 17.9062\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 338.8171 - root_mean_squared_error: 18.0376 - val_loss: 334.0916 - val_root_mean_squared_error: 17.9137\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 337.8698 - root_mean_squared_error: 18.0192 - val_loss: 333.0162 - val_root_mean_squared_error: 17.8947\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 335.9192 - root_mean_squared_error: 17.9813 - val_loss: 332.6466 - val_root_mean_squared_error: 17.8916\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 335.3339 - root_mean_squared_error: 17.9799 - val_loss: 331.9152 - val_root_mean_squared_error: 17.9008\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 334.5807 - root_mean_squared_error: 17.9727 - val_loss: 331.7373 - val_root_mean_squared_error: 17.9017\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 332.2902 - root_mean_squared_error: 17.9165 - val_loss: 332.0811 - val_root_mean_squared_error: 17.9079\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 332.9428 - root_mean_squared_error: 17.9373 - val_loss: 331.7232 - val_root_mean_squared_error: 17.9002\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 331.5860 - root_mean_squared_error: 17.9064 - val_loss: 330.7673 - val_root_mean_squared_error: 17.8982\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 331.1726 - root_mean_squared_error: 17.9092 - val_loss: 330.5673 - val_root_mean_squared_error: 17.8953\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 329.7069 - root_mean_squared_error: 17.8733 - val_loss: 330.6413 - val_root_mean_squared_error: 17.9168\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 329.3066 - root_mean_squared_error: 17.8746 - val_loss: 330.1882 - val_root_mean_squared_error: 17.9022\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 327.8520 - root_mean_squared_error: 17.8424 - val_loss: 329.3573 - val_root_mean_squared_error: 17.8902\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 328.4614 - root_mean_squared_error: 17.8621 - val_loss: 328.5268 - val_root_mean_squared_error: 17.8681\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 327.9906 - root_mean_squared_error: 17.8510 - val_loss: 328.8907 - val_root_mean_squared_error: 17.8800\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 328.1971 - root_mean_squared_error: 17.8641 - val_loss: 329.0933 - val_root_mean_squared_error: 17.8907\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 327.6243 - root_mean_squared_error: 17.8519 - val_loss: 329.2448 - val_root_mean_squared_error: 17.8898\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 327.1969 - root_mean_squared_error: 17.8410 - val_loss: 329.9491 - val_root_mean_squared_error: 17.9178\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 327.2649 - root_mean_squared_error: 17.8466 - val_loss: 328.9041 - val_root_mean_squared_error: 17.8934\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 327.5835 - root_mean_squared_error: 17.8576 - val_loss: 328.8699 - val_root_mean_squared_error: 17.8958\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.9199 - root_mean_squared_error: 17.8469 - val_loss: 328.4324 - val_root_mean_squared_error: 17.8910\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.9775 - root_mean_squared_error: 17.8541 - val_loss: 327.4633 - val_root_mean_squared_error: 17.8725\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.2258 - root_mean_squared_error: 17.8376 - val_loss: 329.8147 - val_root_mean_squared_error: 17.9102\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.1400 - root_mean_squared_error: 17.8301 - val_loss: 327.5111 - val_root_mean_squared_error: 17.8779\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.4100 - root_mean_squared_error: 17.8454 - val_loss: 328.2800 - val_root_mean_squared_error: 17.8971\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 325.8931 - root_mean_squared_error: 17.8334 - val_loss: 327.8876 - val_root_mean_squared_error: 17.8938\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 325.9784 - root_mean_squared_error: 17.8439 - val_loss: 327.0269 - val_root_mean_squared_error: 17.8809\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.6265 - root_mean_squared_error: 17.8351 - val_loss: 326.9933 - val_root_mean_squared_error: 17.8824\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 11s 46ms/step - loss: 325.3698 - root_mean_squared_error: 17.8339 - val_loss: 326.9265 - val_root_mean_squared_error: 17.8850\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 325.1863 - root_mean_squared_error: 17.8368 - val_loss: 326.9212 - val_root_mean_squared_error: 17.8887\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 324.5862 - root_mean_squared_error: 17.8192 - val_loss: 327.3891 - val_root_mean_squared_error: 17.8980\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 324.8507 - root_mean_squared_error: 17.8310 - val_loss: 326.6263 - val_root_mean_squared_error: 17.8836\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 324.8563 - root_mean_squared_error: 17.8303 - val_loss: 326.6208 - val_root_mean_squared_error: 17.8838\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.5695 - root_mean_squared_error: 17.8236 - val_loss: 326.9024 - val_root_mean_squared_error: 17.8868\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.7717 - root_mean_squared_error: 17.8302 - val_loss: 326.6123 - val_root_mean_squared_error: 17.8868\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 324.5525 - root_mean_squared_error: 17.8243 - val_loss: 327.0963 - val_root_mean_squared_error: 17.8999\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 324.0291 - root_mean_squared_error: 17.8143 - val_loss: 326.2984 - val_root_mean_squared_error: 17.8808\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 324.0746 - root_mean_squared_error: 17.8156 - val_loss: 326.5602 - val_root_mean_squared_error: 17.8805\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.9994 - root_mean_squared_error: 17.8146 - val_loss: 326.4268 - val_root_mean_squared_error: 17.8803\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 324.1513 - root_mean_squared_error: 17.8241 - val_loss: 325.8000 - val_root_mean_squared_error: 17.8724\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.9324 - root_mean_squared_error: 17.8091 - val_loss: 327.9887 - val_root_mean_squared_error: 17.9177\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.4692 - root_mean_squared_error: 17.7990 - val_loss: 325.3787 - val_root_mean_squared_error: 17.8585\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 323.5185 - root_mean_squared_error: 17.8020 - val_loss: 326.0883 - val_root_mean_squared_error: 17.8672\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.4194 - root_mean_squared_error: 17.7983 - val_loss: 325.3272 - val_root_mean_squared_error: 17.8533\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 323.5210 - root_mean_squared_error: 17.8015 - val_loss: 325.9385 - val_root_mean_squared_error: 17.8727\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 323.4607 - root_mean_squared_error: 17.8048 - val_loss: 325.2073 - val_root_mean_squared_error: 17.8591\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 322.9177 - root_mean_squared_error: 17.7861 - val_loss: 326.7386 - val_root_mean_squared_error: 17.8955\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 323.4634 - root_mean_squared_error: 17.8127\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 325.2660 - root_mean_squared_error: 17.8632\n",
            "[4369.925354   3218.26153564 2791.36981201 2469.93014526 2216.68338013\n",
            " 2002.6378479  1864.92633057 1789.69696045 1762.19876099 1745.44430542\n",
            " 1730.50759888 1720.99325562 1709.70019531 1696.88388062 1692.19244385\n",
            " 1685.32550049 1677.70822144 1671.9755249  1666.72137451 1660.58084106\n",
            " 1659.30645752 1657.52612305 1652.17294312 1647.48556519 1645.79171753\n",
            " 1642.88839722 1641.76220703 1639.93173218 1640.15600586 1638.32217407\n",
            " 1636.48272705 1634.79275513 1635.39996338 1632.9382019  1633.35668945\n",
            " 1630.78582764 1630.67996216 1629.23532104 1628.15795898 1627.8638916\n",
            " 1627.99578857 1625.84191895 1625.68103027 1624.95602417 1624.82458496\n",
            " 1625.1027832  1623.34909058 1623.01507568 1623.22399902 1621.11825562\n",
            " 1621.8553772  1620.32400513 1621.35244751 1619.16830444 1618.81253052\n",
            " 1618.27023315 1617.76034546 1617.6177063  1617.84286499 1614.67767334] [873.9850708  643.65230713 558.2739624  493.98602905 443.33667603\n",
            " 400.52756958 372.98526611 357.93939209 352.4397522  349.08886108\n",
            " 346.10151978 344.19865112 341.94003906 339.37677612 338.43848877\n",
            " 337.0651001  335.54164429 334.39510498 333.3442749  332.11616821\n",
            " 331.8612915  331.50522461 330.43458862 329.49711304 329.15834351\n",
            " 328.57767944 328.35244141 327.98634644 328.03120117 327.66443481\n",
            " 327.29654541 326.95855103 327.07999268 326.58764038 326.67133789\n",
            " 326.15716553 326.13599243 325.84706421 325.6315918  325.57277832\n",
            " 325.59915771 325.16838379 325.13620605 324.99120483 324.96491699\n",
            " 325.02055664 324.66981812 324.60301514 324.6447998  324.22365112\n",
            " 324.37107544 324.06480103 324.2704895  323.83366089 323.7625061\n",
            " 323.65404663 323.55206909 323.52354126 323.568573   322.93553467]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAFNCAYAAABMn9WLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5xU9b3/8ddnZrbCAkuRtkhVWYoNRBB7JVjjtSYxYhSN0Wjajf5y741p98YkJpaUm2uLippINJZYUjR2gUgTKUZpAgvq0uuWmfn8/jhnd4dlARdm92x5Px+ex5zzPd9zzmfK4nc+8/1+j7k7IiIiIiIiIiIi+yoWdQAiIiIiIiIiItK6KcEkIiIiIiIiIiL7RQkmERERERERERHZL0owiYiIiIiIiIjIflGCSURERERERERE9osSTCIiIiIiIiIisl+UYBKRFsvMBpiZm1niU9SdZGZvNEdcIiIiIm2J2lwikg1KMIlIVpjZcjOrMrPu9crnhA2WAdFEtlOjaU698u5hzMszyo41s7fMbJOZrTezN83sqHDfJDNLmdnWekufZn5KIiIi0k61kjZXTRtpuZndXK/Op4rfzErM7AkzWxu2y+ab2aTdXKdmubiZnqqINEAJJhHJpmXApTUbZjYSKIwunF0UmtmIjO3PEcQMgJl1Ap4Ffgl0BfoC3wcqM46Z5u4d6y2rmyF2ERERkRotvc3Vxd07AhcA/2Vmp9Xb/2ninwKsBPoD3YDLgI8buk7G8lg2n4SINI4STCKSTVOAL2ZsXw48lFnBzDqb2UNmVm5mH5rZf5pZLNwXN7Pbwl+qlgJnNnDsfWa2xszKzOxHZhZvZHyXZ2x/sV58BwO4++/dPeXuO9z9b+4+rxHXEBEREWlqLb3NBYC7zwQWAIc3Nn7gKOABd9/m7kl3n+PuLzQ2BhFpPkowiUg2TQc6mVlp2Ai5BHi4Xp1fAp2BQcAJBI2LK8J9k4GzgCOA0QS/emV6AEgCQ8I6pwNXNSK+h4FLwkbVMKAjMCNj//tAysweNLPPmFlxI84tIiIi0lxaepsLADMbC4wAFu9D/NOBX5vZJWZ2YGOvLSLNTwkmEcm2ml+kTgMWAWU1OzIaEP/P3be4+3Lg5wRdngEuAu5w95Xuvh74ccaxPYGJwNfCX7I+AW4Pz/dprQL+BZwaxjglc6e7bwaOBRy4Byg3s2fCa9cYa2YbM5Yljbi+iIiISLa05DbXWjPbAUwDfgM81Zj4QxcCrwP/BSwzs7k182LWu05mu6y0ETGKSJbt9S4BIiKNNAV4DRjIrl2duwM5wIcZZR8SzHUE0IdgrH3mvhr9w2PXmFlNWaxe/U/jIWAScAxwHOGwuBruvijcj5kNJfg17Q7q5gmY7u7HNvKaIiIiItnWkttc3Ql+sLuRYM7LHKCqEfHj7huAm4GbwwnBbwOeMrOSzOu4e7IRcYlIE1IPJhHJKnf/kGDixonAn+rtXgtUEzRcahxI3S9Wa4B+9fbVWEkw2XZ3d+8SLp3cfXgjQ3yCYJ6Bpe6+Yi/P5T2CLuIj9lRPREREpLm19DZXOJ/lL4AK4CuNjL9+3bUECaY+BDdiEZEWSAkmEWkKVwInu/u2zEJ3TwFTgf82syIz6w98g7ox91OBG8Lb0hYT/GpVc+wa4G/Az82sk5nFzGywmZ3QmMDCmE6mgXkEzGyomX2z5pcxM+tH0HNpemOuISIiItJMWmybK8OtwLfNLP/Txg9gZj8xsxFmljCzIuBaYLG7r9vHOESkiSnBJCJZ5+5LwruGNOSrwDZgKfAG8Chwf7jvHuCvwDvAbHb9NeuLQC6wENgAPA703of4Zrp7Q3MnbQGOBmaY2TaCxNJ84JsZdcaZ2dZ6S/35AERERESaXEtvc4WeC88xuZHxFwJPAhvD59AfOKdenY312mTf2McYRSQLzN2jjkFERERERERERFox9WASEREREREREZH90mQJJjO738w+MbP5GWVdzezvZvZB+FgclpuZ3WVmi81snpkdmXHM5WH9D8zs8qaKV0RERKQ9MrN8M/unmb1jZgvM7Pth+UAzmxG2zx4zs9yoYxUREZGWqyl7MD0ATKhXdjPwkrsfBLxE3WRynwEOCpergf+FICEF3EIwJ8oY4JaapJSIiIiIZEUlwSS7hwGHAxPMbCzwE+B2dx9CMH/KlRHGKCIiIi1ckyWY3P01YH294nOBB8P1B4HzMsof8sB0oIuZ9QbOAP7u7uvdfQPwd3ZNWomIiIjIPgrbX1vDzZxwcYI7bj4elme220RERER20dxzMPUMb3sJ8BHQM1zvC6zMqLcqLNtduYiIiIhkiZnFzWwu8AnBD3pLgI3ungyrqA0mIiIie5SI6sLu7maWtVvYmdnVBMPr6NChw6ihQ4dm69QiIiLSAs2aNWutu/eIOo62wN1TwOFm1oXgtuCfuiGlNpiIiEj7saf2V3MnmD42s97uviYcAvdJWF4G9MuoVxKWlQEn1it/paETu/vdwN0Ao0eP9pkzZ2Y3chEREWlRzOzDqGNoa9x9o5m9DIwjmLIgEfZiqmmbNXSM2mAiIiLtxJ7aX809RO4ZoOZOcJcDT2eUfzG8m9xYYFM4lO6vwOlmVhxO7n16WCYiIiIiWWBmPcKeS5hZAXAasAh4GbggrJbZbhMRERHZRZP1YDKz3xP0PupuZqsI7gZ3KzDVzK4EPgQuCqs/D0wEFgPbgSsA3H29mf0QeDus9wN3rz9xuIiIiIjsu97Ag2YWJ/jxcaq7P2tmC4E/mNmPgDnAfVEGKSIiIi1bkyWY3P3S3ew6pYG6Dly3m/PcD9yfxdBEREREJOTu84AjGihfCoxp/ohERESkNYpskm8REZG2qLq6mlWrVlFRURF1KG1Gfn4+JSUl5OTkRB2KiIiItFBqg2XXvrS/lGASERHJolWrVlFUVMSAAQMws6jDafXcnXXr1rFq1SoGDhwYdTgiIiLSQqkNlj372v5q7km+RURE2rSKigq6deumhk2WmBndunXTr5EiIiKyR2qDZc++tr+UYBIREckyNWyyS6+niIiIfBpqM2TPvryWSjCJiIi0IRs3buQ3v/lNo4+bOHEiGzdu3GOd7373u7z44ov7GpqIiIhIm6U2mBJMIiIibcruGjfJZHKPxz3//PN06dJlj3V+8IMfcOqpp+5XfCIiIiJtkdpgSjCJiIi0KTfffDNLlizh8MMP56ijjuK4447jnHPOYdiwYQCcd955jBo1iuHDh3P33XfXHjdgwADWrl3L8uXLKS0tZfLkyQwfPpzTTz+dHTt2ADBp0iQef/zx2vq33HILRx55JCNHjuS9994DoLy8nNNOO43hw4dz1VVX0b9/f9auXdvMr4KIiIhI81IbTAkmERGRNuXWW29l8ODBzJ07l5/97GfMnj2bO++8k/fffx+A+++/n1mzZjFz5kzuuusu1q1bt8s5PvjgA6677joWLFhAly5deOKJJxq8Vvfu3Zk9ezbXXnstt912GwDf//73Ofnkk1mwYAEXXHABK1asaLonKyIiItJCqA0GiWa/ooiISDvx/T8vYOHqzVk957A+nbjl7OGfuv6YMWN2ur3sXXfdxZNPPgnAypUr+eCDD+jWrdtOxwwcOJDDDz8cgFGjRrF8+fIGz33++efX1vnTn/4EwBtvvFF7/gkTJlBcXPypYxURERHJBrXBommDKcEkIiLShnXo0KF2/ZVXXuHFF19k2rRpFBYWcuKJJzZ4+9m8vLza9Xg8Xts9e3f14vH4XucXEBEREWlP2mMbTAkmERGRJtKYX7mypaioiC1btjS4b9OmTRQXF1NYWMh7773H9OnTs3798ePHM3XqVG666Sb+9re/sWHDhqxfQ0RERGRP1AaLpg2mBJOIiEgb0q1bN8aPH8+IESMoKCigZ8+etfsmTJjAb3/7W0pLSznkkEMYO3Zs1q9/yy23cOmllzJlyhTGjRtHr169KCoqyvp1RERERFoStcHA3L1ZL9gcRo8e7TNnzow6DBERaYcWLVpEaWlp1GFEprKykng8TiKRYNq0aVx77bXMnTt3v8/b0OtqZrPcffR+n1yyRm0wERGJitpg2W+DNbb9pR5MIiIikjUrVqzgoosuIp1Ok5ubyz333BN1SCIiIiJtXktogynBJCIiIllz0EEHMWfOnKjDEBEREWlXWkIbLBbp1UVEREREREREpNVTgklERERERERERPaLEkwiIiIiIiIiIrJflGASEREREREREZH9ogSTiIhIO9exY0cAVq9ezQUXXNBgnRNPPJG93X7+jjvuYPv27bXbEydOZOPGjdkLVERERKSNaIvtLyWYREREBIA+ffrw+OOP7/Px9Rs4zz//PF26dMlGaCIiIiJtUltqfynBJCIi0sbcfPPN/PrXv67d/t73vsePfvQjTjnlFI488khGjhzJ008/vctxy5cvZ8SIEQDs2LGDSy65hNLSUj772c+yY8eO2nrXXnsto0ePZvjw4dxyyy0A3HXXXaxevZqTTjqJk046CYABAwawdu1aAH7xi18wYsQIRowYwR133FF7vdLSUiZPnszw4cM5/fTTd7qOiIiISGuh9hfg7m1uGTVqlIuIiERh4cKFUYfgs2fP9uOPP752u7S01FesWOGbNm1yd/fy8nIfPHiwp9Npd3fv0KGDu7svW7bMhw8f7u7uP//5z/2KK65wd/d33nnH4/G4v/322+7uvm7dOnd3TyaTfsIJJ/g777zj7u79+/f38vLy2uvWbM+cOdNHjBjhW7du9S1btviwYcN89uzZvmzZMo/H4z5nzhx3d7/wwgt9ypQpDT6nhl5XYKa3gHaHFrXBREQkelG3wdT+chLZSVOJiIjILl64GT56N7vn7DUSPnPrHqscccQRfPLJJ6xevZry8nKKi4vp1asXX//613nttdeIxWKUlZXx8ccf06tXrwbP8dprr3HDDTcAcOihh3LooYfW7ps6dSp33303yWSSNWvWsHDhwp321/fGG2/w2c9+lg4dOgBw/vnn8/rrr3POOecwcOBADj/8cABGjRrF8uXLG/NqiIiIiOwqgjaY2l8owSQiItIWXXjhhTz++ON89NFHXHzxxTzyyCOUl5cza9YscnJyGDBgABUVFY0+77Jly7jtttt4++23KS4uZtKkSft0nhp5eXm16/F4XEPkpEEV1SlWb9zBoB4dow5FRERkt9p7+0sJJhERkaayl55GTeniiy9m8uTJrF27lldffZWpU6dywAEHkJOTw8svv8yHH364x+OPP/54Hn30UU4++WTmz5/PvHnzANi8eTMdOnSgc+fOfPzxx7zwwguceOKJABQVFbFlyxa6d+++07mOO+44Jk2axM0334y78+STTzJlypQmed7SNt3w+zl88MlWXv7WiVGHIiIirUFEbbD23v5SgklERKQNGj58OFu2bKFv37707t2bz3/+85x99tmMHDmS0aNHM3To0D0ef+2113LFFVdQWlpKaWkpo0aNAuCwww7jiCOOYOjQofTr14/x48fXHnP11VczYcIE+vTpw8svv1xbfuSRRzJp0iTGjBkDwFVXXcURRxyh4XDyqY0Z2JW/LfyYjzZV0KtzftThiIiINKi9t78smKOpbRk9erTPnDkz6jBERKQdWrRoEaWlpVGH0eY09Lqa2Sx3Hx1RSNKApmqDzS/bxFm/fIM7Lj6c847om/Xzi4hI66c2WPY1tv0Va5ao2ogFqzfx07+8x/aqZNShiIiIiLQbpb070Sk/wbQl66IORURERHZDCaZGWFK+jd+8soRVGzQBqYiIiEhziceMowd1Y/oyJZhERERaKiWYGqGkuACAVRu2RxyJiIiISPsyblA3Ply3ndUb9UOfiIhIS6QEUyPUJZjUsBERkd1ri/MbRkmvpwCMHdQNgOlL1YtJREQapjZD9uzLa6kEUyP06JhHXiKmBJOIiOxWfn4+69atUwMnS9yddevWkZ+vO4e1d0N7FdGlMEfzMImISIPUBsuefW1/JZoonjbJzOhbXKAhciIislslJSWsWrWK8vLyqENpM/Lz8ykpKYk6DIlYLGYcPbAr09SDSUREGqA2WHbtS/tLCaZGKikuVA8mERHZrZycHAYOHBh1GCJt0rhB3fjrgo9ZuX47/boWRh2OiIi0IGqDRU9D5BqppLhACSYRERGRCIwdrHmYREREWiolmBqppLiA9duq2FaZjDoUERERkf1mZv3M7GUzW2hmC8zsxrD8e2ZWZmZzw2Vi1LEefEARXTvkMn3p+qhDERERkXo0RK6RSoqD7thlG3dwcM+iiKMRERER2W9J4JvuPtvMioBZZvb3cN/t7n5bhLHtpGYepulLg0lczSzqkERERCSkHkyNVFJcAKCJvkVERKRNcPc17j47XN8CLAL6RhvV7o0b3I2yjTtYuV5TFoiIiLQkSjA1Ul2CSY0aERERaVvMbABwBDAjLLrezOaZ2f1mVhxZYBnGDdI8TCIiIi2REkyN1KNjHnmJmBJMIiIi0qaYWUfgCeBr7r4Z+F9gMHA4sAb4+W6Ou9rMZprZzOa4NfSQAzrSvWMu05RgEhERaVGUYGokM6NvcYGGyImIiEibYWY5BMmlR9z9TwDu/rG7p9w9DdwDjGnoWHe/291Hu/voHj16NEesHD2oW+08TCIiItIyKMG0D0qKC9WDSURERNoEC2bKvg9Y5O6/yCjvnVHts8D85o5td8YO6saaTRV8uE4/+ImIiLQUuovcPigpLmB+2aaowxARERHJhvHAZcC7ZjY3LPsOcKmZHQ44sBy4JprwdpU5D9OA7h0ijkZERERACaZ9UlJcwPptVWyrTNIhTy+hiIiItF7u/gZgDex6vrlj+bQG9+hAj6I8pi1dxyVjDow6HBEREUFD5PZJ3y7BneTKNmqYnIiIiEhzMzPGDurGtCWah0lERKSliCTBZGZfN7MFZjbfzH5vZvlmNtDMZpjZYjN7zMxyw7p54fbicP+AKGLOVFJcCECZ5mESERERicTYQV35ZEsly9ZuizoUERERIYIEk5n1BW4ARrv7CCAOXAL8BLjd3YcAG4Arw0OuBDaE5beH9SLVrzjowaQ7yYmIiIhEo2YepmlL10UciYiIiEB0Q+QSQIGZJYBCYA1wMvB4uP9B4Lxw/dxwm3D/KeHdTiLTvWMeuYmY7iQnIiIiEpGB3TvQs1Me05eujzoUERERIYIEk7uXAbcBKwgSS5uAWcBGd0+G1VYBfcP1vsDK8NhkWL9b/fOa2dVmNtPMZpaXlzfpc4jFjJIuBUowiYiIiERE8zCJiIi0LFEMkSsm6JU0EOgDdAAm7O953f1udx/t7qN79Oixv6fbq77FBRoiJyIiIhKhcYO6sXZrJUvKNQ+TiIhI1KIYIncqsMzdy929GvgTMB7oEg6ZAygBysL1MqAfQLi/MxD5YPuS4kL1YBIRERGJ0FjNwyQiItJiRJFgWgGMNbPCcC6lU4CFwMvABWGdy4Gnw/Vnwm3C/f/wFtAPuqS4gHXbqtheldx7ZRERERHJuv7dCundOZ/pS5RgEhERiVoUczDNIJisezbwbhjD3cBNwDfMbDHBHEv3hYfcB3QLy78B3NzcMTekJLyTXJl6MYmIiIg0rd38tlgzD9P0pZqHSUREJGqJvVfJPne/BbilXvFSYEwDdSuAC5sjrsYoKS4EYNWGHRzUsyjiaERERETasBe/B2WzYOhZMHQidDmwdte4Qd14ck4ZH3yylYPVJhMREYlMFEPk2oR+YQ8mTfQtIiIi0sQ69YFta+EvN8EdI+G3x8ErP4GP5jN2YFcApmseJhERkUhF0oOpLejeMY/cREwTfYuIiIg0taOvCZZ1S+C954LllR/DK/9Dvy79ubXDobz29rl8/uj+xGMWdbQiIiLtkhJM+ygWM0q6FCjBJCIiItJcug2G8TcEy9ZP4F8vYO89x4Wb/8IJ697kkX8M4IunHhV1lCIiIu2Shsjth77FBRoiJyIiIhKFjgfAqMvh81OJTX6JbrGtDHnta7y3ekPUkYmIiLRLSjDth5LiQvVgEhEREYmY9T6MqtN/yjGx+cx+8CYqk6moQxIREWl3lGDaDyXFBazbVsX2qmTUoYiIiIi0ax3HXUHZwAv4XOVjPP3HB6IOR0REpN1Rgmk/lIR3kitTLyYRERGRyPX93K9YnT+E09/7L96ZPy/qcERERNoVJZj2Q0lxIYCGyYmIiIi0BDkFdL789yTMyf3TFWzdti3qiERERNoNJZj2Q7+wB5Mm+hYRERFpGTr0Ppg1J91OaXox7973lajDERERaTeUYNoP3TvmkZuIqQeTiIiISAty0AmXMKP3Fxi3/inefeGeqMMRERFpF5Rg2g+xmNG3S4ESTCIiIiItzBFX3M67ieEMmfEfbFz+TtThiIiItHlKMO2nkuICDZETERERaWFyc3MpuPQhtno+FY98Hq/YHHVIIiIibZoSTPspSDCpB5OIiIhISzNk8BCmH/kzelStYsmUG6IOR0REpE1Tgmk/lRQXsm5bFdurklGHIiIiIiL1TDz7Il7ofDFDyp5k3mtPRR2OiIhIm6UE034qCe8kt3qjejGJiIiItDTxmHHC5J+xKtaXri99i/dWfBR1SCIiIm2SEkz7qSbBtFLD5ERERERapKKiTuT/268psXLmPPBNPtpUEXVIIiIibY4STPuppLgQQPMwiYiIiLRg3YefxPphX+Ti1HP85N4pbK3U9AYiIiLZpATTfurRMY/ceEx3khMRERFp4bqe899UdejFtZtu58aHp1OdSkcdkoiISJuhBNN+isWMvrqTnIiIiEjLl9+J/PPu4uBYGYcuu4/vPj0fd486KhERkTZBCaYsKFGCSURERKR1OPh0OPRirs95mjlvv8lvX10adUQiIiJtghJMWVBSXECZhsiJiIiItA5n/JhYQTH/1/l33PaXBTzzzuqoIxIREWn1lGDKgpLiQtZurWJHVSrqUERERERkbzp0wyb+lP4V/+K7PV7lW1Pf4c3Fa6OOSkREpFVTgikLSooLACjbqF5MIiIiIq3C8PPhkIl8cccjHFO8kSsffJu3lGQSERHZZ0owZUFNgmml5mESERERaR3M4MyfY/Ec7i6ewoHFBXzpwbd5a4mSTCIiIvtCCaYsKCkuBNBE3yIiIiKtSac+cPoPyV35Jk+MW0q/4kK+9MDbTFuyLurIREREWh0lmLKgR8c8cuMxVmmibxEREZHW5YgvwoHjKHrth/zhsoPpV1zIFQ/8U0kmERGRRlKCKQtiMaNvcYF6MImIiIi0NrEYnPkLqNhEt2n/w6OTx9b2ZJq+VEkmERGRT0sJpiwpUYJJREREWiEz62dmL5vZQjNbYGY3huVdzezvZvZB+FgcdaxNpucwGPcVmP0QPTa+w6OTx1JSXMAVv1OSSURE5NNSgilLSooLKNMQOREREWl9ksA33X0YMBa4zsyGATcDL7n7QcBL4XbbdcLNUNQHnv0GPQrjPDp5LH3DJNMMJZlERET2SgmmLOnbpYC1W6vYUZWKOhQRERGRT83d17j77HB9C7AI6AucCzwYVnsQOC+aCJtJXkf4zK3w8bvwz7vpUZTHo5OPpm9xAZN+9zZvLtbd5URERPZECaYsqbmTXNlG9WISERGR1snMBgBHADOAnu6+Jtz1EdAzorCaT+k5MORUePm/YfNqDijK59HJR3Ng10KueOBtXlz4cdQRioiItFhKMGVJSXEBACs1D5OIiIi0QmbWEXgC+Jq7b87c5+4O+G6Ou9rMZprZzPLy8maItAmZwcSfQaoa/vofABxQlM9j14yltFcR1zw8i6fnlkUcpIiISMukBFOW1PRg0kTfIiIi0tqYWQ5BcukRd/9TWPyxmfUO9/cGPmnoWHe/291Hu/voHj16NE/ATanrIDjum7DgT7DkHwB0KczlkcljGd2/mK89NpdHZ6yIOEgREZGWRwmmLDmgKI+cuLFKE32LiIhIK2JmBtwHLHL3X2Tsega4PFy/HHi6uWOLzPgbg0TTc9+C6goAOuYlePBLYzjx4B5858l3uee1pREHKSIi0rIowZQlsZjRt0uBejCJiIhIazMeuAw42czmhstE4FbgNDP7ADg13G4fcvJh4m2wfgm8dVdtcX5OnP+7bDRnjuzNfz+/iF/8/X2C0YMiIiKSiDqAtqSkuFAJJhEREWlV3P0NwHaz+5TmjKVFGXIKDDsPXrsNRl4Q9GgCchMx7rr0CDrkxbnrpQ/YWpHkv84qJegIJiIi0n6pB1MWlRQXsGLdNv2SJSIiItIWTPgxxHPg+W9DRvsuHjNuPf9Qrhg/gPvfXMY3//gO2yqTEQYqIiISPSWYsmhU/2I2bK9m3qpNUYciIiIiIvurUx846T9g8d/hlZ1HCMZixnfPGsbXTz2YJ+eUMeHO13hr8dqIAhUREYmeEkxZdPqwXuTEjefeXRN1KCIiIiKSDWOvhSO+AK/eCtN+vdMuM+PGUw9i6jXjSMRifO7eGXznyXfZUlEdUbAiIiLRUYIpizoX5nDcQT14bt4aDZMTERERaQvM4Oy7YNi58NfvwOwpu1Q5akBXnr/hOCYfN5A//HMFZ9z+Gq++Xx5BsCIiItFRginLzhzZm7KNO5i7cmPUoYiIiIhINsTicP49MPhk+PMNsOCpXaoU5Mb5jzOH8fi1x1CYl+Dy+//Jtx9/h0071JtJRETaByWYsuy04T3Jjcd4dp6GyYmIiIi0GYk8uPhhKDkKnrgKFr/YYLUjDyzm2a8ey1dOHMwTs8s4/fZXeXpuGZXJVDMHLCIi0ryUYGqM7euDW9Wm07ut0ik/h+MP7sHz764hndYwOREREZE2I7cDfG4qHDAU/vAFWDG9wWr5OXG+PWEoT31lPMWFudz4h7mM/Z+X+P6fF/DeR5ubOWgREZHmoQRTYyx6Bv7xQ3jlx3usdtahvVmzqYI5Kzc0U2AiIiIi0iwKusAXnoTOfeGRi2DNvN1WHVnSmeduOI6HvjSGY4Z055HpK5hwx+uc+6s3eHj6h2zWZOAiItKGJKIOoFU58nJY9Ta89lPocQiMvKDBaqeUHkBuIhgmN6p/12YOUkRERESaVMcecNlTcP8EmPJZ+NJfofuQBqvGY8bxB/fg+KN/TvAAACAASURBVIN7sGFbFU/OKWPqzJX851Pz+dFzC5k4ojfjBnejX9dCSooL6N25gHjMmvkJiYiI7D+L4m5nZtYFuBcYATjwJeBfwGPAAGA5cJG7bzAzA+4EJgLbgUnuPntP5x89erTPnDmzaYJPVsFD50LZLLjiBSgZ1WC1qx+ayTurNjLt5lOIqZEgIiKSdWY2y91HRx2H1GnSNlhLtHYx3H8GpKqDHx4PuxRKRgd3ntsDd2feqk08NnMlf567mi2Vydp9iZjRp0sBJcUF9CsOkk5dO+bSuSBnl6UoP0fJKBERaVZ7an9FlWB6EHjd3e81s1ygEPgOsN7dbzWzm4Fid7/JzCYCXyVIMB0N3OnuR+/p/E3euNm2Fu45GZIVMPnloIt0PU/PLePGP8xl6jXjGDNQvZhERESyTQmmlqfdJZgAyv8Fr/4U3ns2aBt2HRwkmg69CIr77/XwqmSa1Rt3sGrDDlZu2M6qDdtZub5mfQflWyr3eHxRfqI24dQpPyMBVRg8dsxLkJuIkRuPBY/hkhdu5+fEKcyNU5iboDAvTmFOnERcs2iIiEjD9tT+avYhcmbWGTgemATg7lVAlZmdC5wYVnsQeAW4CTgXeMiDTNh0M+tiZr3dPbrbtHXoDp97DO49Df5wadCTKbfDTlVOLe1JXiLGc/NWK8EkIiIi0lb1OAQuuA8qNgfzdb7zB3j5R8HSfzwcdgkcdAZ0PKDBnk25iRgDundgQPcODZwcKqpTbNpRXbdsr955e0c1mzPWl67dWrteUb37G9PsSV4iVpt06piXoENenA55CYryE3TITdSt5yVIxAwzI2YQM8OMnbZrElt5iRh5OXFy4zHycsLtRIy8RJy8nCDRlZ+IkxMPziciIq1PFHMwDQTKgd+Z2WHALOBGoGdG0ugjoGe43hdYmXH8qrAsugQTwAGlQWPi0YvhyS/DhQ9CrO7Xng55CU4eegDPz/+I7549XN2XRURERNqy/E5wxBeCZeMKmPdYkGx65qvB/rxO0HUQdBsC3QYHj10HQ7dBkN9lt8Pq8nPi5OfE6dkpf9edNSMRdnNsZTLF1ookVak0VclgqUymd9reUZ1iR1WK7VUptlcl2VYZPG6vSrGtMsm2qiRbK5NsrkiyZlMF2yqTbK1IsrUqSVMMhDCD/DDplBf2tsqJBz2wcuI120ZOuJ2IBeuJuJGIBfsS4f7c+K6JrbrHOHtrnu8pz2Vh8iyIw8jJ6CVWE1duInhMxOtirknIiYi0RVEkmBLAkcBX3X2Gmd0J3JxZwd3dzBr1vywzuxq4GuDAAw/MVqx7dvAZcPqP4G//EdxZ7uT/2Gn3mYf25oX5H/H28vWMHdSteWISERERkWh1ORCO/3c47ltQNhvKZsK6xcGy6m2Y/wTBNKSZDCzW8IKDp3de0qm6c1gMYjkQz4FYovYxL5ZDXjwHEnnhkg/x3OAxET5ikKoM5hlNVkCqCpKVwZKqDJJYsThYHArj0DFY91icNDE8jNstBhhuFjwSw3FIVuPJSjxVc84qLFWFpSqxdIpkLJdULJek5VJtuVRbDlWWSzW5VJEg5ZByI1VtpKqMFEbKjWQa0g7uady9wSXtkNpNFqwaJ0GaOCkSpMghRZwUORZsx0mTIkaKGEmP160TJ0UcB1IkiZMkTYq0JUkRLDGSOGmqAccylmAbjJTFqSJBNQmSJKgih2oSVJNDkji5Vk0hlcFilRRSQb5XUEgFuVRTSS47rIAdls8O8tlhhcG6FVBpecH7StCjDDMMC4qIYeaYp4OFNDFPA07MU2GZ1z7LmKWJkabm3Y6RDj+rNc8peO+9tixGxh7MvOZTUntseFUcI2UxgivULEGsNT3hIHg0ap5Hzafea/4LtpzaVztW81h77TThpzPYsnjwjCx4VimLkyZB2mLhdSCGh6+fhxEF54/VvotpzGve2WC9Zk/N61H32sTCv4vM192D193TxEhh7mBG2mLB39dOS1BmpML3KEXMk5iniXlYRqr23xEP4635WwQLSsO6Ma/OWA8WB1KWIG05JC2HlCVIWQ6pWPAIECdFzNPESQafCU8T8yRx0jXvSHg9Mv4doO7fhfDN8tpXM+Nfv5pYLfj3xGreCIvVnc+Dz4CH73vNecj4fATvWc15rOaZ40DaM9YBD7djpEmEf+FxUsQ9+PuPeVDmlgjex1jwL0bNulscJ1b7uat7JHg/655c+DzqPR+r65xieEbCvuaFyjhH+Dda96KlwZ2EV5PwJDGvJuHVxNPVxLyKeDpJLF1N7rWvEovHaU5RJJhWAavcfUa4/ThBgunjmqFvZtYb+CTcXwb0yzi+JCzbibvfDdwNwfj/pgp+F+Oug/JFDd5Z7uShB1CQE+fZeauVYBIRERFpb8yCG8LUvylMshI2LA+TTkugatuuCaTMxWJ1X1J2WsIvDukkpKshVfNYHZYld00YJSugYlNGAikN8by6JFQ8D/I7h+u5wXXTqbqkVjoJnsLSKeI7JbySGV+C0uGXIw/OkZ8HiU7hdXLrHmMJ8moSW7XJrYow3q1B0quh5JqnIZ3O6GJUkzyp+8JJvS+xwZdSr/ty6h58SYwlwBLhej7E4ngsB7cY5unwuSYhHXyxN6+qfa7pWC7pWA4pK6j7Qm45JC34uhokutJ4Ol237o6nnRxPku9J4ukqYl5NPL2DePgFMe7VpCyHylgBVbECKmOd2GAFVMbyqbQCqsglxyvJS+8gL72dvPQOOqe3c0C6nPz0DnLSFcEX3Z2+EdV9+QXq0kVhMiRt8dpUjFu8NgmU9jDxU5MI8jDpE77XmUmWmAePYcol4xHSHqu9ehwnkZnECq8Wr61d8555mFDK/KJd9zZn/KHVFmVed6cYPHisSWPVJBfjYTIxHm57xslrPzs1ZU7GeWNhoiKIviaouuRaXUKu5jEdJuVStSVWe3xNoiIeJvxitfGla8+RmeRMh+mQZPiYzrg+XvOn4TslOpIkqKw9Lr7T8QYkrIIctpJLihySFJAkhyS5VNfGHRwXI+kxqmuPj9X8Fe70GljteuY7Vfeq1pXtekxduiojaVPv/DuV2c71d3fOhsprnxNxUh481jw3J5aRgAoeE1b3eYmHn/fMiDLTTbvGkpEA3fmTXe+zV/fvV936zs86jVFNgu1ek6CO1yaqqzxBFQlOSCXbfoLJ3T8ys5Vmdoi7/ws4BVgYLpcDt4aPT4eHPANcb2Z/IJjke1Ok8y/VZwZn3g7rlsJTX4HigbWNiMLcBCeXHsBf5n/E984ergkTRURERCRI3vQ4JFikSVm9RxHJnnTaSbnv9e+rtjda7XZdeZB8DXobpmvW08F60Esx7JMVdkyKhT2WzGr6ZgX10u5B7tnrjk27Bz3SzIIlFswPF49Z7Zxx6TQk02lSaSeZdpIp32k787klgVS9Ia41N00LEte1pbXr9ZPctete9zrUvU71trG616p2f12lZDpNMuVUpYLH6lR6p/VETu5e3pnsi6IHEwR3hXskvIPcUuAKIAZMNbMrgQ+Bi8K6zxPcQW4xsD2s27IkcuHiKcGd5aZeBjfMCRoOwFkje/PcvDX8c9l6jhnSPeJARURERERERPZfLGbE9jN9a2GiZ3/Ps3+at5dPWxZJgsnd5wIN3dbulAbqOnBdkwe1vzp0h7PvhCnnwbt/DCZ4BE485AAKc+M8++4aJZhEREREREREpE3SmK1sGnQi9BwBb/2qtn9cQW6cU0p78pf5H5FM7dutYkVEREREREREWjIlmLLJDMZdH0z6vfil2uIzR/Zm/bYqpi1dF2FwIiIiIiIiIiJNQwmmbBvxb1DUG6b9srboxEN60CE3znPzWs7c5CIiIiIiIiIi2aIEU7YlcuHoa2DpK/DRuwDk58Q5bVhP/rLgI6o1TE5ERERERERE2hglmJrCqEmQ0wGm/bq26MxD+7BxezVvLdEwORERERERERFpW5RgagoFxXDkZfDu47B5NQDHH9ydorwEf35ndcTBiYiIiIiIiIhklxJMTWXsteApmPF/AOQl4px5aG+enbeaDduqIg5ORERERERERCR7lGBqKsUDoPRsmPU7qNwKwJeOHUhFdZpHZnwYbWwiIiIiIiIiIlmkBFNTOuYGqNgEcx4G4OCeRRx/cA8enPYhlclUxMGJiIiIiIiIiGSHEkxNqWQ09BsL038D6SChNPm4gZRvqeSZuZqLSURERERERETaBiWYmtox18PGD2HRnwE4dkh3hvYq4r43luHuEQcnIiIibYGZnZyxPrDevvObPyIRERFpb5RgamqHTITigfDWL8EdM+PKYwfy3kdbeGPx2qijExERkbbhtoz1J+rt+8/mDERERETaJyWYmlosDuOug7KZsHIGAOcc3oceRXnc+/qyiIMTERGRNsJ2s97QtoiIiEjWKcHUHA7/HOR3CXoxAXmJOJeP68+r75fz/sdbIg5ORERE2gDfzXpD2yIiIiJZt8cEk5l9IWN9fL191zdVUG1Obgc46ip47zlYtwSAzx/dn/ycGPepF5OIiIjsv0Fm9oyZ/TljvWZ74N4OFhEREdlfe+vB9I2M9V/W2/elLMfSto25GuI5wR3lgOIOuVwwqoQn55RRvqUy4uBERESklTsX+DnBXEw16zXb50UYl4iIiLQTe0swaTx/thT1hJEXwZxHYPt6AL40fiDV6TRTpn8YcXAiIiLSmrn7q5kL8BawGVgUbouIiIg0qb0lmDSeP5uOuR6SO2DmfQAM6tGRU4b25OHpH1JRnYo4OBEREWmtzOy3ZjY8XO8MvAM8BMwxs0sjDU5ERETahb0lmIaa2TwzezdjvWb7kGaIr205oBSGnAoz7oZkMCxu8nEDWb+tij/NLos4OBEREWnFjnP3BeH6FcD77j4SGAV8e08Hmtn9ZvaJmc3PKPuemZWZ2dxwmdh0oYuIiEhbsLcEUylwNnBWxnrN9rCmDa2NGnc9bPsE5k0FYMzArozs25l731hKOq1OYSIiIrJPqjLWTwOeAnD3jz7FsQ8AExoov93dDw+X5/c/RBEREWnL9phgcvcPMxdgK3Ak0D3clsYadCL0HAnTfgXumBlXHTeQpeXbeOX9T6KOTkRERFqnjWZ2lpkdAYwH/gJgZgmgYE8HuvtrwPqmD1FERETasj0mmMzsWTMbEa73BuYT3D1uipl9rRnia3vMgrmYyt+DxS8CMHFkb3p3zuee15ZFHJyIiIi0UtcA1wO/A76W0XPpFOC5fTzn9eHUCPebWXE2ghQREZG2a29D5Aa6e814/CuAv7v72cDRBIkm2RfDz4eiPvDWLwHIice4YvwApi1dx/yyTREHJyIiIq2Nu7/v7hPC4WwPZJT/1d2/uQ+n/F9gMHA4sAb4+e4qmtnVZjbTzGaWl5fvw6VERESkLdhbgqk6Y/0U4HkAd98CpJsqqDYvkQtHXwPLXoU18wC4ZMyBdMxL8Kt/LI44OBEREWltzOyuPS2NPZ+7f+zuKXdPA/cAY/ZQ9253H+3uo3v06LE/T0NERERasb0lmFaa2VfN7LMEcy/VjOcvAHKaOrg2bdQkyO0YzMUEdMrP4erjB/GXBR8xY+m6aGMTERGR1ubLwLHAamAmMKve0ijh1Ag1PkswTYKIiIjIbu0twXQlMByYBFzs7hvD8rEEY/xlXxV0gSO/CPOfgE1lAEw+bhB9Oufzw+cW6o5yIiIi0hi9gbuBM4DLCH4IfNrdH3T3B/d0oJn9HpgGHGJmq8zsSuCnZvaumc0DTgK+3rThi4iISGu3t7vIfeLuX3b3c939bxnlL7v7bU0fXht39JfB0zDjtwAU5Ma56TNDmV+2mSdmr4o4OBEREWkt3H2du//W3U8imDezC7DQzC77FMde6u693T3H3Uvc/T53v8zdR7r7oe5+jruvafInISIiIq1aYk87zeyZPe1393OyG047U9wfhp0Hsx6A4/8d8jtxzmF9+N2by/npX//FxJG96ZC3x7dIREREpJaZHQlcCpwGvMA+DI8TERER2Rd7GyI3DigBXgduI7iDSOYi++uY66FyM8yZAoCZ8d2zh1G+pZLfvrok4uBERESkNTCzH5jZLOAbwKvAaHe/0t0XRhyaiIiItBN7SzD1Ar4DjADuJPg1bK27v+rurzZ1cO1C31HQfzxM/19IJQE48sBizjmsD3e/tpSyjTsiDlBERERagf8kGBZ3GPBjYLaZzcuYR0lERESkSe1tDqaUu//F3S8nmNh7MfCKmV3fLNG1F+Ouh00rYeFTtUU3fWYoAD954b2oohIREZHWYyBwMnBWuJwdLjXrIiIiIk1qbz2YMLM8MzsfeBi4DrgLeLKpA2tXDp4A3YbAW78ED+4e17dLAVcfP4hn3lnN7BUbIg5QREREWjJ3/7ChBVgJHBt1fCIiItL27THBZGYPEdy29kjg++5+lLv/0N3LmiW69iIWg3HXwZq58OGbtcVfPmEwBxTl8YM/L8TDxJOIiIhIfWbWycz+n5n9ysxOt8BXgaXARVHHJyIiIm3f3nowfQE4CLgReMvMNofLFjPb3PThtSOHXQqF3eDNu2qLOuQl+NYZhzB35UaeeWd1hMGJiIhICzcFOAR4F7gKeBm4ADjP3c+NMjARERFpH/Y2B1PM3YvCpVPGUuTunZoryHYhpwDGXAMf/BU+rrvhywVHljC8Tyd+8sJ77KhKRRigiIiItGCD3H2Su/8fcCkwDDjD3edGHJeIiIi0E3udg0ma0ZjJkFMIb95ZWxSLGd89axirN1Vw7+tLIwxOREREWrDqmhV3TwGr3L0iwnhERESknVGCqSUp7ApHXg7zH4eNK2uLjx7UjQnDe/GbV5bw8Wa1FUVERGQXh2VOZQAcqmkNREREpDkpwdTSjLsueJz+m52KvzOxlJQ7//nUfE34LSIiIjtx93i9qQwSmtZAREREmpMSTC1Nl34w4gKY9SBsX19bfGC3Qr51+sH8feHHPD1XE36LiIiIiIiISMuhBFNLNP5GqN4Gb9+7U/GVxw7iyAO7cMszCzRUTkRERERERERaDCWYWqKew+CgM2DGb6Fqe21xPGbcduFhVFSn+M6f3tVQORERERERERFpEZRgaqmO/RpsXwdzH9mpeFCPjnx7wlBeeu8TnphdFlFwIiIiIiIiIiJ1lGBqqQ4cByVj4K27IJXcadcVxwxgzICufP/PC1izaUdEAYqIiIiIiIiIBJRgaqnMgl5MG1fAwqd22hWLGT+94FCSKefmJzRUTkRERERERESipQRTS3bwZ6D7IfDGHVAviTSgewdu/sxQXn2/nKkzV0YUoIiIiIiIiIhIhAkmM4ub2RwzezbcHmhmM8xssZk9Zma5YXleuL043D8gqpibXSwG42+Aj9+FJS/tsvuysf0ZO6grP3x2EWUbNVRORERERERERKIRZQ+mG4FFGds/AW539yHABuDKsPxKYENYfntYr/0YeREU9Ql6MdUTixk/u+Aw0u7c9Pg8DZUTERERERERkUhEkmAysxLgTODecNuAk4HHwyoPAueF6+eG24T7Twnrtw+JXBj3FVj+OpTN2mV3v66F/L+JpbyxeC2P/nNFBAGKiIiIiIiISHsXVQ+mO4BvA+lwuxuw0d1rbpe2CugbrvcFVgKE+zeF9duPUZMgv3ODvZgAPj/mQMYP6cZ/P7eIhas3N29sIiIiIiIiItLuNXuCyczOAj5x91274+zfea82s5lmNrO8vDybp45eXhEcdRUs+jOs/WCX3cFd5Q6jc0EOl9w9jbkrN0YQpIiIiIiIiIi0V1H0YBoPnGNmy4E/EAyNuxPoYmaJsE4JUBaulwH9AML9nYF19U/q7ne7+2h3H92jR4+mfQZROPrLkNsRnvoKpKp32d23SwFTrxlHl8JcvnDvDP65bH0EQYqIiIiIiIhIe9TsCSZ3/3/uXuLuA4BLgH+4++eBl4ELwmqXA0+H68+E24T7/+HtcTbrjgfAOXfCqn/CS99vsEq/roVMvWYcPTvl8cX7Z/D6B22sJ5eIiIiIiIiItEhR3kWuvpuAb5jZYoI5lu4Ly+8DuoXl3wBujii+6I34Nxh9Jbz1S/jXCw1W6dU5n8euGceAbh248oGZvLjw42YOUkRERERERETam0gTTO7+irufFa4vdfcx7j7E3S9098qwvCLcHhLuXxplzJE743+g16Hw5JdhY8N3jeveMY8/XD2W0t5FfPnhWTw7b3UzBykiIiIiIiIi7UlL6sEkn0ZOPlz0IHga/jgJklUNVutSmMvDVx3NEQd24Ybfz+HxWauaN04RERERERERaTeUYGqNug6Cc38FZbPgxe/ttlpRfg4PfmkMxwzuzrf++A4PvrWc9jh9lYiIiIiIiIg0LSWYWqth58KYa2D6r2HRs7utVpib4N7LR3Nq6QHc8swCzvvNW7y5eG0zBioiIiIiIiIibZ0STK3Z6T+EPkfAU1+BDct3Wy0/J85vvzCKn15wKGu3VPL5e2fwuXumM3vFhuaLVURERERERETaLCWYWrNEHlz4QLD+x0mQrNx91XiMi0b34x/fOoHvnT2M9z/ewvm/eYurHpzJojWbmyVcEREREREREWmblGBq7YoHwHm/htVz4G//tdfqeYk4k8YP5NV/P4l/P+MQ/rlsHRPvep0bfj+H+WWbqE6lmz5mEREREREREWlTElEHIFlQejaM/QpM/w18shCO/RoMPgXMdntIh7wE1500hC8c3Z//e20Jv3tzOc+8s5rcRIyhvYoY3qcTw3p3YlifzpT2LqIwVx8VEREREREREWmYsgZtxWk/gE59Ydqv4OF/g14jYfzXYNh5EN/929y5MIdvTxjKl44dyBsfrGXB6k0sWL2Z59/9iN//cyUAMYOB3TswuEdH+nQpoG+XAvp0KaBPl3z6dCmgR8c8YrHdJ7NEREREREREpG2ztnjb+tGjR/vMmTOjDiMayUqYNxXevBPWfRAMoRt3PRzxBcgp+NSncXfKNu5gwerNLFy9mQWrN/Phum2s3riDbVWpnermxI1enfPp1Smfnp3qHnt2zqdnUR69Ogfb+TnxLD9ZERFpz8xslruPjjoOqdOu22AiIiLtwJ7aX0owtVXpNPzreXjzDlj1NhR2h9FXQMlRQe+mot57HEK3O+7O5ookqzfu+P/t3X2MZXd93/H395x752F3/Qgb4/oB48QNuGkw1EJQ04gHJYIE1UilNDShFkJy/3AlkFI1TtQKNVIkqkqhrYrSWOBiFJJACS5WhFKoS6GoCmDAwTYGxVhQ27K9gM16d+fhPpxv/zi/mbm73p2dvWd37p31+yUdn98598w9v/nOnPFvPvs7Z7aWw2s88ewqTz+3xtPPrfHUc2usDZ//LKfFXsVFy/3nLRcu97l4X59L9y9wyb6FzfWLDixw8b4+iz2DKUnS8xkwnT0RcSfwNuBQZv5C2Xcp8EngGuAHwDszc9s/QesYTJKk89t24y9vkTtfVRW84m3w8l+DH/5f+MqH4Mv/fuv15UvboOklfxcu+4V2fem17SynbYKniNgMhl5x+YUnPWYjhNoMnA6vcejIOodXhxxeGbbr1SFPHl7ju08d4bnVIUfWR6c854HFHpfs7/PiA4sTy8Jx7QuX+yz1axZ7FYu9arPdq32OvSRJO/Ax4D8DH5/Ydztwb2Z+MCJuL9u/PYO+SZKkPcCA6XwXAdfc1C5rz8HTD8HTD8JT34anHoSvfwRGaxPH17BwABYPTKz3w8IFbfjUW4LeQruuF6C3WJal9vili4ili7ioLH/7b10E174E6v623RyNG55dGfLsyoBnjg149tiAZ1bK+tiQnxxb5ydHBzz2zArf+n/P8syxAc0OJt/VVbDUq1heqNm/2GPfQo/9pb1/sd7cPrDUY/9ijwsW2/WBjaXs37dQs9yvN4OrmGL2lyRJ8yozvxwR15yw+2bgDaV9F/C/MWCSJEmnYMD0QrJ0Ibz0de2yYTyCZ74PTz0Ahx+D9aMwOFrWR7a2j/0ERqvtM55G6zAetMHUeLCzc/eWS1BVlv6+49q9/jIHqx4HqxqqXht0VVXb3lfDBf02xCohV9Nb4ui4x+FRj58Oao6Oa9aaHutZsTquWWva9UpTsTKqWB01rK0PWVkfsDYYsnpsxE+eGfLEcMTq+pCfDiqeaxZYYwHYPjyKgOX+VuC0vBk+tTOnlvpb25PH7FuoWV7osa+/0W4Drn4dVFGWis12XbUzxqoIelVQVUFdjqkjqKt2WerX9J2pJUk6+y7LzCdL+yngsll2RpIkzTcDphe6ugcHf75dppG5FTatH4W1wydf1g/D4BgMVtrAarjSbq88A8NjMFyFZgTNGHLcrjfbI8jjn+lUAReW5aquNQBYKJ8OQfaXaeplRr1lRtUyw2qJUfQY0WNIzZAeg2zb61kzaGqG68FwtWKQwXoTDJuK9SYYjGHQwLCBVYIV4McZW+faQdfG1KzTY0B/89ybbXpUNPQClnuwWCdLNSz2YKmGhRp6dU2vrqmrmrpXb273ezVV3WNcL5H1EuPeEtlbIutlmt4S9JaoK1hiwGIOWGCdRQb0mwELuU6fAdFbpOkfIBcuIBcO0CxcQC7sp6r7m4FZXYKxjUCsmmhPfhu1NTm+Isd9XFWCtrKvV4UzySRpl2RmRsRJ/7cVEbcCtwJcffXVu9ovSZI0PwyY1E3E1m1ySxfBRVecm/M04zbEGq61M6k212UZD2A8PH7dDLfaAFFNLLHVBhgNYHiMGKwQwxWq4Qq94Wobgk2+fzOE8erx52IIjIFRG4jRtG3GECOoGqh26WH6TVmGu3O6U1nJRY6xxJi2vpNhWhI0BA0QJBVJRUMAQUNVjt5YtwvlHZIkGZOMCMZUjKlpqBhR0VDRRLtvYyZabP4HYqtBEoypN99jXD5+o020R0dEaUf7eLLY6mkTFU05fzNx/iToMaYXDb3Sw15555oxRMUo+oxigVG1wDj6DGOBcdXuCfbqmgAAESdJREFUy2hvw2zPWc5fzhtVbNajAiK26rPRvYyaJuqy7pFRk9Ejq5qkar8C2bRfjWwgm/bjs2lrVfWJqgdVj6g31n2oelSRRDMmsq0cOaYq25HjzWsrNq4xqnY2YlQQlGNHRDPaXFfNqP3YbGiqBZp6kaZeaNvVQmkvQlVTZfkKZfsV6222x1tf8Y3gMYKI9jusrUvbj6SsS02z9LWKiqpqP6auaqq6bVdVRVXes9n8Xm7P02TZjoqqqolybFXX7b66po62Bhvf6U1UZFbk5r6qfA4jes2IKofUOaTOEbHxcyfq9rbkuj+xLu2qD2QbxGce394I5ze/Hhs/+ya3Y+siOZnTBbnjwcTs1vWt9sb2tW88d/9v0Ln2dERcnplPRsTlwKGTHZSZdwB3QPuQ793soCRJmh8GTNobqnrrlrq9bHOqzsYvgbn9L2+Z7Qyu8XobZm38wrbZHrYfX9Xll8a6tMsthsTWeTZ+2dxYSBgPaQarNMMVmsEqOVylGbShXTNYoSEYV4uM6kVG0a6HsbEskOMB1fAo1eAo1eAI1fAY9fAI9eAo1fAYWX7JzWxKF3JrIYGq/aW//JK70c7NEKf9Bb5JyNhqN0A22QZ6Od4MPJgIOjbPx+S6zJLKEmJlc3y0lGN6NCzkuJS/7StM9Lk9Of3nR0sl/Gh/oR9RMyqB1SgrBtQMsz1bMGKBNfo5ZD8D+oxYYMgCQ/oMy3uUGCOPD9jKV5QT906GeHXpWz/GZ+O79pxqMhhSM6ImibYOe6Df2rnv//Kd/OxN/2jW3dB07gFuAT5Y1p+dbXckSdI8M2CSdtPEzIodq3vQXzo3/aG93dAnOO1NmdkGbpk0mW0emUkDjBMGJdyjGZHjITRjMsdE1MfN4ovNgLKiyYZmNGQ0GtKMRozHQ8bDIc14yHg0aGf/VG2ERdXOksqNNVUJ8RpoGrJp55vRJE0zbgO6qMmqV5b+1ixCJvLWbKjGA6rxOtEM2nYzgPGIcdSM6DEmaKgZUjPOilGWGUkboeZksEpC07SzvTZnbrWBaxVlpk/TkNkwbpKmaTaXcdO0NRk3VFEivYAqs8122Yj5yuebDdmM269NMy71b9+7Jqlp+1FlQxUbM/jG5XPpMaJmQI9R9hhGr70VtmlnOEWOqJt2dlOVI6qNdjMqM6s2etLWdHNfwmbQTANJG8hCmcG2NeHk+VNP8oS5TVtb7dcqGdJjjR7rTZ/V7LGaPdaaPivZY62p+ecveR2afxHxp7QP9H5xRDwOfIA2WPpURLwX+CHwztn1UJIkzTsDJknaoyKCOqA+zYPpYfEM33l52i5J2qMy812neOnNu9oRSZK0ZzlxQZIkSZIkSZ0YMEmSJEmSJKkTAyZJkiRJkiR1YsAkSZIkSZKkTgyYJEmSJEmS1IkBkyRJkiRJkjoxYJIkSZIkSVInBkySJEmSJEnqxIBJkiRJkiRJnRgwSZIkSZIkqRMDJkmSJEmSJHViwCRJkiRJkqRODJgkSZIkSZLUiQGTJEmSJEmSOjFgkiRJkiRJUicGTJIkSZIkSerEgEmSJEmSJEmdGDBJkiRJkiSpEwMmSZIkSZIkdWLAJEmSJEmSpE4MmCRJkiRJktSJAZMkSZIkSZI6MWCSJEmSJElSJwZMkiRJkiRJ6sSASZIkSZIkSZ0YMEmSJEmSJKkTAyZJkiRJkiR1YsAkSZIkSZKkTnY9YIqIqyLiixHxnYh4KCLeV/ZfGhFfiIi/KetLyv6IiP8UEY9ExLcj4tW73WdJkiRJkiSd2ixmMI2A38rM64HXArdFxPXA7cC9mXkdcG/ZBngrcF1ZbgX+cPe7LEmSJEmSpFPZ9YApM5/MzG+W9hHgYeAK4GbgrnLYXcDbS/tm4OPZ+ivg4oi4fJe7LUmSJEmSpFOY6TOYIuIa4FXAV4HLMvPJ8tJTwGWlfQXw2MSHPV72nfhet0bEfRFx349+9KNz1mdJkiRJkiQdb2YBU0QcAP4ceH9mPjf5WmYmkGfyfpl5R2bemJk3Hjx48Cz2VJIkSZIkSduZScAUEX3acOkTmfmZsvvpjVvfyvpQ2f8EcNXEh19Z9kmSJEmSJGkOzOKvyAXwUeDhzPyDiZfuAW4p7VuAz07s/2flr8m9Fjg8cSudJEmSJEmSZqw3g3PeBLwbeCAi7i/7fhf4IPCpiHgv8EPgneW1zwG/CjwCrADv2d3uSpIkSZIkaTu7HjBl5leAOMXLbz7J8Qncdk47JUmSJEmSpKnNYgaTJEmS9oCI+AFwBBgDo8y8cbY9kiRJ88qASZIkSdt5Y2b+eNadkCRJ820mf0VOkiRJkiRJ5w8DJkmSJJ1KAp+PiG9ExK2z7owkSZpf3iInSZKkU3l9Zj4RET8DfCEivpuZX548oARPtwJcffXVs+ijJEmaA85gkiRJ0kll5hNlfQi4G3jNSY65IzNvzMwbDx48uNtdlCRJc8KASZIkSc8TEfsj4oKNNvArwIOz7ZUkSZpX3iInSZKkk7kMuDsioB0z/klm/uVsuyRJkuaVAZMkSZKeJzMfBV45635IkqS9wVvkJEmSJEmS1IkBkyRJkiRJkjoxYJIkSZIkSVInBkySJEmSJEnqxIBJkiRJkiRJnRgwSZIkSZIkqRMDJkmSJEmSJHViwCRJkiRJkqRODJgkSZIkSZLUiQGTJEmSJEmSOjFgkiRJkiRJUicGTJIkSZIkSerEgEmSJEmSJEmdGDBJkiRJkiSpEwMmSZIkSZIkdWLAJEmSJEmSpE4MmCRJkiRJktSJAZMkSZIkSZI6MWCSJEmSJElSJwZMkiRJkiRJ6sSASZIkSZIkSZ0YMEmSJEmSJKkTAyZJkiRJkiR1YsAkSZIkSZKkTgyYJEmSJEmS1IkBkyRJkiRJkjoxYJIkSZIkSVInBkySJEmSJEnqxIBJkiRJkiRJnRgwSZIkSZIkqRMDJkmSJEmSJHViwCRJkiRJkqRODJgkSZIkSZLUiQGTJEmSJEmSOjFgkiRJkiRJUicGTJIkSZIkSepkzwRMEfGWiPheRDwSEbfPuj+SJEnnO8dfkiRpp/ZEwBQRNfBh4K3A9cC7IuL62fZKkiTp/OX4S5IknYk9ETABrwEeycxHM3MA/Blw84z7JEmSdD5z/CVJknZsrwRMVwCPTWw/XvZJkiTp3HD8JUmSdqw36w6cLRFxK3Br2TwaEd87R6d6MfDjc/Te5ztrNx3rNh3rNh3rNh3rNp2udXvp2eqIpucYbO5Zt+lYt+lZu+lYt+lYt+l0qdspx197JWB6ArhqYvvKsm9TZt4B3HGuOxIR92Xmjef6POcjazcd6zYd6zYd6zYd6zYd6zb3Tjv+Asdg8866Tce6Tc/aTce6Tce6Tedc1W2v3CL3deC6iHhZRCwAvw7cM+M+SZIknc8cf0mSpB3bEzOYMnMUEf8C+B9ADdyZmQ/NuFuSJEnnLcdfkiTpTOyJgAkgMz8HfG7W/WAXpoCfx6zddKzbdKzbdKzbdKzbdKzbnJuj8Rf4/TIt6zYd6zY9azcd6zYd6zadc1K3yMxz8b6SJEmSJEl6gdgrz2CSJEmSJEnSnDJgOgMR8ZaI+F5EPBIRt8+6P/MqIu6MiEMR8eDEvksj4gsR8Tdlfcks+ziPIuKqiPhiRHwnIh6KiPeV/dZuGxGxFBFfi4i/LnX7t2X/yyLiq+V6/WR5QK1OEBF1RHwrIv6ibFu3HYiIH0TEAxFxf0TcV/Z5rZ5GRFwcEZ+OiO9GxMMR8Trrpp1wDLYzjsGm4xhsOo7BunEMduYcf01vt8ZgBkw7FBE18GHgrcD1wLsi4vrZ9mpufQx4ywn7bgfuzczrgHvLto43An4rM68HXgvcVr7HrN321oE3ZeYrgRuAt0TEa4F/B3woM38OeBZ47wz7OM/eBzw8sW3ddu6NmXnDxJ949Vo9vf8I/GVmvhx4Je33nnXTthyDnZGP4RhsGo7BpuMYrBvHYNNx/DWdXRmDGTDt3GuARzLz0cwcAH8G3DzjPs2lzPwy8MwJu28G7irtu4C372qn9oDMfDIzv1naR2gv+iuwdtvK1tGy2S9LAm8CPl32W7eTiIgrgV8DPlK2A+vWhdfqNiLiIuCXgI8CZOYgM3+KddPpOQbbIcdg03EMNh3HYNNzDHZWeZ2exm6OwQyYdu4K4LGJ7cfLPu3MZZn5ZGk/BVw2y87Mu4i4BngV8FWs3WmVKcb3A4eALwDfB36amaNyiNfryf0H4F8BTdl+EdZtpxL4fER8IyJuLfu8Vrf3MuBHwH8ttwR8JCL2Y910eo7BuvEaOwOOwc6MY7CpOQabjuOv6ezaGMyASbsu2z9d6J8vPIWIOAD8OfD+zHxu8jVrd3KZOc7MG4Araf+l++Uz7tLci4i3AYcy8xuz7sse9frMfDXtLTu3RcQvTb7otXpSPeDVwB9m5quAY5wwFdu6SeeW19j2HIOdOcdgZ84xWCeOv6aza2MwA6adewK4amL7yrJPO/N0RFwOUNaHZtyfuRQRfdqBzScy8zNlt7XboTLV84vA64CLI6JXXvJ6fb6bgH8YET+gvd3kTbT3Zlu3HcjMJ8r6EHA37aDaa3V7jwOPZ+ZXy/anaQc71k2n4xisG6+xHXAM1o1jsDPiGGxKjr+mtmtjMAOmnfs6cF15uv8C8OvAPTPu015yD3BLad8CfHaGfZlL5d7rjwIPZ+YfTLxk7bYREQcj4uLSXgZ+mfbZCV8E3lEOs24nyMzfycwrM/Ma2p9n/yszfwPrdloRsT8iLthoA78CPIjX6rYy8yngsYj4+bLrzcB3sG46Pcdg3XiNnYZjsOk4BpuOY7DpOP6a3m6OwaKdCaWdiIhfpb1ftgbuzMzfn3GX5lJE/CnwBuDFwNPAB4D/DnwKuBr4IfDOzDzxIZQvaBHxeuD/AA+wdT/279I+A8DanUJE/CLtQ+lq2tD8U5n5exFxLe2/Cl0KfAv4zcxcn11P51dEvAH4l5n5Nut2eqVGd5fNHvAnmfn7EfEivFa3FRE30D7QdAF4FHgP5brFumkbjsF2xjHYdByDTccxWHeOwXbO8Vc3uzUGM2CSJEmSJElSJ94iJ0mSJEmSpE4MmCRJkiRJktSJAZMkSZIkSZI6MWCSJEmSJElSJwZMkiRJkiRJ6sSASdILQkS8ISL+Ytb9kCRJeiFxDCa9cBgwSZIkSZIkqRMDJklzJSJ+MyK+FhH3R8QfRUQdEUcj4kMR8VBE3BsRB8uxN0TEX0XEtyPi7oi4pOz/uYj4nxHx1xHxzYj42fL2ByLi0xHx3Yj4RETEzD5RSZKkOeIYTFJXBkyS5kZEvAL4J8BNmXkDMAZ+A9gP3JeZfwf4EvCB8iEfB347M38ReGBi/yeAD2fmK4G/DzxZ9r8KeD9wPXAtcNM5/6QkSZLmnGMwSWdDb9YdkKQJbwb+HvD18g9by8AhoAE+WY75Y+AzEXERcHFmfqnsvwv4bxFxAXBFZt4NkJlrAOX9vpaZj5ft+4FrgK+c+09LkiRprjkGk9SZAZOkeRLAXZn5O8ftjPg3JxyXU77/+kR7jD8DJUmSwDGYpLPAW+QkzZN7gXdExM8ARMSlEfFS2p9V7yjH/FPgK5l5GHg2Iv5B2f9u4EuZeQR4PCLeXt5jMSL27epnIUmStLc4BpPUmcmxpLmRmd+JiH8NfD4iKmAI3AYcA15TXjtE+4wAgFuA/1IGL48C7yn73w38UUT8XnmPf7yLn4YkSdKe4hhM0tkQmdPOcpSk3RERRzPzwKz7IUmS9ELiGEzSmfAWOUmSJEmSJHXiDCZJkiRJkiR14gwmSZIkSZIkdWLAJEmSJEmSpE4MmCRJkiRJktSJAZMkSZIkSZI6MWCSJEmSJElSJwZMkiRJkiRJ6uT/Az5/GsII/nK8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
        "    \"\"\"\n",
        "    Train and evaluate the data for num-folds times, and return the average \n",
        "    training and validation loss. First the data is split in num-folds batches\n",
        "    and then the model is trained on the data, where a different batch is the \n",
        "    validation data each time.\n",
        "    \"\"\"\n",
        "    # Create kfold object to later split the data\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "    x_indices = np.array(range(len(x_tabular)))\n",
        "    y_indices = np.array(range(len(y)))\n",
        "\n",
        "    # Pre allocate variables to store the MSE (loss) and RMSE (accuracy)\n",
        "    train_loss = np.array(np.zeros(epochs))\n",
        "    train_acc = np.array(np.zeros(epochs))\n",
        "    val_loss = np.array(np.zeros(epochs))\n",
        "    val_acc = np.array(np.zeros(epochs))\n",
        "    \n",
        "    # Train and evaluate the model for num-fold times on a different training \n",
        "    # and validation set each time\n",
        "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
        "        \n",
        "        # Make Neural Networks before concatenation\n",
        "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "        image_size = (64, 64, 3)\n",
        "        image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "\n",
        "        # Create subset training and validation data\n",
        "        x_tabular_train = x_tabular[id_train]\n",
        "        x_imgs_train = x_imgs[id_train]\n",
        "        y_train = y[id_train]\n",
        "        \n",
        "        x_tabular_val = x_tabular[id_val]\n",
        "        x_imgs_val = x_imgs[id_val]\n",
        "        y_val_2 = y[id_val]\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
        "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
        "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs, preprocess=preprocess, augment=augment)\n",
        "\n",
        "        # Add all the losses and metrics\n",
        "        train_loss += history.history['loss']\n",
        "        train_acc += history.history['root_mean_squared_error']\n",
        "        val_loss += history.history['val_loss']\n",
        "        val_acc += history.history['val_root_mean_squared_error']\n",
        "\n",
        "    # Calculate average loss and metric\n",
        "    avg_train_loss = train_loss / num_folds\n",
        "    avg_val_loss = val_loss / num_folds\n",
        "    avg_train_acc = train_acc / num_folds\n",
        "    avg_val_acc = val_acc / num_folds\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Plot MSE\n",
        "    axs[0].plot(avg_train_loss)\n",
        "    axs[0].plot(avg_val_loss)\n",
        "    axs[0].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[0].set_title('Model MSE')\n",
        "    axs[0].set_ylabel('MSE')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "    axs[0].set_ylim([0, 1000])\n",
        "\n",
        "    # Plot RMSE\n",
        "    axs[1].plot(avg_train_acc)\n",
        "    axs[1].plot(avg_val_acc)\n",
        "    axs[1].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[1].set_title('Model RMSE')\n",
        "    axs[1].set_ylabel('RMSE')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    axs[1].set_ylim([0, 30])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return avg_train_loss[-1], avg_val_loss[-1], avg_train_acc[-1], avg_val_acc[-1]\n",
        "\n",
        "# Use k-fold cross-validation to train and evaluate concatenated network\n",
        "avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc = k_fold(5, x_tabular, y, x_images, epochs=60, \n",
        "                                               preprocess={'featurewise_center': True, 'featurewise_std_normalization': True})\n",
        "\n",
        "print(f'The train MSE is {avg_train_loss}')\n",
        "print(f'The train RMSE is {avg_train_acc}')\n",
        "print(f'The validation MSE is {avg_val_loss}')\n",
        "print(f'The validation RMSE is {avg_val_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9-K3Mgs8weVG",
      "metadata": {
        "id": "9-K3Mgs8weVG"
      },
      "outputs": [],
      "source": [
        "# Create overview of layers in model\n",
        "tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32273205",
      "metadata": {
        "id": "32273205"
      },
      "source": [
        "# Plot predictions\n",
        "We will plot the predictions of the model to see how the predictions are distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UiMunH5vM8wU",
      "metadata": {
        "id": "UiMunH5vM8wU"
      },
      "outputs": [],
      "source": [
        "# Get model predictions and compute difference and squared difference\n",
        "predictions = concat_model.predict([train_imgs_array, x_train_tabular])\n",
        "difference = np.subtract(predictions, y_train)\n",
        "squared_difference = np.square(difference)\n",
        "\n",
        "# Create histogram of squared difference\n",
        "plt.hist(squared_difference)\n",
        "plt.title('Distribution of squared error of the model')\n",
        "plt.xlabel('Squared error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim([0, 4500])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b62527",
      "metadata": {
        "id": "67b62527"
      },
      "outputs": [],
      "source": [
        "# Create histogram of difference\n",
        "plt.hist(difference)\n",
        "plt.title('Distribution of squared error of the model')\n",
        "plt.xlabel('Squared error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chapter_9_Remove_outliers_K_fold.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}