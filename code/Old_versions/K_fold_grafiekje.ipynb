{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3915ca73",
      "metadata": {
        "id": "3915ca73"
      },
      "source": [
        "# Linear output\n",
        "In this chapter we will limit the linear output between 0 and 100, so the model will be more realistic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "vRjBTUzjlmKA",
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras import backend as K\n",
        "from keras import activations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFZWcvRBvYv_",
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fANqjfPxoHI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "f6befdda-4a7b-47cb-e5f6-d7e8c652dc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 12:11:40--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-25 12:11:40--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [                <=> ] 993.18M  23.0MB/s    in 45s     \n",
            "\n",
            "2022-01-25 12:12:25 (22.1 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1041430087]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ae10a3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8ae10a3a",
        "outputId": "8c66a8ad-7223-47c4-eac1-54dc19a00102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fabc05d5-9a9a-4f5b-8aad-9341989ec3b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fabc05d5-9a9a-4f5b-8aad-9341989ec3b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fabc05d5-9a9a-4f5b-8aad-9341989ec3b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fabc05d5-9a9a-4f5b-8aad-9341989ec3b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "SRYM1P29o8k1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "2360c558-47fa-4b8d-fd66-ffb830e88e55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99"
      },
      "outputs": [],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)\n",
        "\n",
        "# train_data_sorted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select x-values (the 12 input features) and y-values from training data\n",
        "x_tabular = train_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y = train_data_sorted.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
        "\n",
        "# Create numpy array of image data \n",
        "x_images = np.array(train_imgs)\n",
        "test_imgs_array = np.array(test_imgs)"
      ],
      "metadata": {
        "id": "Agl1YxFwNcKo"
      },
      "id": "Agl1YxFwNcKo",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "RNE8NWL7xgmp",
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99"
      },
      "outputs": [],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create neural network for tabular data and get summary of model \n",
        "# with 12 inputs and 100 hidden nodes\n",
        "tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "# tabular_NN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7adc6959",
      "metadata": {
        "id": "7adc6959"
      },
      "outputs": [],
      "source": [
        "# Create neural network for image data and get summary of model\n",
        "image_size = (64, 64, 3)\n",
        "image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "# image_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtZpIRuAue4B",
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ZKkweNdcNXLl",
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "outputs": [],
      "source": [
        "def linear_limit(x):\n",
        "    \"\"\"\n",
        "    Create a linear activation function that clips the output at 0 and 100.\n",
        "    \"\"\"\n",
        "    activation_x = activations.linear(x)\n",
        "    activation_x_new = K.clip(activation_x, 0, 100)\n",
        "\n",
        "    return activation_x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "DZ58i65PvawJ",
      "metadata": {
        "id": "DZ58i65PvawJ"
      },
      "outputs": [],
      "source": [
        "# Part of code from: https://www.tensorflow.org/tutorials/keras/regression\n",
        "\n",
        "def plot_loss(history):\n",
        "    \"\"\"\n",
        "    Plot loss during epochs of training a neural network.\n",
        "    \"\"\"\n",
        "    \n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Set y-limits for MSE (0, 1000) and RMSE (0, 30)\n",
        "    ylimits = [[0, 1000], [0,30]]\n",
        "\n",
        "    for i, metric in enumerate(['loss', 'root_mean_squared_error']):\n",
        "        axs[i].plot(history.history[metric])\n",
        "        axs[i].plot(history.history['val_'+metric])\n",
        "        axs[i].legend(['training', 'validation'], loc='best')\n",
        "\n",
        "        axs[i].set_title('Model '+metric)\n",
        "        axs[i].set_ylabel(metric)\n",
        "        axs[i].set_xlabel('epoch')\n",
        "        axs[i].set_ylim(ylimits[i])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "    \"\"\"\n",
        "    This function trains and evaluated a model. It first compiles the model with \n",
        "    the loss and metrics. It then makes a train and validation generator for the \n",
        "    image data, based on the preprocess and augment input. \n",
        "    It then trains the model on both the image and tabular data for epochs times. \n",
        "    The values of the loss and metric are plotted and printed.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Preprocess the image data\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(image_x)\n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(image_x)\n",
        "\n",
        "    # Train the model by fitting both tabular and image data at the same time\n",
        "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs = epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "    # Plot the loss and metric\n",
        "    # plot_loss(history)\n",
        "\n",
        "\n",
        "\n",
        "    # print(f\"Validation Accuracy: {model.evaluate(val_gen.flow([x_val_imgs, x_val_tabular], val_y))[1]}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7eJp3actWxsB",
      "metadata": {
        "id": "7eJp3actWxsB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70fbece2-025a-4aeb-976b-ba89d4fddbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 38ms/step - loss: 1083.1014 - root_mean_squared_error: 30.2145 - val_loss: 697.4714 - val_root_mean_squared_error: 23.9463\n",
            "Epoch 2/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 806.4725 - root_mean_squared_error: 26.3018 - val_loss: 624.3306 - val_root_mean_squared_error: 22.7882\n",
            "Epoch 3/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 699.0176 - root_mean_squared_error: 24.8452 - val_loss: 647.3534 - val_root_mean_squared_error: 24.6653\n",
            "Epoch 4/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 603.5186 - root_mean_squared_error: 23.4414 - val_loss: 567.0703 - val_root_mean_squared_error: 23.1919\n",
            "Epoch 5/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 540.5980 - root_mean_squared_error: 22.4624 - val_loss: 479.8618 - val_root_mean_squared_error: 21.3101\n",
            "Epoch 6/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 507.9005 - root_mean_squared_error: 21.9078 - val_loss: 467.2121 - val_root_mean_squared_error: 21.0612\n",
            "Epoch 7/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 485.9126 - root_mean_squared_error: 21.4942 - val_loss: 464.0249 - val_root_mean_squared_error: 21.0779\n",
            "Epoch 8/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 473.4435 - root_mean_squared_error: 21.2632 - val_loss: 450.7896 - val_root_mean_squared_error: 20.7521\n",
            "Epoch 9/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 469.4554 - root_mean_squared_error: 21.2114 - val_loss: 450.8805 - val_root_mean_squared_error: 20.8020\n",
            "Epoch 10/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 459.4721 - root_mean_squared_error: 21.0043 - val_loss: 453.3690 - val_root_mean_squared_error: 20.9046\n",
            "Epoch 11/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 456.3271 - root_mean_squared_error: 20.9526 - val_loss: 448.8679 - val_root_mean_squared_error: 20.7975\n",
            "Epoch 12/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 457.7061 - root_mean_squared_error: 21.0034 - val_loss: 444.9601 - val_root_mean_squared_error: 20.7143\n",
            "Epoch 13/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 456.3633 - root_mean_squared_error: 20.9965 - val_loss: 446.5550 - val_root_mean_squared_error: 20.7779\n",
            "Epoch 14/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 449.5892 - root_mean_squared_error: 20.8502 - val_loss: 445.8730 - val_root_mean_squared_error: 20.7485\n",
            "Epoch 15/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 448.5922 - root_mean_squared_error: 20.8343 - val_loss: 443.0404 - val_root_mean_squared_error: 20.7055\n",
            "Epoch 16/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 446.6673 - root_mean_squared_error: 20.7987 - val_loss: 442.8203 - val_root_mean_squared_error: 20.7110\n",
            "Epoch 17/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 447.5995 - root_mean_squared_error: 20.8319 - val_loss: 442.7153 - val_root_mean_squared_error: 20.7148\n",
            "Epoch 18/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 445.9678 - root_mean_squared_error: 20.7987 - val_loss: 442.2874 - val_root_mean_squared_error: 20.7209\n",
            "Epoch 19/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 441.3914 - root_mean_squared_error: 20.6974 - val_loss: 442.2329 - val_root_mean_squared_error: 20.7225\n",
            "Epoch 20/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 441.8283 - root_mean_squared_error: 20.7164 - val_loss: 442.5607 - val_root_mean_squared_error: 20.7314\n",
            "Epoch 21/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 440.6666 - root_mean_squared_error: 20.6896 - val_loss: 441.4910 - val_root_mean_squared_error: 20.7162\n",
            "Epoch 22/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 439.9246 - root_mean_squared_error: 20.6830 - val_loss: 441.3306 - val_root_mean_squared_error: 20.7261\n",
            "Epoch 23/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 438.0247 - root_mean_squared_error: 20.6419 - val_loss: 440.4496 - val_root_mean_squared_error: 20.6992\n",
            "Epoch 24/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 440.7720 - root_mean_squared_error: 20.7097 - val_loss: 447.4770 - val_root_mean_squared_error: 20.8676\n",
            "Epoch 25/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 437.1122 - root_mean_squared_error: 20.6164 - val_loss: 443.1163 - val_root_mean_squared_error: 20.7801\n",
            "Epoch 26/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 436.0882 - root_mean_squared_error: 20.5998 - val_loss: 442.7191 - val_root_mean_squared_error: 20.7601\n",
            "Epoch 27/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 434.4979 - root_mean_squared_error: 20.5677 - val_loss: 442.1042 - val_root_mean_squared_error: 20.7568\n",
            "Epoch 28/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 433.4869 - root_mean_squared_error: 20.5420 - val_loss: 441.8109 - val_root_mean_squared_error: 20.7502\n",
            "Epoch 29/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 430.8859 - root_mean_squared_error: 20.4826 - val_loss: 441.7897 - val_root_mean_squared_error: 20.7450\n",
            "Epoch 30/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 429.9977 - root_mean_squared_error: 20.4539 - val_loss: 443.6186 - val_root_mean_squared_error: 20.7928\n",
            "Epoch 31/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 428.2570 - root_mean_squared_error: 20.4064 - val_loss: 442.1404 - val_root_mean_squared_error: 20.7605\n",
            "Epoch 32/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 424.4449 - root_mean_squared_error: 20.3160 - val_loss: 442.0338 - val_root_mean_squared_error: 20.7617\n",
            "Epoch 33/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 421.2709 - root_mean_squared_error: 20.2382 - val_loss: 450.6751 - val_root_mean_squared_error: 20.9497\n",
            "Epoch 34/60\n",
            "248/248 [==============================] - 8s 33ms/step - loss: 419.2994 - root_mean_squared_error: 20.1841 - val_loss: 449.2535 - val_root_mean_squared_error: 20.9245\n",
            "Epoch 35/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 415.8786 - root_mean_squared_error: 20.1004 - val_loss: 444.7503 - val_root_mean_squared_error: 20.8211\n",
            "Epoch 36/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 414.0105 - root_mean_squared_error: 20.0457 - val_loss: 452.1214 - val_root_mean_squared_error: 20.9590\n",
            "Epoch 37/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 409.1033 - root_mean_squared_error: 19.9202 - val_loss: 454.0982 - val_root_mean_squared_error: 21.0387\n",
            "Epoch 38/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 406.6997 - root_mean_squared_error: 19.8640 - val_loss: 455.1411 - val_root_mean_squared_error: 21.0654\n",
            "Epoch 39/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 402.7844 - root_mean_squared_error: 19.7594 - val_loss: 456.5594 - val_root_mean_squared_error: 21.0771\n",
            "Epoch 40/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 392.7688 - root_mean_squared_error: 19.5055 - val_loss: 464.3611 - val_root_mean_squared_error: 21.2570\n",
            "Epoch 41/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 390.1332 - root_mean_squared_error: 19.4369 - val_loss: 459.2835 - val_root_mean_squared_error: 21.1414\n",
            "Epoch 42/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 384.3276 - root_mean_squared_error: 19.2867 - val_loss: 474.3456 - val_root_mean_squared_error: 21.4745\n",
            "Epoch 43/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 376.0621 - root_mean_squared_error: 19.0616 - val_loss: 482.8848 - val_root_mean_squared_error: 21.7025\n",
            "Epoch 44/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 374.6904 - root_mean_squared_error: 19.0237 - val_loss: 474.8106 - val_root_mean_squared_error: 21.5204\n",
            "Epoch 45/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 364.3428 - root_mean_squared_error: 18.7501 - val_loss: 510.5701 - val_root_mean_squared_error: 22.3237\n",
            "Epoch 46/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 359.2811 - root_mean_squared_error: 18.6057 - val_loss: 500.2331 - val_root_mean_squared_error: 22.0944\n",
            "Epoch 47/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 352.2175 - root_mean_squared_error: 18.4133 - val_loss: 676.1626 - val_root_mean_squared_error: 25.7283\n",
            "Epoch 48/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 354.0221 - root_mean_squared_error: 18.4666 - val_loss: 472.1419 - val_root_mean_squared_error: 21.4301\n",
            "Epoch 49/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 342.9420 - root_mean_squared_error: 18.1613 - val_loss: 528.8033 - val_root_mean_squared_error: 22.7233\n",
            "Epoch 50/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 337.2340 - root_mean_squared_error: 17.9966 - val_loss: 605.5842 - val_root_mean_squared_error: 24.3389\n",
            "Epoch 51/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 334.1497 - root_mean_squared_error: 17.9119 - val_loss: 513.1950 - val_root_mean_squared_error: 22.3748\n",
            "Epoch 52/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 332.7003 - root_mean_squared_error: 17.8640 - val_loss: 544.5583 - val_root_mean_squared_error: 23.0511\n",
            "Epoch 53/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 319.0490 - root_mean_squared_error: 17.4805 - val_loss: 484.7185 - val_root_mean_squared_error: 21.7354\n",
            "Epoch 54/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 317.3273 - root_mean_squared_error: 17.4289 - val_loss: 525.5760 - val_root_mean_squared_error: 22.6522\n",
            "Epoch 55/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 314.5666 - root_mean_squared_error: 17.3462 - val_loss: 521.9381 - val_root_mean_squared_error: 22.5775\n",
            "Epoch 56/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 314.5467 - root_mean_squared_error: 17.3459 - val_loss: 494.4477 - val_root_mean_squared_error: 21.9552\n",
            "Epoch 57/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 299.0972 - root_mean_squared_error: 16.8961 - val_loss: 540.8467 - val_root_mean_squared_error: 22.9861\n",
            "Epoch 58/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 304.0847 - root_mean_squared_error: 17.0480 - val_loss: 495.3070 - val_root_mean_squared_error: 21.9656\n",
            "Epoch 59/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 300.3011 - root_mean_squared_error: 16.9317 - val_loss: 505.3536 - val_root_mean_squared_error: 22.2129\n",
            "Epoch 60/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 301.0125 - root_mean_squared_error: 16.9525 - val_loss: 517.7338 - val_root_mean_squared_error: 22.4842\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 254.0021 - root_mean_squared_error: 15.5375\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 517.7338 - root_mean_squared_error: 22.4842\n",
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 36ms/step - loss: 1160.9741 - root_mean_squared_error: 31.4596 - val_loss: 1122.6112 - val_root_mean_squared_error: 33.1834\n",
            "Epoch 2/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 770.2563 - root_mean_squared_error: 25.7355 - val_loss: 728.7430 - val_root_mean_squared_error: 26.3472\n",
            "Epoch 3/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 652.2866 - root_mean_squared_error: 24.1314 - val_loss: 590.7348 - val_root_mean_squared_error: 23.6604\n",
            "Epoch 4/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 599.7227 - root_mean_squared_error: 23.5126 - val_loss: 529.5638 - val_root_mean_squared_error: 22.4669\n",
            "Epoch 5/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 536.5133 - root_mean_squared_error: 22.4176 - val_loss: 451.1013 - val_root_mean_squared_error: 20.6241\n",
            "Epoch 6/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 513.6382 - root_mean_squared_error: 22.0252 - val_loss: 448.3505 - val_root_mean_squared_error: 20.6513\n",
            "Epoch 7/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 493.2755 - root_mean_squared_error: 21.6433 - val_loss: 432.2220 - val_root_mean_squared_error: 20.2742\n",
            "Epoch 8/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 487.4888 - root_mean_squared_error: 21.5596 - val_loss: 428.8481 - val_root_mean_squared_error: 20.2253\n",
            "Epoch 9/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 471.5214 - root_mean_squared_error: 21.2286 - val_loss: 424.2712 - val_root_mean_squared_error: 20.1078\n",
            "Epoch 10/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 469.3874 - root_mean_squared_error: 21.2067 - val_loss: 421.9334 - val_root_mean_squared_error: 20.0804\n",
            "Epoch 11/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 470.4698 - root_mean_squared_error: 21.2665 - val_loss: 421.1728 - val_root_mean_squared_error: 20.0875\n",
            "Epoch 12/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 461.4562 - root_mean_squared_error: 21.0790 - val_loss: 419.8648 - val_root_mean_squared_error: 20.0856\n",
            "Epoch 13/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 457.8713 - root_mean_squared_error: 21.0175 - val_loss: 418.3981 - val_root_mean_squared_error: 20.0750\n",
            "Epoch 14/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 459.7681 - root_mean_squared_error: 21.0760 - val_loss: 417.4857 - val_root_mean_squared_error: 20.0676\n",
            "Epoch 15/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 456.2343 - root_mean_squared_error: 21.0048 - val_loss: 417.8901 - val_root_mean_squared_error: 20.0708\n",
            "Epoch 16/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 454.1840 - root_mean_squared_error: 20.9741 - val_loss: 417.0055 - val_root_mean_squared_error: 20.0862\n",
            "Epoch 17/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 451.3701 - root_mean_squared_error: 20.9127 - val_loss: 416.3430 - val_root_mean_squared_error: 20.0645\n",
            "Epoch 18/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 449.2906 - root_mean_squared_error: 20.8753 - val_loss: 417.5738 - val_root_mean_squared_error: 20.0979\n",
            "Epoch 19/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 449.9803 - root_mean_squared_error: 20.8988 - val_loss: 416.0470 - val_root_mean_squared_error: 20.0668\n",
            "Epoch 20/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 450.8880 - root_mean_squared_error: 20.9288 - val_loss: 414.9904 - val_root_mean_squared_error: 20.0619\n",
            "Epoch 21/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 448.5375 - root_mean_squared_error: 20.8851 - val_loss: 415.3354 - val_root_mean_squared_error: 20.0848\n",
            "Epoch 22/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 447.7545 - root_mean_squared_error: 20.8699 - val_loss: 415.6396 - val_root_mean_squared_error: 20.0822\n",
            "Epoch 23/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 446.8022 - root_mean_squared_error: 20.8416 - val_loss: 415.1118 - val_root_mean_squared_error: 20.0739\n",
            "Epoch 24/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 446.2806 - root_mean_squared_error: 20.8392 - val_loss: 417.0898 - val_root_mean_squared_error: 20.1253\n",
            "Epoch 25/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 444.7903 - root_mean_squared_error: 20.8014 - val_loss: 414.8792 - val_root_mean_squared_error: 20.0791\n",
            "Epoch 26/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 444.4855 - root_mean_squared_error: 20.8021 - val_loss: 418.7696 - val_root_mean_squared_error: 20.1654\n",
            "Epoch 27/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 443.4708 - root_mean_squared_error: 20.7762 - val_loss: 417.5071 - val_root_mean_squared_error: 20.1444\n",
            "Epoch 28/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 440.6110 - root_mean_squared_error: 20.7070 - val_loss: 420.5918 - val_root_mean_squared_error: 20.2457\n",
            "Epoch 29/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 437.7208 - root_mean_squared_error: 20.6439 - val_loss: 419.0901 - val_root_mean_squared_error: 20.1847\n",
            "Epoch 30/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 436.1841 - root_mean_squared_error: 20.6061 - val_loss: 417.4865 - val_root_mean_squared_error: 20.1607\n",
            "Epoch 31/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 434.4164 - root_mean_squared_error: 20.5588 - val_loss: 418.0266 - val_root_mean_squared_error: 20.1797\n",
            "Epoch 32/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 430.7136 - root_mean_squared_error: 20.4656 - val_loss: 421.5835 - val_root_mean_squared_error: 20.2530\n",
            "Epoch 33/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 429.0937 - root_mean_squared_error: 20.4190 - val_loss: 426.0959 - val_root_mean_squared_error: 20.3571\n",
            "Epoch 34/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 423.7308 - root_mean_squared_error: 20.2843 - val_loss: 447.8403 - val_root_mean_squared_error: 20.8827\n",
            "Epoch 35/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 413.3078 - root_mean_squared_error: 20.0297 - val_loss: 430.8898 - val_root_mean_squared_error: 20.4830\n",
            "Epoch 36/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 410.8505 - root_mean_squared_error: 19.9633 - val_loss: 451.5250 - val_root_mean_squared_error: 20.9702\n",
            "Epoch 37/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 403.3465 - root_mean_squared_error: 19.7739 - val_loss: 427.8238 - val_root_mean_squared_error: 20.3991\n",
            "Epoch 38/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 402.9354 - root_mean_squared_error: 19.7630 - val_loss: 501.2845 - val_root_mean_squared_error: 22.1003\n",
            "Epoch 39/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 391.6881 - root_mean_squared_error: 19.4703 - val_loss: 475.8057 - val_root_mean_squared_error: 21.5339\n",
            "Epoch 40/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 385.2689 - root_mean_squared_error: 19.3125 - val_loss: 430.2904 - val_root_mean_squared_error: 20.4641\n",
            "Epoch 41/60\n",
            "248/248 [==============================] - 8s 34ms/step - loss: 377.8695 - root_mean_squared_error: 19.1146 - val_loss: 459.2114 - val_root_mean_squared_error: 21.1586\n",
            "Epoch 42/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 371.3442 - root_mean_squared_error: 18.9431 - val_loss: 439.7241 - val_root_mean_squared_error: 20.6861\n",
            "Epoch 43/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 363.5536 - root_mean_squared_error: 18.7309 - val_loss: 445.4586 - val_root_mean_squared_error: 20.8260\n",
            "Epoch 44/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 365.7639 - root_mean_squared_error: 18.7947 - val_loss: 503.2438 - val_root_mean_squared_error: 22.1564\n",
            "Epoch 45/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 356.8205 - root_mean_squared_error: 18.5490 - val_loss: 547.6943 - val_root_mean_squared_error: 23.1269\n",
            "Epoch 46/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 347.3974 - root_mean_squared_error: 18.2858 - val_loss: 480.7666 - val_root_mean_squared_error: 21.6545\n",
            "Epoch 47/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 344.7606 - root_mean_squared_error: 18.2143 - val_loss: 445.3847 - val_root_mean_squared_error: 20.8013\n",
            "Epoch 48/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 331.9214 - root_mean_squared_error: 17.8553 - val_loss: 460.3218 - val_root_mean_squared_error: 21.1804\n",
            "Epoch 49/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 333.3290 - root_mean_squared_error: 17.8958 - val_loss: 478.1346 - val_root_mean_squared_error: 21.5892\n",
            "Epoch 50/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 330.5207 - root_mean_squared_error: 17.8193 - val_loss: 511.0473 - val_root_mean_squared_error: 22.3321\n",
            "Epoch 51/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 322.3519 - root_mean_squared_error: 17.5781 - val_loss: 453.5604 - val_root_mean_squared_error: 21.0155\n",
            "Epoch 52/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 313.7617 - root_mean_squared_error: 17.3311 - val_loss: 472.4879 - val_root_mean_squared_error: 21.4561\n",
            "Epoch 53/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 315.7552 - root_mean_squared_error: 17.3871 - val_loss: 503.1968 - val_root_mean_squared_error: 22.1540\n",
            "Epoch 54/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 312.9769 - root_mean_squared_error: 17.3067 - val_loss: 470.4922 - val_root_mean_squared_error: 21.4170\n",
            "Epoch 55/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 295.8007 - root_mean_squared_error: 16.8007 - val_loss: 460.3521 - val_root_mean_squared_error: 21.1745\n",
            "Epoch 56/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 298.7367 - root_mean_squared_error: 16.8916 - val_loss: 469.4991 - val_root_mean_squared_error: 21.3943\n",
            "Epoch 57/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 294.6878 - root_mean_squared_error: 16.7692 - val_loss: 509.3727 - val_root_mean_squared_error: 22.2904\n",
            "Epoch 58/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 288.2430 - root_mean_squared_error: 16.5728 - val_loss: 464.2705 - val_root_mean_squared_error: 21.2635\n",
            "Epoch 59/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 286.4451 - root_mean_squared_error: 16.5194 - val_loss: 505.6419 - val_root_mean_squared_error: 22.2090\n",
            "Epoch 60/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 285.4732 - root_mean_squared_error: 16.4847 - val_loss: 511.9922 - val_root_mean_squared_error: 22.3519\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 211.3153 - root_mean_squared_error: 14.0865\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 511.9923 - root_mean_squared_error: 22.3519\n",
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 37ms/step - loss: 1026.2980 - root_mean_squared_error: 29.2467 - val_loss: 796.2496 - val_root_mean_squared_error: 22.8133\n",
            "Epoch 2/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 760.4307 - root_mean_squared_error: 25.5236 - val_loss: 715.6795 - val_root_mean_squared_error: 25.7698\n",
            "Epoch 3/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 645.1026 - root_mean_squared_error: 23.8416 - val_loss: 675.0823 - val_root_mean_squared_error: 25.2968\n",
            "Epoch 4/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 591.9632 - root_mean_squared_error: 23.2102 - val_loss: 595.0807 - val_root_mean_squared_error: 23.7738\n",
            "Epoch 5/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 533.4866 - root_mean_squared_error: 22.2616 - val_loss: 546.0389 - val_root_mean_squared_error: 22.8315\n",
            "Epoch 6/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 499.2745 - root_mean_squared_error: 21.6972 - val_loss: 510.6976 - val_root_mean_squared_error: 22.1136\n",
            "Epoch 7/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 469.9476 - root_mean_squared_error: 21.1221 - val_loss: 488.3836 - val_root_mean_squared_error: 21.6160\n",
            "Epoch 8/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 461.4844 - root_mean_squared_error: 20.9799 - val_loss: 482.3747 - val_root_mean_squared_error: 21.4906\n",
            "Epoch 9/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 459.0132 - root_mean_squared_error: 20.9507 - val_loss: 488.6718 - val_root_mean_squared_error: 21.6758\n",
            "Epoch 10/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 452.9289 - root_mean_squared_error: 20.8382 - val_loss: 480.8090 - val_root_mean_squared_error: 21.5160\n",
            "Epoch 11/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 450.3601 - root_mean_squared_error: 20.8050 - val_loss: 481.3841 - val_root_mean_squared_error: 21.5411\n",
            "Epoch 12/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 447.8945 - root_mean_squared_error: 20.7757 - val_loss: 477.3099 - val_root_mean_squared_error: 21.4806\n",
            "Epoch 13/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 445.1248 - root_mean_squared_error: 20.7282 - val_loss: 476.3994 - val_root_mean_squared_error: 21.4805\n",
            "Epoch 14/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 439.6002 - root_mean_squared_error: 20.6119 - val_loss: 476.6489 - val_root_mean_squared_error: 21.5050\n",
            "Epoch 15/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 439.7111 - root_mean_squared_error: 20.6236 - val_loss: 475.8078 - val_root_mean_squared_error: 21.4962\n",
            "Epoch 16/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 437.3597 - root_mean_squared_error: 20.5857 - val_loss: 474.9189 - val_root_mean_squared_error: 21.4833\n",
            "Epoch 17/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 435.5195 - root_mean_squared_error: 20.5487 - val_loss: 474.9572 - val_root_mean_squared_error: 21.4924\n",
            "Epoch 18/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 434.4826 - root_mean_squared_error: 20.5380 - val_loss: 474.2700 - val_root_mean_squared_error: 21.4948\n",
            "Epoch 19/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 436.0540 - root_mean_squared_error: 20.5827 - val_loss: 475.4770 - val_root_mean_squared_error: 21.5302\n",
            "Epoch 20/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 431.7808 - root_mean_squared_error: 20.4876 - val_loss: 473.9122 - val_root_mean_squared_error: 21.5007\n",
            "Epoch 21/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 432.0770 - root_mean_squared_error: 20.5030 - val_loss: 472.8995 - val_root_mean_squared_error: 21.4758\n",
            "Epoch 22/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 430.3959 - root_mean_squared_error: 20.4630 - val_loss: 473.0951 - val_root_mean_squared_error: 21.4795\n",
            "Epoch 23/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 429.1975 - root_mean_squared_error: 20.4351 - val_loss: 476.5805 - val_root_mean_squared_error: 21.5725\n",
            "Epoch 24/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 427.9454 - root_mean_squared_error: 20.4086 - val_loss: 473.9679 - val_root_mean_squared_error: 21.4983\n",
            "Epoch 25/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 424.2991 - root_mean_squared_error: 20.3171 - val_loss: 473.1636 - val_root_mean_squared_error: 21.4898\n",
            "Epoch 26/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 423.0176 - root_mean_squared_error: 20.2822 - val_loss: 478.2947 - val_root_mean_squared_error: 21.6143\n",
            "Epoch 27/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 417.6879 - root_mean_squared_error: 20.1480 - val_loss: 481.5248 - val_root_mean_squared_error: 21.6873\n",
            "Epoch 28/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 415.0305 - root_mean_squared_error: 20.0864 - val_loss: 475.5913 - val_root_mean_squared_error: 21.5410\n",
            "Epoch 29/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 408.5430 - root_mean_squared_error: 19.9133 - val_loss: 480.6866 - val_root_mean_squared_error: 21.6612\n",
            "Epoch 30/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 404.5656 - root_mean_squared_error: 19.8146 - val_loss: 488.4847 - val_root_mean_squared_error: 21.8404\n",
            "Epoch 31/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 401.3482 - root_mean_squared_error: 19.7330 - val_loss: 483.5021 - val_root_mean_squared_error: 21.7230\n",
            "Epoch 32/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 393.9521 - root_mean_squared_error: 19.5436 - val_loss: 492.7799 - val_root_mean_squared_error: 21.9384\n",
            "Epoch 33/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 384.8743 - root_mean_squared_error: 19.3039 - val_loss: 549.2380 - val_root_mean_squared_error: 23.1606\n",
            "Epoch 34/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 381.5228 - root_mean_squared_error: 19.2165 - val_loss: 505.3306 - val_root_mean_squared_error: 22.2192\n",
            "Epoch 35/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 365.1036 - root_mean_squared_error: 18.7744 - val_loss: 491.4289 - val_root_mean_squared_error: 21.9128\n",
            "Epoch 36/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 361.0820 - root_mean_squared_error: 18.6714 - val_loss: 513.1528 - val_root_mean_squared_error: 22.3929\n",
            "Epoch 37/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 361.5104 - root_mean_squared_error: 18.6878 - val_loss: 530.2393 - val_root_mean_squared_error: 22.7644\n",
            "Epoch 38/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 344.8808 - root_mean_squared_error: 18.2316 - val_loss: 515.4803 - val_root_mean_squared_error: 22.4492\n",
            "Epoch 39/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 340.9527 - root_mean_squared_error: 18.1198 - val_loss: 508.9592 - val_root_mean_squared_error: 22.3053\n",
            "Epoch 40/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 339.1536 - root_mean_squared_error: 18.0661 - val_loss: 508.8435 - val_root_mean_squared_error: 22.2852\n",
            "Epoch 41/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 322.5915 - root_mean_squared_error: 17.6005 - val_loss: 541.6809 - val_root_mean_squared_error: 23.0172\n",
            "Epoch 42/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 318.9099 - root_mean_squared_error: 17.4959 - val_loss: 548.1008 - val_root_mean_squared_error: 23.1496\n",
            "Epoch 43/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 310.7258 - root_mean_squared_error: 17.2621 - val_loss: 536.4299 - val_root_mean_squared_error: 22.9042\n",
            "Epoch 44/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 309.8627 - root_mean_squared_error: 17.2334 - val_loss: 511.0446 - val_root_mean_squared_error: 22.3504\n",
            "Epoch 45/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 302.6697 - root_mean_squared_error: 17.0255 - val_loss: 552.2090 - val_root_mean_squared_error: 23.2407\n",
            "Epoch 46/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 296.6955 - root_mean_squared_error: 16.8441 - val_loss: 532.1002 - val_root_mean_squared_error: 22.8120\n",
            "Epoch 47/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 287.0360 - root_mean_squared_error: 16.5475 - val_loss: 526.7753 - val_root_mean_squared_error: 22.7031\n",
            "Epoch 48/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 280.4861 - root_mean_squared_error: 16.3546 - val_loss: 542.2676 - val_root_mean_squared_error: 23.0317\n",
            "Epoch 49/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 280.1420 - root_mean_squared_error: 16.3409 - val_loss: 544.0394 - val_root_mean_squared_error: 23.0682\n",
            "Epoch 50/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 269.1597 - root_mean_squared_error: 15.9978 - val_loss: 554.4202 - val_root_mean_squared_error: 23.2896\n",
            "Epoch 51/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 273.8145 - root_mean_squared_error: 16.1472 - val_loss: 537.5208 - val_root_mean_squared_error: 22.9294\n",
            "Epoch 52/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 264.8984 - root_mean_squared_error: 15.8647 - val_loss: 539.6844 - val_root_mean_squared_error: 22.9814\n",
            "Epoch 53/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 258.2986 - root_mean_squared_error: 15.6545 - val_loss: 532.8272 - val_root_mean_squared_error: 22.8318\n",
            "Epoch 54/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 255.6571 - root_mean_squared_error: 15.5633 - val_loss: 546.2828 - val_root_mean_squared_error: 23.1229\n",
            "Epoch 55/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 251.9372 - root_mean_squared_error: 15.4499 - val_loss: 546.6056 - val_root_mean_squared_error: 23.1353\n",
            "Epoch 56/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 249.4550 - root_mean_squared_error: 15.3746 - val_loss: 562.8752 - val_root_mean_squared_error: 23.4687\n",
            "Epoch 57/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 244.2244 - root_mean_squared_error: 15.1983 - val_loss: 542.4440 - val_root_mean_squared_error: 23.0407\n",
            "Epoch 58/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 245.2766 - root_mean_squared_error: 15.2302 - val_loss: 531.4001 - val_root_mean_squared_error: 22.8047\n",
            "Epoch 59/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 238.8997 - root_mean_squared_error: 15.0177 - val_loss: 518.6278 - val_root_mean_squared_error: 22.5184\n",
            "Epoch 60/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 234.7637 - root_mean_squared_error: 14.8879 - val_loss: 530.7137 - val_root_mean_squared_error: 22.7896\n",
            "248/248 [==============================] - 3s 11ms/step - loss: 169.4624 - root_mean_squared_error: 12.5431\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 530.7137 - root_mean_squared_error: 22.7896\n",
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 36ms/step - loss: 1014.3032 - root_mean_squared_error: 28.7008 - val_loss: 845.3636 - val_root_mean_squared_error: 28.0144\n",
            "Epoch 2/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 769.9439 - root_mean_squared_error: 25.5363 - val_loss: 686.4224 - val_root_mean_squared_error: 25.1567\n",
            "Epoch 3/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 688.7646 - root_mean_squared_error: 24.6229 - val_loss: 633.6517 - val_root_mean_squared_error: 24.3713\n",
            "Epoch 4/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 590.6586 - root_mean_squared_error: 23.1998 - val_loss: 498.3723 - val_root_mean_squared_error: 21.6852\n",
            "Epoch 5/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 527.0342 - root_mean_squared_error: 22.2121 - val_loss: 447.5836 - val_root_mean_squared_error: 20.5703\n",
            "Epoch 6/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 504.4958 - root_mean_squared_error: 21.8561 - val_loss: 451.4356 - val_root_mean_squared_error: 20.7604\n",
            "Epoch 7/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 482.0846 - root_mean_squared_error: 21.4339 - val_loss: 434.6068 - val_root_mean_squared_error: 20.3552\n",
            "Epoch 8/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 471.7664 - root_mean_squared_error: 21.2338 - val_loss: 432.6063 - val_root_mean_squared_error: 20.3461\n",
            "Epoch 9/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 464.0615 - root_mean_squared_error: 21.0945 - val_loss: 431.1154 - val_root_mean_squared_error: 20.3403\n",
            "Epoch 10/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 460.4365 - root_mean_squared_error: 21.0384 - val_loss: 431.4046 - val_root_mean_squared_error: 20.3304\n",
            "Epoch 11/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 457.9921 - root_mean_squared_error: 20.9839 - val_loss: 430.0004 - val_root_mean_squared_error: 20.3374\n",
            "Epoch 12/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 455.6881 - root_mean_squared_error: 20.9630 - val_loss: 428.2946 - val_root_mean_squared_error: 20.3325\n",
            "Epoch 13/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 456.4579 - root_mean_squared_error: 21.0094 - val_loss: 427.7179 - val_root_mean_squared_error: 20.3334\n",
            "Epoch 14/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 450.2865 - root_mean_squared_error: 20.8761 - val_loss: 427.6735 - val_root_mean_squared_error: 20.3338\n",
            "Epoch 15/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 451.0239 - root_mean_squared_error: 20.9005 - val_loss: 427.0051 - val_root_mean_squared_error: 20.3313\n",
            "Epoch 16/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 450.4828 - root_mean_squared_error: 20.8995 - val_loss: 428.0361 - val_root_mean_squared_error: 20.3664\n",
            "Epoch 17/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 445.7985 - root_mean_squared_error: 20.7989 - val_loss: 427.8170 - val_root_mean_squared_error: 20.3668\n",
            "Epoch 18/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 445.4462 - root_mean_squared_error: 20.8011 - val_loss: 427.4123 - val_root_mean_squared_error: 20.3526\n",
            "Epoch 19/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 442.9507 - root_mean_squared_error: 20.7425 - val_loss: 431.2722 - val_root_mean_squared_error: 20.4655\n",
            "Epoch 20/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 442.6978 - root_mean_squared_error: 20.7394 - val_loss: 430.5746 - val_root_mean_squared_error: 20.4567\n",
            "Epoch 21/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 441.6337 - root_mean_squared_error: 20.7170 - val_loss: 428.9764 - val_root_mean_squared_error: 20.4176\n",
            "Epoch 22/60\n",
            "248/248 [==============================] - 9s 34ms/step - loss: 438.1550 - root_mean_squared_error: 20.6338 - val_loss: 435.7410 - val_root_mean_squared_error: 20.5462\n",
            "Epoch 23/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 436.6987 - root_mean_squared_error: 20.5939 - val_loss: 428.9800 - val_root_mean_squared_error: 20.4290\n",
            "Epoch 24/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 435.2554 - root_mean_squared_error: 20.5625 - val_loss: 432.0968 - val_root_mean_squared_error: 20.4863\n",
            "Epoch 25/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 428.8633 - root_mean_squared_error: 20.4122 - val_loss: 431.7752 - val_root_mean_squared_error: 20.4792\n",
            "Epoch 26/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 427.4955 - root_mean_squared_error: 20.3766 - val_loss: 442.2823 - val_root_mean_squared_error: 20.7423\n",
            "Epoch 27/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 422.5838 - root_mean_squared_error: 20.2491 - val_loss: 433.9160 - val_root_mean_squared_error: 20.5423\n",
            "Epoch 28/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 417.7962 - root_mean_squared_error: 20.1324 - val_loss: 437.8419 - val_root_mean_squared_error: 20.6403\n",
            "Epoch 29/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 416.4250 - root_mean_squared_error: 20.0911 - val_loss: 449.7313 - val_root_mean_squared_error: 20.9239\n",
            "Epoch 30/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 406.0946 - root_mean_squared_error: 19.8303 - val_loss: 442.2518 - val_root_mean_squared_error: 20.7121\n",
            "Epoch 31/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 408.1566 - root_mean_squared_error: 19.8731 - val_loss: 438.3662 - val_root_mean_squared_error: 20.6486\n",
            "Epoch 32/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 402.8792 - root_mean_squared_error: 19.7462 - val_loss: 447.0685 - val_root_mean_squared_error: 20.8510\n",
            "Epoch 33/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 391.7653 - root_mean_squared_error: 19.4579 - val_loss: 459.0809 - val_root_mean_squared_error: 21.1447\n",
            "Epoch 34/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 384.7599 - root_mean_squared_error: 19.2792 - val_loss: 468.0964 - val_root_mean_squared_error: 21.3559\n",
            "Epoch 35/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 385.7330 - root_mean_squared_error: 19.3084 - val_loss: 493.0353 - val_root_mean_squared_error: 21.9214\n",
            "Epoch 36/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 378.7683 - root_mean_squared_error: 19.1259 - val_loss: 465.5265 - val_root_mean_squared_error: 21.2940\n",
            "Epoch 37/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 372.3800 - root_mean_squared_error: 18.9505 - val_loss: 463.3230 - val_root_mean_squared_error: 21.2336\n",
            "Epoch 38/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 357.6864 - root_mean_squared_error: 18.5549 - val_loss: 462.9461 - val_root_mean_squared_error: 21.2075\n",
            "Epoch 39/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 362.5713 - root_mean_squared_error: 18.6868 - val_loss: 489.0911 - val_root_mean_squared_error: 21.8363\n",
            "Epoch 40/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 347.4418 - root_mean_squared_error: 18.2747 - val_loss: 530.4978 - val_root_mean_squared_error: 22.7531\n",
            "Epoch 41/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 344.9590 - root_mean_squared_error: 18.2007 - val_loss: 463.8011 - val_root_mean_squared_error: 21.2506\n",
            "Epoch 42/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 337.9898 - root_mean_squared_error: 18.0086 - val_loss: 491.7444 - val_root_mean_squared_error: 21.8918\n",
            "Epoch 43/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 335.3999 - root_mean_squared_error: 17.9439 - val_loss: 461.6121 - val_root_mean_squared_error: 21.1898\n",
            "Epoch 44/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 329.2503 - root_mean_squared_error: 17.7654 - val_loss: 463.2844 - val_root_mean_squared_error: 21.2147\n",
            "Epoch 45/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 325.7971 - root_mean_squared_error: 17.6602 - val_loss: 507.5822 - val_root_mean_squared_error: 22.2511\n",
            "Epoch 46/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 323.2182 - root_mean_squared_error: 17.5984 - val_loss: 471.1097 - val_root_mean_squared_error: 21.4193\n",
            "Epoch 47/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 316.8213 - root_mean_squared_error: 17.4105 - val_loss: 487.7229 - val_root_mean_squared_error: 21.7981\n",
            "Epoch 48/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 312.6160 - root_mean_squared_error: 17.2901 - val_loss: 465.0495 - val_root_mean_squared_error: 21.2790\n",
            "Epoch 49/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 309.4604 - root_mean_squared_error: 17.1992 - val_loss: 514.3972 - val_root_mean_squared_error: 22.4031\n",
            "Epoch 50/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 310.0971 - root_mean_squared_error: 17.2164 - val_loss: 483.9347 - val_root_mean_squared_error: 21.7211\n",
            "Epoch 51/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 303.9968 - root_mean_squared_error: 17.0393 - val_loss: 487.5223 - val_root_mean_squared_error: 21.8039\n",
            "Epoch 52/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 301.6742 - root_mean_squared_error: 16.9695 - val_loss: 467.2669 - val_root_mean_squared_error: 21.3026\n",
            "Epoch 53/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 299.4658 - root_mean_squared_error: 16.9038 - val_loss: 484.1822 - val_root_mean_squared_error: 21.7296\n",
            "Epoch 54/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 288.9669 - root_mean_squared_error: 16.5944 - val_loss: 518.8142 - val_root_mean_squared_error: 22.5010\n",
            "Epoch 55/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 289.5295 - root_mean_squared_error: 16.6111 - val_loss: 506.0991 - val_root_mean_squared_error: 22.2219\n",
            "Epoch 56/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 280.5709 - root_mean_squared_error: 16.3385 - val_loss: 501.0366 - val_root_mean_squared_error: 22.1079\n",
            "Epoch 57/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 279.5381 - root_mean_squared_error: 16.3015 - val_loss: 504.3838 - val_root_mean_squared_error: 22.1769\n",
            "Epoch 58/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 271.2388 - root_mean_squared_error: 16.0485 - val_loss: 477.2563 - val_root_mean_squared_error: 21.5604\n",
            "Epoch 59/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 276.9801 - root_mean_squared_error: 16.2261 - val_loss: 471.9557 - val_root_mean_squared_error: 21.4326\n",
            "Epoch 60/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 273.5190 - root_mean_squared_error: 16.1172 - val_loss: 505.8595 - val_root_mean_squared_error: 22.2165\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 181.6671 - root_mean_squared_error: 12.9901\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 505.8595 - root_mean_squared_error: 22.2165\n",
            "Epoch 1/60\n",
            "248/248 [==============================] - 12s 38ms/step - loss: 990.4410 - root_mean_squared_error: 28.3600 - val_loss: 779.7796 - val_root_mean_squared_error: 27.0421\n",
            "Epoch 2/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 710.7259 - root_mean_squared_error: 24.7768 - val_loss: 676.1767 - val_root_mean_squared_error: 25.2190\n",
            "Epoch 3/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 639.7691 - root_mean_squared_error: 24.0203 - val_loss: 593.9523 - val_root_mean_squared_error: 23.7720\n",
            "Epoch 4/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 565.4197 - root_mean_squared_error: 22.8755 - val_loss: 507.6393 - val_root_mean_squared_error: 21.9559\n",
            "Epoch 5/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 521.2809 - root_mean_squared_error: 22.1148 - val_loss: 463.8644 - val_root_mean_squared_error: 20.9642\n",
            "Epoch 6/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 496.2420 - root_mean_squared_error: 21.6628 - val_loss: 457.6474 - val_root_mean_squared_error: 20.8755\n",
            "Epoch 7/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 487.9462 - root_mean_squared_error: 21.5454 - val_loss: 446.4461 - val_root_mean_squared_error: 20.6512\n",
            "Epoch 8/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 475.2995 - root_mean_squared_error: 21.3061 - val_loss: 437.3678 - val_root_mean_squared_error: 20.3941\n",
            "Epoch 9/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 468.3984 - root_mean_squared_error: 21.1731 - val_loss: 434.5077 - val_root_mean_squared_error: 20.3951\n",
            "Epoch 10/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 462.8124 - root_mean_squared_error: 21.0792 - val_loss: 433.4433 - val_root_mean_squared_error: 20.4047\n",
            "Epoch 11/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 461.3566 - root_mean_squared_error: 21.0778 - val_loss: 430.8731 - val_root_mean_squared_error: 20.3533\n",
            "Epoch 12/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 455.5858 - root_mean_squared_error: 20.9670 - val_loss: 430.7991 - val_root_mean_squared_error: 20.3717\n",
            "Epoch 13/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 458.0783 - root_mean_squared_error: 21.0398 - val_loss: 428.8262 - val_root_mean_squared_error: 20.3516\n",
            "Epoch 14/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 452.7811 - root_mean_squared_error: 20.9350 - val_loss: 429.1297 - val_root_mean_squared_error: 20.3713\n",
            "Epoch 15/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 452.0085 - root_mean_squared_error: 20.9268 - val_loss: 428.7757 - val_root_mean_squared_error: 20.3888\n",
            "Epoch 16/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 452.3397 - root_mean_squared_error: 20.9511 - val_loss: 429.0419 - val_root_mean_squared_error: 20.3887\n",
            "Epoch 17/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 448.7863 - root_mean_squared_error: 20.8768 - val_loss: 429.3440 - val_root_mean_squared_error: 20.4179\n",
            "Epoch 18/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 446.8392 - root_mean_squared_error: 20.8373 - val_loss: 426.0810 - val_root_mean_squared_error: 20.3429\n",
            "Epoch 19/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 444.9932 - root_mean_squared_error: 20.7951 - val_loss: 432.8858 - val_root_mean_squared_error: 20.4980\n",
            "Epoch 20/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 444.4339 - root_mean_squared_error: 20.7828 - val_loss: 429.1014 - val_root_mean_squared_error: 20.4276\n",
            "Epoch 21/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 443.6943 - root_mean_squared_error: 20.7734 - val_loss: 426.2981 - val_root_mean_squared_error: 20.3607\n",
            "Epoch 22/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 443.2698 - root_mean_squared_error: 20.7729 - val_loss: 428.2368 - val_root_mean_squared_error: 20.4277\n",
            "Epoch 23/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 439.8030 - root_mean_squared_error: 20.6930 - val_loss: 429.9275 - val_root_mean_squared_error: 20.4692\n",
            "Epoch 24/60\n",
            "248/248 [==============================] - 9s 35ms/step - loss: 439.0741 - root_mean_squared_error: 20.6833 - val_loss: 425.8922 - val_root_mean_squared_error: 20.3679\n",
            "Epoch 25/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 441.1702 - root_mean_squared_error: 20.7299 - val_loss: 425.5389 - val_root_mean_squared_error: 20.3716\n",
            "Epoch 26/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 437.6260 - root_mean_squared_error: 20.6559 - val_loss: 426.4158 - val_root_mean_squared_error: 20.3900\n",
            "Epoch 27/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 438.5612 - root_mean_squared_error: 20.6675 - val_loss: 433.7961 - val_root_mean_squared_error: 20.5617\n",
            "Epoch 28/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 435.5592 - root_mean_squared_error: 20.6012 - val_loss: 432.9590 - val_root_mean_squared_error: 20.5293\n",
            "Epoch 29/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 435.5258 - root_mean_squared_error: 20.6062 - val_loss: 429.8051 - val_root_mean_squared_error: 20.4609\n",
            "Epoch 30/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 433.0194 - root_mean_squared_error: 20.5487 - val_loss: 429.2532 - val_root_mean_squared_error: 20.4495\n",
            "Epoch 31/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 431.9663 - root_mean_squared_error: 20.5184 - val_loss: 429.5376 - val_root_mean_squared_error: 20.4756\n",
            "Epoch 32/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 431.3199 - root_mean_squared_error: 20.5032 - val_loss: 431.2261 - val_root_mean_squared_error: 20.4827\n",
            "Epoch 33/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 429.1789 - root_mean_squared_error: 20.4405 - val_loss: 431.5453 - val_root_mean_squared_error: 20.4989\n",
            "Epoch 34/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 426.8388 - root_mean_squared_error: 20.3839 - val_loss: 432.9524 - val_root_mean_squared_error: 20.5485\n",
            "Epoch 35/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 428.9517 - root_mean_squared_error: 20.4291 - val_loss: 428.7833 - val_root_mean_squared_error: 20.4618\n",
            "Epoch 36/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 423.6440 - root_mean_squared_error: 20.3116 - val_loss: 430.5886 - val_root_mean_squared_error: 20.4966\n",
            "Epoch 37/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 419.6857 - root_mean_squared_error: 20.2109 - val_loss: 436.1218 - val_root_mean_squared_error: 20.6404\n",
            "Epoch 38/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 415.8890 - root_mean_squared_error: 20.1095 - val_loss: 444.8145 - val_root_mean_squared_error: 20.8395\n",
            "Epoch 39/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 415.0218 - root_mean_squared_error: 20.0867 - val_loss: 435.6261 - val_root_mean_squared_error: 20.5750\n",
            "Epoch 40/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 413.3240 - root_mean_squared_error: 20.0328 - val_loss: 437.7895 - val_root_mean_squared_error: 20.6688\n",
            "Epoch 41/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 408.3043 - root_mean_squared_error: 19.9181 - val_loss: 438.8382 - val_root_mean_squared_error: 20.6904\n",
            "Epoch 42/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 401.0409 - root_mean_squared_error: 19.7366 - val_loss: 437.1030 - val_root_mean_squared_error: 20.6513\n",
            "Epoch 43/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 396.7835 - root_mean_squared_error: 19.6221 - val_loss: 457.1869 - val_root_mean_squared_error: 21.1288\n",
            "Epoch 44/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 394.6422 - root_mean_squared_error: 19.5573 - val_loss: 443.4967 - val_root_mean_squared_error: 20.7468\n",
            "Epoch 45/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 392.6076 - root_mean_squared_error: 19.5084 - val_loss: 445.6976 - val_root_mean_squared_error: 20.8416\n",
            "Epoch 46/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 385.2345 - root_mean_squared_error: 19.3198 - val_loss: 444.3480 - val_root_mean_squared_error: 20.7814\n",
            "Epoch 47/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 383.4851 - root_mean_squared_error: 19.2703 - val_loss: 446.2195 - val_root_mean_squared_error: 20.8279\n",
            "Epoch 48/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 373.3780 - root_mean_squared_error: 19.0064 - val_loss: 478.9063 - val_root_mean_squared_error: 21.6085\n",
            "Epoch 49/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 371.5388 - root_mean_squared_error: 18.9590 - val_loss: 457.7483 - val_root_mean_squared_error: 21.1217\n",
            "Epoch 50/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 368.8186 - root_mean_squared_error: 18.8866 - val_loss: 451.3823 - val_root_mean_squared_error: 20.9484\n",
            "Epoch 51/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 361.7339 - root_mean_squared_error: 18.6964 - val_loss: 487.4534 - val_root_mean_squared_error: 21.8224\n",
            "Epoch 52/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 367.8593 - root_mean_squared_error: 18.8566 - val_loss: 461.9941 - val_root_mean_squared_error: 21.2321\n",
            "Epoch 53/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 358.8210 - root_mean_squared_error: 18.6111 - val_loss: 464.1339 - val_root_mean_squared_error: 21.2858\n",
            "Epoch 54/60\n",
            "248/248 [==============================] - 9s 37ms/step - loss: 356.5489 - root_mean_squared_error: 18.5597 - val_loss: 514.6404 - val_root_mean_squared_error: 22.4282\n",
            "Epoch 55/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 347.5977 - root_mean_squared_error: 18.3126 - val_loss: 448.3946 - val_root_mean_squared_error: 20.9033\n",
            "Epoch 56/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 346.2224 - root_mean_squared_error: 18.2712 - val_loss: 530.1729 - val_root_mean_squared_error: 22.7667\n",
            "Epoch 57/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 342.2188 - root_mean_squared_error: 18.1572 - val_loss: 494.5298 - val_root_mean_squared_error: 21.9782\n",
            "Epoch 58/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 337.8567 - root_mean_squared_error: 18.0422 - val_loss: 463.5350 - val_root_mean_squared_error: 21.2681\n",
            "Epoch 59/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 330.6978 - root_mean_squared_error: 17.8422 - val_loss: 453.9011 - val_root_mean_squared_error: 21.0323\n",
            "Epoch 60/60\n",
            "248/248 [==============================] - 9s 36ms/step - loss: 331.7691 - root_mean_squared_error: 17.8700 - val_loss: 475.6393 - val_root_mean_squared_error: 21.5460\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 277.9055 - root_mean_squared_error: 16.3188\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 475.6393 - root_mean_squared_error: 21.5460\n",
            "[5275.11767578 3817.82928467 3324.94055176 2951.28277588 2658.91296387\n",
            " 2521.55105591 2419.16650391 2369.48251343 2332.44989014 2305.03729248\n",
            " 2296.50582886 2278.33071899 2273.89569092 2252.02502441 2247.57015991\n",
            " 2241.03344727 2229.07397461 2222.02642822 2215.36968994 2211.6288147\n",
            " 2206.60903931 2199.49981689 2190.52609253 2189.32757568 2176.23513794\n",
            " 2168.71276855 2156.80154419 2142.48373413 2129.10049438 2109.86129761\n",
            " 2104.14437866 2083.30966187 2056.18313599 2036.15179443 2008.97470093\n",
            " 1988.35522461 1966.02584839 1928.09143066 1913.01824951 1877.95709229\n",
            " 1843.85754395 1813.61248779 1782.52490234 1774.20947266 1742.23773193\n",
            " 1711.82675171 1684.32037354 1652.42355347 1637.41213989 1615.83007812\n",
            " 1596.04675293 1580.89389038 1551.38952637 1531.47706604 1499.43162537\n",
            " 1489.53164673 1459.76629639 1446.69989014 1433.32391357 1426.53755188] [1055.02353516  763.56585693  664.98811035  590.25655518  531.78259277\n",
            "  504.31021118  483.83330078  473.89650269  466.48997803  461.0074585\n",
            "  459.30116577  455.6661438   454.77913818  450.40500488  449.51403198\n",
            "  448.20668945  445.81479492  444.40528564  443.07393799  442.32576294\n",
            "  441.32180786  439.89996338  438.10521851  437.86551514  435.24702759\n",
            "  433.74255371  431.36030884  428.49674683  425.82009888  421.97225952\n",
            "  420.82887573  416.66193237  411.2366272   407.23035889  401.79494019\n",
            "  397.67104492  393.20516968  385.61828613  382.6036499   375.59141846\n",
            "  368.77150879  362.72249756  356.50498047  354.84189453  348.44754639\n",
            "  342.36535034  336.86407471  330.48471069  327.48242798  323.16601562\n",
            "  319.20935059  316.17877808  310.27790527  306.29541321  299.88632507\n",
            "  297.90632935  291.95325928  289.33997803  286.66478271  285.30751038]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
        "    \"\"\"\n",
        "    Train and evaluate the data for num-folds times, and return the average \n",
        "    training and validation loss. First the data is split in num-folds batches\n",
        "    and then the model is trained on the data, where a different batch is the \n",
        "    validation data each time.\n",
        "    \"\"\"\n",
        "    losses = {}\n",
        "\n",
        "    # Create kfold object to later split the data\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "    x_indices = np.array(range(len(x_tabular)))\n",
        "    y_indices = np.array(range(len(y)))\n",
        "\n",
        "    # Preset arrays to add the loss for training and validation\n",
        "    train_loss1 = np.array([0.0, 0.0])\n",
        "    val_loss1 = np.array([0.0, 0.0])\n",
        "\n",
        "    # Train and evaluate the model for num-fold times on a different training \n",
        "    # and validation set each time\n",
        "    count = 0 \n",
        "\n",
        "    train_loss = np.array(np.zeros(epochs))\n",
        "    train_acc = np.array(np.zeros(epochs))\n",
        "    val_loss = np.array(np.zeros(epochs))\n",
        "    val_acc = np.array(np.zeros(epochs))\n",
        "    \n",
        "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
        "        \n",
        "        # Make Neural Networks before concatenation\n",
        "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "        image_size = (64, 64, 3)\n",
        "        image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "\n",
        "        # Create subset training and validation data\n",
        "        x_tabular_train = x_tabular[id_train]\n",
        "        x_imgs_train = x_imgs[id_train]\n",
        "        y_train = y[id_train]\n",
        "        \n",
        "        x_tabular_val = x_tabular[id_val]\n",
        "        x_imgs_val = x_imgs[id_val]\n",
        "        y_val_2 = y[id_val]\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
        "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
        "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs,  preprocess={}, augment={})\n",
        "\n",
        "        # Add the evaluation loss each time\n",
        "        train_loss1 += concat_model.evaluate([x_imgs_train, x_tabular_train], y_train)\n",
        "        val_loss1 += concat_model.evaluate([x_imgs_val, x_tabular_val], y_val_2)\n",
        "        \n",
        "        # print(history.history['loss'])\n",
        "\n",
        "        # Add all the losses and metrics\n",
        "        train_loss += history.history['loss']\n",
        "        train_acc += history.history['root_mean_squared_error']\n",
        "        val_loss += history.history['val_loss']\n",
        "        val_acc += history.history['val_root_mean_squared_error']\n",
        "\n",
        "        losses[count] = history.history\n",
        "        count += 1 \n",
        "\n",
        "    # Calculate average loss and metric\n",
        "    avg_train_loss = train_loss / num_folds\n",
        "    avg_val_loss = val_loss / num_folds\n",
        "    avg_train_acc = train_acc / num_folds\n",
        "    avg_val_acc = val_acc / num_folds\n",
        "\n",
        "    print(train_loss, avg_train_loss)\n",
        "\n",
        "    # Calculate average evaluation\n",
        "    avg_train_loss1 = train_loss / num_folds\n",
        "    avg_val_loss1 = val_loss / num_folds\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Set y-limits for MSE (0, 1000) and RMSE (0, 30)\n",
        "    ylimits = [[0, 1000], [0,30]]\n",
        "\n",
        "    # Plot MSE\n",
        "    axs[0].plot(avg_train_loss)\n",
        "    axs[0].plot(avg_val_loss)\n",
        "    axs[0].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[0].set_title('Model MSE')\n",
        "    axs[0].set_ylabel('MSE')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "    axs[0].set_ylim(ylimits[0])\n",
        "\n",
        "    # Plot RMSE\n",
        "    axs[1].plot(avg_train_acc)\n",
        "    axs[1].plot(avg_val_acc)\n",
        "    axs[1].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[1].set_title('Model RMSE')\n",
        "    axs[1].set_ylabel('RMSE')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    axs[1].set_ylim(ylimits[1])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return avg_train_loss1, avg_val_loss1, losses\n",
        "\n",
        "avg_train_loss, avg_val_loss, loss_df = k_fold(5, x_tabular, y, x_images, epochs=60, preprocess={'featurewise_center': True, 'featurewise_std_normalization': True})\n",
        "# display(loss_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The average training loss is {avg_train_loss[0]} and the average training RMSE is {avg_train_loss[1]}')\n",
        "print(f'The average validation loss is {avg_val_loss[0]} and the average validation RMSE is {avg_val_loss[1]}')\n",
        "\n",
        "# See how the model scored on the testing data\n",
        "# loss = concat_model.evaluate([test_imgs_array, x_test_tabular], y_test)\n",
        "# print(f'Test loss: {loss}')"
      ],
      "metadata": {
        "id": "HlZsEhYcKBjb"
      },
      "id": "HlZsEhYcKBjb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9-K3Mgs8weVG",
      "metadata": {
        "id": "9-K3Mgs8weVG"
      },
      "outputs": [],
      "source": [
        "# Create overview of layers in model\n",
        "# tf.keras.utils.plot_model(concat_model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(loss_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tBbBXupsa6E7",
        "outputId": "be15d8d5-0516-4b61-d4ad-b9bb88667107"
      },
      "id": "tBbBXupsa6E7",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{0: {'loss': [1083.1014404296875,\n",
              "   806.4724731445312,\n",
              "   699.0176391601562,\n",
              "   603.5186157226562,\n",
              "   540.5979614257812,\n",
              "   507.90045166015625,\n",
              "   485.9125671386719,\n",
              "   473.4434814453125,\n",
              "   469.45538330078125,\n",
              "   459.47210693359375,\n",
              "   456.3271484375,\n",
              "   457.7060852050781,\n",
              "   456.3632507324219,\n",
              "   449.58917236328125,\n",
              "   448.59222412109375,\n",
              "   446.6672668457031,\n",
              "   447.5995178222656,\n",
              "   445.9678039550781,\n",
              "   441.39141845703125,\n",
              "   441.8283386230469,\n",
              "   440.66656494140625,\n",
              "   439.9245910644531,\n",
              "   438.0247497558594,\n",
              "   440.77203369140625,\n",
              "   437.1121826171875,\n",
              "   436.08819580078125,\n",
              "   434.49786376953125,\n",
              "   433.48687744140625,\n",
              "   430.8858947753906,\n",
              "   429.9976501464844,\n",
              "   428.2569580078125,\n",
              "   424.4449157714844,\n",
              "   421.2708740234375,\n",
              "   419.2994384765625,\n",
              "   415.8786315917969,\n",
              "   414.0105285644531,\n",
              "   409.103271484375,\n",
              "   406.6997375488281,\n",
              "   402.7843933105469,\n",
              "   392.7688293457031,\n",
              "   390.1331787109375,\n",
              "   384.3276062011719,\n",
              "   376.06207275390625,\n",
              "   374.69036865234375,\n",
              "   364.3428039550781,\n",
              "   359.2811279296875,\n",
              "   352.21746826171875,\n",
              "   354.0220947265625,\n",
              "   342.9420471191406,\n",
              "   337.2340087890625,\n",
              "   334.149658203125,\n",
              "   332.7003479003906,\n",
              "   319.0489807128906,\n",
              "   317.32733154296875,\n",
              "   314.56658935546875,\n",
              "   314.5466613769531,\n",
              "   299.09716796875,\n",
              "   304.0847473144531,\n",
              "   300.3011474609375,\n",
              "   301.0124816894531],\n",
              "  'root_mean_squared_error': [30.21449089050293,\n",
              "   26.30181884765625,\n",
              "   24.845182418823242,\n",
              "   23.441377639770508,\n",
              "   22.462373733520508,\n",
              "   21.907779693603516,\n",
              "   21.49424171447754,\n",
              "   21.263208389282227,\n",
              "   21.211437225341797,\n",
              "   21.004314422607422,\n",
              "   20.952573776245117,\n",
              "   21.003355026245117,\n",
              "   20.99652671813965,\n",
              "   20.85024642944336,\n",
              "   20.834304809570312,\n",
              "   20.79868507385254,\n",
              "   20.831933975219727,\n",
              "   20.798704147338867,\n",
              "   20.697355270385742,\n",
              "   20.716440200805664,\n",
              "   20.689603805541992,\n",
              "   20.682979583740234,\n",
              "   20.64188003540039,\n",
              "   20.709686279296875,\n",
              "   20.616384506225586,\n",
              "   20.59981346130371,\n",
              "   20.567733764648438,\n",
              "   20.542011260986328,\n",
              "   20.482624053955078,\n",
              "   20.45388412475586,\n",
              "   20.406442642211914,\n",
              "   20.315982818603516,\n",
              "   20.238191604614258,\n",
              "   20.184083938598633,\n",
              "   20.10040283203125,\n",
              "   20.045690536499023,\n",
              "   19.920154571533203,\n",
              "   19.863994598388672,\n",
              "   19.759414672851562,\n",
              "   19.50554847717285,\n",
              "   19.43693733215332,\n",
              "   19.286731719970703,\n",
              "   19.061635971069336,\n",
              "   19.023733139038086,\n",
              "   18.7501220703125,\n",
              "   18.60569953918457,\n",
              "   18.413305282592773,\n",
              "   18.466629028320312,\n",
              "   18.16131591796875,\n",
              "   17.99664306640625,\n",
              "   17.91191864013672,\n",
              "   17.863969802856445,\n",
              "   17.48052978515625,\n",
              "   17.428945541381836,\n",
              "   17.34623146057129,\n",
              "   17.34592056274414,\n",
              "   16.896100997924805,\n",
              "   17.047975540161133,\n",
              "   16.931669235229492,\n",
              "   16.952491760253906],\n",
              "  'val_loss': [697.471435546875,\n",
              "   624.33056640625,\n",
              "   647.3533935546875,\n",
              "   567.0703125,\n",
              "   479.8618469238281,\n",
              "   467.2121276855469,\n",
              "   464.0249328613281,\n",
              "   450.7896423339844,\n",
              "   450.8804931640625,\n",
              "   453.3689880371094,\n",
              "   448.86785888671875,\n",
              "   444.9601135253906,\n",
              "   446.5550231933594,\n",
              "   445.8730163574219,\n",
              "   443.0404052734375,\n",
              "   442.8203430175781,\n",
              "   442.7153015136719,\n",
              "   442.2874450683594,\n",
              "   442.2329406738281,\n",
              "   442.5606689453125,\n",
              "   441.4909973144531,\n",
              "   441.33056640625,\n",
              "   440.4495544433594,\n",
              "   447.4769592285156,\n",
              "   443.11627197265625,\n",
              "   442.7191162109375,\n",
              "   442.1042175292969,\n",
              "   441.81085205078125,\n",
              "   441.78973388671875,\n",
              "   443.61859130859375,\n",
              "   442.1404113769531,\n",
              "   442.0338134765625,\n",
              "   450.6751403808594,\n",
              "   449.25347900390625,\n",
              "   444.7502746582031,\n",
              "   452.1213684082031,\n",
              "   454.0981750488281,\n",
              "   455.1410827636719,\n",
              "   456.5594177246094,\n",
              "   464.361083984375,\n",
              "   459.2834777832031,\n",
              "   474.3455505371094,\n",
              "   482.884765625,\n",
              "   474.8106384277344,\n",
              "   510.570068359375,\n",
              "   500.23309326171875,\n",
              "   676.16259765625,\n",
              "   472.1419372558594,\n",
              "   528.8033447265625,\n",
              "   605.584228515625,\n",
              "   513.1950073242188,\n",
              "   544.558349609375,\n",
              "   484.7184753417969,\n",
              "   525.5760498046875,\n",
              "   521.9381103515625,\n",
              "   494.44769287109375,\n",
              "   540.8466796875,\n",
              "   495.3070373535156,\n",
              "   505.3536376953125,\n",
              "   517.7337646484375],\n",
              "  'val_root_mean_squared_error': [23.94626808166504,\n",
              "   22.788164138793945,\n",
              "   24.66529083251953,\n",
              "   23.191925048828125,\n",
              "   21.31009292602539,\n",
              "   21.061235427856445,\n",
              "   21.07786750793457,\n",
              "   20.752147674560547,\n",
              "   20.802021026611328,\n",
              "   20.90464210510254,\n",
              "   20.797483444213867,\n",
              "   20.714344024658203,\n",
              "   20.777894973754883,\n",
              "   20.748470306396484,\n",
              "   20.70549964904785,\n",
              "   20.71104621887207,\n",
              "   20.71478843688965,\n",
              "   20.720876693725586,\n",
              "   20.722545623779297,\n",
              "   20.731412887573242,\n",
              "   20.716236114501953,\n",
              "   20.726085662841797,\n",
              "   20.699249267578125,\n",
              "   20.8675537109375,\n",
              "   20.780071258544922,\n",
              "   20.76006317138672,\n",
              "   20.75682830810547,\n",
              "   20.75018310546875,\n",
              "   20.744998931884766,\n",
              "   20.792844772338867,\n",
              "   20.760507583618164,\n",
              "   20.761749267578125,\n",
              "   20.94968605041504,\n",
              "   20.924503326416016,\n",
              "   20.821147918701172,\n",
              "   20.95902442932129,\n",
              "   21.038677215576172,\n",
              "   21.065410614013672,\n",
              "   21.07709312438965,\n",
              "   21.2569580078125,\n",
              "   21.141407012939453,\n",
              "   21.474536895751953,\n",
              "   21.702505111694336,\n",
              "   21.520360946655273,\n",
              "   22.3237361907959,\n",
              "   22.094371795654297,\n",
              "   25.72830581665039,\n",
              "   21.430147171020508,\n",
              "   22.723299026489258,\n",
              "   24.338939666748047,\n",
              "   22.374801635742188,\n",
              "   23.051145553588867,\n",
              "   21.73543930053711,\n",
              "   22.65216636657715,\n",
              "   22.57750129699707,\n",
              "   21.95516586303711,\n",
              "   22.986127853393555,\n",
              "   21.965560913085938,\n",
              "   22.212858200073242,\n",
              "   22.484222412109375]},\n",
              " 1: {'loss': [1160.97412109375,\n",
              "   770.2562866210938,\n",
              "   652.28662109375,\n",
              "   599.72265625,\n",
              "   536.5133056640625,\n",
              "   513.6382446289062,\n",
              "   493.2755432128906,\n",
              "   487.48876953125,\n",
              "   471.5213623046875,\n",
              "   469.38739013671875,\n",
              "   470.4698181152344,\n",
              "   461.4561767578125,\n",
              "   457.871337890625,\n",
              "   459.76806640625,\n",
              "   456.2343444824219,\n",
              "   454.1839904785156,\n",
              "   451.3701477050781,\n",
              "   449.2905578613281,\n",
              "   449.9803466796875,\n",
              "   450.8879699707031,\n",
              "   448.5374755859375,\n",
              "   447.7545471191406,\n",
              "   446.8021545410156,\n",
              "   446.2806091308594,\n",
              "   444.79034423828125,\n",
              "   444.4854736328125,\n",
              "   443.4707946777344,\n",
              "   440.61102294921875,\n",
              "   437.7207946777344,\n",
              "   436.18414306640625,\n",
              "   434.4163818359375,\n",
              "   430.71356201171875,\n",
              "   429.0937194824219,\n",
              "   423.73077392578125,\n",
              "   413.30780029296875,\n",
              "   410.8504638671875,\n",
              "   403.3464660644531,\n",
              "   402.9353942871094,\n",
              "   391.6881103515625,\n",
              "   385.26885986328125,\n",
              "   377.8695373535156,\n",
              "   371.3442077636719,\n",
              "   363.5535888671875,\n",
              "   365.76385498046875,\n",
              "   356.82049560546875,\n",
              "   347.39739990234375,\n",
              "   344.76055908203125,\n",
              "   331.9213562011719,\n",
              "   333.3289794921875,\n",
              "   330.52069091796875,\n",
              "   322.3519287109375,\n",
              "   313.76165771484375,\n",
              "   315.75518798828125,\n",
              "   312.97686767578125,\n",
              "   295.8006591796875,\n",
              "   298.7366638183594,\n",
              "   294.68780517578125,\n",
              "   288.2430419921875,\n",
              "   286.44512939453125,\n",
              "   285.4732360839844],\n",
              "  'root_mean_squared_error': [31.459592819213867,\n",
              "   25.735504150390625,\n",
              "   24.131378173828125,\n",
              "   23.51264762878418,\n",
              "   22.41755485534668,\n",
              "   22.025224685668945,\n",
              "   21.643299102783203,\n",
              "   21.55963134765625,\n",
              "   21.22858238220215,\n",
              "   21.206729888916016,\n",
              "   21.266469955444336,\n",
              "   21.079004287719727,\n",
              "   21.017528533935547,\n",
              "   21.076013565063477,\n",
              "   21.00484275817871,\n",
              "   20.974105834960938,\n",
              "   20.91272735595703,\n",
              "   20.87528419494629,\n",
              "   20.898845672607422,\n",
              "   20.928775787353516,\n",
              "   20.885122299194336,\n",
              "   20.869901657104492,\n",
              "   20.841615676879883,\n",
              "   20.839235305786133,\n",
              "   20.801355361938477,\n",
              "   20.802087783813477,\n",
              "   20.776233673095703,\n",
              "   20.70701026916504,\n",
              "   20.64388084411621,\n",
              "   20.60611343383789,\n",
              "   20.55878257751465,\n",
              "   20.465585708618164,\n",
              "   20.419034957885742,\n",
              "   20.2842960357666,\n",
              "   20.029666900634766,\n",
              "   19.963308334350586,\n",
              "   19.773876190185547,\n",
              "   19.763010025024414,\n",
              "   19.470251083374023,\n",
              "   19.31252098083496,\n",
              "   19.114614486694336,\n",
              "   18.943134307861328,\n",
              "   18.730937957763672,\n",
              "   18.79471206665039,\n",
              "   18.54903793334961,\n",
              "   18.285816192626953,\n",
              "   18.21428680419922,\n",
              "   17.855274200439453,\n",
              "   17.8957576751709,\n",
              "   17.819286346435547,\n",
              "   17.578126907348633,\n",
              "   17.331098556518555,\n",
              "   17.387142181396484,\n",
              "   17.306663513183594,\n",
              "   16.800683975219727,\n",
              "   16.891557693481445,\n",
              "   16.76924705505371,\n",
              "   16.572813034057617,\n",
              "   16.519372940063477,\n",
              "   16.48468017578125],\n",
              "  'val_loss': [1122.6112060546875,\n",
              "   728.7429809570312,\n",
              "   590.7348022460938,\n",
              "   529.5638427734375,\n",
              "   451.1012878417969,\n",
              "   448.3504638671875,\n",
              "   432.22198486328125,\n",
              "   428.8480529785156,\n",
              "   424.2712097167969,\n",
              "   421.93341064453125,\n",
              "   421.17279052734375,\n",
              "   419.8648376464844,\n",
              "   418.3980712890625,\n",
              "   417.4857177734375,\n",
              "   417.8901062011719,\n",
              "   417.0054626464844,\n",
              "   416.343017578125,\n",
              "   417.5738220214844,\n",
              "   416.0469970703125,\n",
              "   414.9903869628906,\n",
              "   415.3353576660156,\n",
              "   415.6395568847656,\n",
              "   415.11181640625,\n",
              "   417.0898132324219,\n",
              "   414.8792419433594,\n",
              "   418.7695617675781,\n",
              "   417.50714111328125,\n",
              "   420.5917663574219,\n",
              "   419.09014892578125,\n",
              "   417.4865417480469,\n",
              "   418.0266418457031,\n",
              "   421.5835266113281,\n",
              "   426.0958557128906,\n",
              "   447.84027099609375,\n",
              "   430.8897705078125,\n",
              "   451.5250244140625,\n",
              "   427.8238220214844,\n",
              "   501.2845153808594,\n",
              "   475.8056945800781,\n",
              "   430.2904052734375,\n",
              "   459.2113952636719,\n",
              "   439.72412109375,\n",
              "   445.4586181640625,\n",
              "   503.2437744140625,\n",
              "   547.6943359375,\n",
              "   480.7666015625,\n",
              "   445.3846740722656,\n",
              "   460.3218078613281,\n",
              "   478.1346435546875,\n",
              "   511.0473327636719,\n",
              "   453.5604248046875,\n",
              "   472.4878845214844,\n",
              "   503.19677734375,\n",
              "   470.4921569824219,\n",
              "   460.35211181640625,\n",
              "   469.4991455078125,\n",
              "   509.3726501464844,\n",
              "   464.2705078125,\n",
              "   505.6419372558594,\n",
              "   511.9922180175781],\n",
              "  'val_root_mean_squared_error': [33.18336486816406,\n",
              "   26.347177505493164,\n",
              "   23.660436630249023,\n",
              "   22.466936111450195,\n",
              "   20.624073028564453,\n",
              "   20.65131950378418,\n",
              "   20.274158477783203,\n",
              "   20.225318908691406,\n",
              "   20.107786178588867,\n",
              "   20.080434799194336,\n",
              "   20.087526321411133,\n",
              "   20.085601806640625,\n",
              "   20.07501792907715,\n",
              "   20.067556381225586,\n",
              "   20.070789337158203,\n",
              "   20.086206436157227,\n",
              "   20.064516067504883,\n",
              "   20.09785270690918,\n",
              "   20.066829681396484,\n",
              "   20.06185531616211,\n",
              "   20.084800720214844,\n",
              "   20.082155227661133,\n",
              "   20.073925018310547,\n",
              "   20.12533950805664,\n",
              "   20.079137802124023,\n",
              "   20.16535186767578,\n",
              "   20.144376754760742,\n",
              "   20.245708465576172,\n",
              "   20.18467903137207,\n",
              "   20.160661697387695,\n",
              "   20.17969512939453,\n",
              "   20.253009796142578,\n",
              "   20.35713005065918,\n",
              "   20.882726669311523,\n",
              "   20.482973098754883,\n",
              "   20.97020149230957,\n",
              "   20.399145126342773,\n",
              "   22.100317001342773,\n",
              "   21.533889770507812,\n",
              "   20.46405601501465,\n",
              "   21.158615112304688,\n",
              "   20.686067581176758,\n",
              "   20.82596778869629,\n",
              "   22.15638542175293,\n",
              "   23.126888275146484,\n",
              "   21.654470443725586,\n",
              "   20.801254272460938,\n",
              "   21.180418014526367,\n",
              "   21.589235305786133,\n",
              "   22.33209228515625,\n",
              "   21.015544891357422,\n",
              "   21.456117630004883,\n",
              "   22.154033660888672,\n",
              "   21.416990280151367,\n",
              "   21.17445182800293,\n",
              "   21.394329071044922,\n",
              "   22.290422439575195,\n",
              "   21.26347541809082,\n",
              "   22.208967208862305,\n",
              "   22.35190773010254]},\n",
              " 2: {'loss': [1026.2979736328125,\n",
              "   760.4307250976562,\n",
              "   645.1026000976562,\n",
              "   591.9631958007812,\n",
              "   533.486572265625,\n",
              "   499.2745056152344,\n",
              "   469.9476013183594,\n",
              "   461.4844055175781,\n",
              "   459.0132141113281,\n",
              "   452.92889404296875,\n",
              "   450.3601379394531,\n",
              "   447.8945007324219,\n",
              "   445.1248474121094,\n",
              "   439.6002197265625,\n",
              "   439.71112060546875,\n",
              "   437.3597106933594,\n",
              "   435.51947021484375,\n",
              "   434.4826354980469,\n",
              "   436.0539855957031,\n",
              "   431.78076171875,\n",
              "   432.0769958496094,\n",
              "   430.3959045410156,\n",
              "   429.197509765625,\n",
              "   427.9454345703125,\n",
              "   424.2991027832031,\n",
              "   423.0176086425781,\n",
              "   417.6878967285156,\n",
              "   415.03045654296875,\n",
              "   408.54302978515625,\n",
              "   404.5655517578125,\n",
              "   401.34820556640625,\n",
              "   393.9520568847656,\n",
              "   384.87432861328125,\n",
              "   381.5228271484375,\n",
              "   365.10357666015625,\n",
              "   361.08197021484375,\n",
              "   361.5103759765625,\n",
              "   344.8808288574219,\n",
              "   340.9526672363281,\n",
              "   339.1535949707031,\n",
              "   322.5914611816406,\n",
              "   318.9099426269531,\n",
              "   310.7257995605469,\n",
              "   309.8627014160156,\n",
              "   302.6697082519531,\n",
              "   296.69549560546875,\n",
              "   287.0359802246094,\n",
              "   280.4860534667969,\n",
              "   280.1419677734375,\n",
              "   269.15972900390625,\n",
              "   273.8144836425781,\n",
              "   264.8984069824219,\n",
              "   258.2985534667969,\n",
              "   255.65711975097656,\n",
              "   251.9371795654297,\n",
              "   249.45504760742188,\n",
              "   244.22439575195312,\n",
              "   245.276611328125,\n",
              "   238.89974975585938,\n",
              "   234.7637481689453],\n",
              "  'root_mean_squared_error': [29.2467041015625,\n",
              "   25.52357292175293,\n",
              "   23.84158706665039,\n",
              "   23.21015167236328,\n",
              "   22.261568069458008,\n",
              "   21.697154998779297,\n",
              "   21.122068405151367,\n",
              "   20.9798583984375,\n",
              "   20.950729370117188,\n",
              "   20.838226318359375,\n",
              "   20.80498695373535,\n",
              "   20.775663375854492,\n",
              "   20.728239059448242,\n",
              "   20.6119384765625,\n",
              "   20.623641967773438,\n",
              "   20.585744857788086,\n",
              "   20.548748016357422,\n",
              "   20.53803825378418,\n",
              "   20.582656860351562,\n",
              "   20.48757553100586,\n",
              "   20.503015518188477,\n",
              "   20.463022232055664,\n",
              "   20.43507194519043,\n",
              "   20.408597946166992,\n",
              "   20.31712532043457,\n",
              "   20.282194137573242,\n",
              "   20.147966384887695,\n",
              "   20.0864315032959,\n",
              "   19.913328170776367,\n",
              "   19.814619064331055,\n",
              "   19.733034133911133,\n",
              "   19.543561935424805,\n",
              "   19.303876876831055,\n",
              "   19.216474533081055,\n",
              "   18.774446487426758,\n",
              "   18.671436309814453,\n",
              "   18.687763214111328,\n",
              "   18.231576919555664,\n",
              "   18.119831085205078,\n",
              "   18.06605339050293,\n",
              "   17.6004638671875,\n",
              "   17.495920181274414,\n",
              "   17.262113571166992,\n",
              "   17.233442306518555,\n",
              "   17.025466918945312,\n",
              "   16.844051361083984,\n",
              "   16.54745101928711,\n",
              "   16.354570388793945,\n",
              "   16.34086036682129,\n",
              "   15.997753143310547,\n",
              "   16.14716911315918,\n",
              "   15.864715576171875,\n",
              "   15.65451717376709,\n",
              "   15.563314437866211,\n",
              "   15.449893951416016,\n",
              "   15.374611854553223,\n",
              "   15.198323249816895,\n",
              "   15.230179786682129,\n",
              "   15.017699241638184,\n",
              "   14.88793659210205],\n",
              "  'val_loss': [796.2496337890625,\n",
              "   715.6795043945312,\n",
              "   675.0823364257812,\n",
              "   595.0806884765625,\n",
              "   546.0389404296875,\n",
              "   510.6976013183594,\n",
              "   488.38360595703125,\n",
              "   482.37469482421875,\n",
              "   488.67181396484375,\n",
              "   480.8089599609375,\n",
              "   481.3841247558594,\n",
              "   477.3099060058594,\n",
              "   476.3994140625,\n",
              "   476.64886474609375,\n",
              "   475.80780029296875,\n",
              "   474.91888427734375,\n",
              "   474.9572448730469,\n",
              "   474.2699890136719,\n",
              "   475.47698974609375,\n",
              "   473.9122314453125,\n",
              "   472.8995056152344,\n",
              "   473.0951232910156,\n",
              "   476.5805358886719,\n",
              "   473.9678649902344,\n",
              "   473.16363525390625,\n",
              "   478.29473876953125,\n",
              "   481.5248107910156,\n",
              "   475.5913391113281,\n",
              "   480.6865539550781,\n",
              "   488.4847106933594,\n",
              "   483.50213623046875,\n",
              "   492.7798767089844,\n",
              "   549.2379760742188,\n",
              "   505.33056640625,\n",
              "   491.42889404296875,\n",
              "   513.1527709960938,\n",
              "   530.2393188476562,\n",
              "   515.4802856445312,\n",
              "   508.9591979980469,\n",
              "   508.8435363769531,\n",
              "   541.680908203125,\n",
              "   548.100830078125,\n",
              "   536.429931640625,\n",
              "   511.0445556640625,\n",
              "   552.208984375,\n",
              "   532.1001586914062,\n",
              "   526.7752685546875,\n",
              "   542.2676391601562,\n",
              "   544.0393676757812,\n",
              "   554.4202270507812,\n",
              "   537.520751953125,\n",
              "   539.6844482421875,\n",
              "   532.8272094726562,\n",
              "   546.2827758789062,\n",
              "   546.6055908203125,\n",
              "   562.8751831054688,\n",
              "   542.4439697265625,\n",
              "   531.4000854492188,\n",
              "   518.6278076171875,\n",
              "   530.7136840820312],\n",
              "  'val_root_mean_squared_error': [22.813343048095703,\n",
              "   25.769804000854492,\n",
              "   25.296751022338867,\n",
              "   23.773754119873047,\n",
              "   22.831512451171875,\n",
              "   22.11355209350586,\n",
              "   21.616039276123047,\n",
              "   21.490631103515625,\n",
              "   21.67580795288086,\n",
              "   21.516008377075195,\n",
              "   21.541139602661133,\n",
              "   21.48059844970703,\n",
              "   21.480531692504883,\n",
              "   21.50502586364746,\n",
              "   21.496152877807617,\n",
              "   21.483259201049805,\n",
              "   21.492441177368164,\n",
              "   21.494796752929688,\n",
              "   21.530193328857422,\n",
              "   21.500743865966797,\n",
              "   21.475770950317383,\n",
              "   21.479480743408203,\n",
              "   21.572471618652344,\n",
              "   21.498302459716797,\n",
              "   21.48977279663086,\n",
              "   21.61433219909668,\n",
              "   21.68731689453125,\n",
              "   21.541013717651367,\n",
              "   21.661209106445312,\n",
              "   21.840402603149414,\n",
              "   21.722984313964844,\n",
              "   21.93840980529785,\n",
              "   23.16061782836914,\n",
              "   22.219188690185547,\n",
              "   21.91282844543457,\n",
              "   22.392871856689453,\n",
              "   22.764404296875,\n",
              "   22.449214935302734,\n",
              "   22.305299758911133,\n",
              "   22.285198211669922,\n",
              "   23.017242431640625,\n",
              "   23.14960479736328,\n",
              "   22.904193878173828,\n",
              "   22.35038948059082,\n",
              "   23.24070930480957,\n",
              "   22.811994552612305,\n",
              "   22.703128814697266,\n",
              "   23.031654357910156,\n",
              "   23.068218231201172,\n",
              "   23.28961753845215,\n",
              "   22.929443359375,\n",
              "   22.98137092590332,\n",
              "   22.83176612854004,\n",
              "   23.122940063476562,\n",
              "   23.135265350341797,\n",
              "   23.46866226196289,\n",
              "   23.040708541870117,\n",
              "   22.804697036743164,\n",
              "   22.5184326171875,\n",
              "   22.789623260498047]},\n",
              " 3: {'loss': [1014.3031616210938,\n",
              "   769.9439086914062,\n",
              "   688.7645874023438,\n",
              "   590.6585693359375,\n",
              "   527.0341796875,\n",
              "   504.4958190917969,\n",
              "   482.0845947265625,\n",
              "   471.766357421875,\n",
              "   464.0615234375,\n",
              "   460.43646240234375,\n",
              "   457.9920959472656,\n",
              "   455.6881408691406,\n",
              "   456.4579162597656,\n",
              "   450.2864685058594,\n",
              "   451.02392578125,\n",
              "   450.4827575683594,\n",
              "   445.7984924316406,\n",
              "   445.4461975097656,\n",
              "   442.95074462890625,\n",
              "   442.6978454589844,\n",
              "   441.63372802734375,\n",
              "   438.1549987792969,\n",
              "   436.69866943359375,\n",
              "   435.25537109375,\n",
              "   428.86328125,\n",
              "   427.4954528808594,\n",
              "   422.5837707519531,\n",
              "   417.7961730957031,\n",
              "   416.42498779296875,\n",
              "   406.0945739746094,\n",
              "   408.15655517578125,\n",
              "   402.8792419433594,\n",
              "   391.76531982421875,\n",
              "   384.7599182128906,\n",
              "   385.7330017089844,\n",
              "   378.7682800292969,\n",
              "   372.3800048828125,\n",
              "   357.6864318847656,\n",
              "   362.5713195800781,\n",
              "   347.4418029785156,\n",
              "   344.95904541015625,\n",
              "   337.98980712890625,\n",
              "   335.39990234375,\n",
              "   329.25030517578125,\n",
              "   325.7970886230469,\n",
              "   323.2182312011719,\n",
              "   316.8212890625,\n",
              "   312.61602783203125,\n",
              "   309.4603576660156,\n",
              "   310.0970764160156,\n",
              "   303.99676513671875,\n",
              "   301.6741638183594,\n",
              "   299.4657897949219,\n",
              "   288.96685791015625,\n",
              "   289.5295104980469,\n",
              "   280.57086181640625,\n",
              "   279.5380859375,\n",
              "   271.2388000488281,\n",
              "   276.9801330566406,\n",
              "   273.5190124511719],\n",
              "  'root_mean_squared_error': [28.700788497924805,\n",
              "   25.5362548828125,\n",
              "   24.622934341430664,\n",
              "   23.199750900268555,\n",
              "   22.212129592895508,\n",
              "   21.856096267700195,\n",
              "   21.433887481689453,\n",
              "   21.233793258666992,\n",
              "   21.094497680664062,\n",
              "   21.03838348388672,\n",
              "   20.98394203186035,\n",
              "   20.963031768798828,\n",
              "   21.009401321411133,\n",
              "   20.87609100341797,\n",
              "   20.900482177734375,\n",
              "   20.899505615234375,\n",
              "   20.798925399780273,\n",
              "   20.80113983154297,\n",
              "   20.74249267578125,\n",
              "   20.739442825317383,\n",
              "   20.717021942138672,\n",
              "   20.63376235961914,\n",
              "   20.593935012817383,\n",
              "   20.562450408935547,\n",
              "   20.412189483642578,\n",
              "   20.376638412475586,\n",
              "   20.24913787841797,\n",
              "   20.13236427307129,\n",
              "   20.09107780456543,\n",
              "   19.830303192138672,\n",
              "   19.87308120727539,\n",
              "   19.7462158203125,\n",
              "   19.457935333251953,\n",
              "   19.27920913696289,\n",
              "   19.30844497680664,\n",
              "   19.12592315673828,\n",
              "   18.95052146911621,\n",
              "   18.554941177368164,\n",
              "   18.686803817749023,\n",
              "   18.274738311767578,\n",
              "   18.200666427612305,\n",
              "   18.00861167907715,\n",
              "   17.943944931030273,\n",
              "   17.765430450439453,\n",
              "   17.660188674926758,\n",
              "   17.598417282104492,\n",
              "   17.410541534423828,\n",
              "   17.290090560913086,\n",
              "   17.19923210144043,\n",
              "   17.216442108154297,\n",
              "   17.039335250854492,\n",
              "   16.969514846801758,\n",
              "   16.903759002685547,\n",
              "   16.594364166259766,\n",
              "   16.611114501953125,\n",
              "   16.33846092224121,\n",
              "   16.301454544067383,\n",
              "   16.048521041870117,\n",
              "   16.226076126098633,\n",
              "   16.117198944091797],\n",
              "  'val_loss': [845.3635864257812,\n",
              "   686.4224243164062,\n",
              "   633.6516723632812,\n",
              "   498.3722839355469,\n",
              "   447.5836181640625,\n",
              "   451.4355773925781,\n",
              "   434.6067810058594,\n",
              "   432.6063232421875,\n",
              "   431.1154479980469,\n",
              "   431.4046325683594,\n",
              "   430.0003967285156,\n",
              "   428.29461669921875,\n",
              "   427.7178955078125,\n",
              "   427.6734924316406,\n",
              "   427.005126953125,\n",
              "   428.03607177734375,\n",
              "   427.8170471191406,\n",
              "   427.4122619628906,\n",
              "   431.272216796875,\n",
              "   430.5745849609375,\n",
              "   428.9764099121094,\n",
              "   435.74102783203125,\n",
              "   428.9800109863281,\n",
              "   432.0968017578125,\n",
              "   431.7751770019531,\n",
              "   442.2822570800781,\n",
              "   433.9159851074219,\n",
              "   437.8419189453125,\n",
              "   449.7313232421875,\n",
              "   442.25177001953125,\n",
              "   438.3662109375,\n",
              "   447.06854248046875,\n",
              "   459.08087158203125,\n",
              "   468.0964050292969,\n",
              "   493.0352783203125,\n",
              "   465.5264587402344,\n",
              "   463.322998046875,\n",
              "   462.9461364746094,\n",
              "   489.091064453125,\n",
              "   530.497802734375,\n",
              "   463.8011474609375,\n",
              "   491.74444580078125,\n",
              "   461.612060546875,\n",
              "   463.2843933105469,\n",
              "   507.5822448730469,\n",
              "   471.1097412109375,\n",
              "   487.722900390625,\n",
              "   465.04949951171875,\n",
              "   514.397216796875,\n",
              "   483.9346618652344,\n",
              "   487.52227783203125,\n",
              "   467.2669372558594,\n",
              "   484.1822204589844,\n",
              "   518.814208984375,\n",
              "   506.0990905761719,\n",
              "   501.03656005859375,\n",
              "   504.3838195800781,\n",
              "   477.25634765625,\n",
              "   471.9556579589844,\n",
              "   505.8594970703125],\n",
              "  'val_root_mean_squared_error': [28.014436721801758,\n",
              "   25.15671157836914,\n",
              "   24.371259689331055,\n",
              "   21.685155868530273,\n",
              "   20.570280075073242,\n",
              "   20.760438919067383,\n",
              "   20.355220794677734,\n",
              "   20.346050262451172,\n",
              "   20.340322494506836,\n",
              "   20.330364227294922,\n",
              "   20.337379455566406,\n",
              "   20.332508087158203,\n",
              "   20.33343505859375,\n",
              "   20.33382797241211,\n",
              "   20.331308364868164,\n",
              "   20.366374969482422,\n",
              "   20.36675262451172,\n",
              "   20.352619171142578,\n",
              "   20.465456008911133,\n",
              "   20.45670509338379,\n",
              "   20.417591094970703,\n",
              "   20.546201705932617,\n",
              "   20.429039001464844,\n",
              "   20.48630714416504,\n",
              "   20.47916603088379,\n",
              "   20.742271423339844,\n",
              "   20.542253494262695,\n",
              "   20.64031982421875,\n",
              "   20.923856735229492,\n",
              "   20.71208381652832,\n",
              "   20.64860725402832,\n",
              "   20.850955963134766,\n",
              "   21.144710540771484,\n",
              "   21.355863571166992,\n",
              "   21.921428680419922,\n",
              "   21.293994903564453,\n",
              "   21.233633041381836,\n",
              "   21.20752716064453,\n",
              "   21.836267471313477,\n",
              "   22.75311851501465,\n",
              "   21.2506046295166,\n",
              "   21.891803741455078,\n",
              "   21.189809799194336,\n",
              "   21.21474266052246,\n",
              "   22.25105857849121,\n",
              "   21.419301986694336,\n",
              "   21.798065185546875,\n",
              "   21.278993606567383,\n",
              "   22.403148651123047,\n",
              "   21.721128463745117,\n",
              "   21.803903579711914,\n",
              "   21.302627563476562,\n",
              "   21.729625701904297,\n",
              "   22.500953674316406,\n",
              "   22.22186279296875,\n",
              "   22.107851028442383,\n",
              "   22.176923751831055,\n",
              "   21.56039047241211,\n",
              "   21.432598114013672,\n",
              "   22.216489791870117]},\n",
              " 4: {'loss': [990.4409790039062,\n",
              "   710.7258911132812,\n",
              "   639.7691040039062,\n",
              "   565.4197387695312,\n",
              "   521.2809448242188,\n",
              "   496.2420349121094,\n",
              "   487.9461975097656,\n",
              "   475.29949951171875,\n",
              "   468.3984069824219,\n",
              "   462.81243896484375,\n",
              "   461.35662841796875,\n",
              "   455.5858154296875,\n",
              "   458.0783386230469,\n",
              "   452.7810974121094,\n",
              "   452.008544921875,\n",
              "   452.3397216796875,\n",
              "   448.7863464355469,\n",
              "   446.8392333984375,\n",
              "   444.9931945800781,\n",
              "   444.43389892578125,\n",
              "   443.69427490234375,\n",
              "   443.269775390625,\n",
              "   439.8030090332031,\n",
              "   439.0741271972656,\n",
              "   441.17022705078125,\n",
              "   437.62603759765625,\n",
              "   438.56121826171875,\n",
              "   435.5592041015625,\n",
              "   435.5257873535156,\n",
              "   433.0193786621094,\n",
              "   431.9662780761719,\n",
              "   431.31988525390625,\n",
              "   429.17889404296875,\n",
              "   426.8388366699219,\n",
              "   428.9516906738281,\n",
              "   423.64398193359375,\n",
              "   419.68572998046875,\n",
              "   415.8890380859375,\n",
              "   415.0217590332031,\n",
              "   413.3240051269531,\n",
              "   408.3043212890625,\n",
              "   401.0409240722656,\n",
              "   396.7835388183594,\n",
              "   394.6422424316406,\n",
              "   392.6076354980469,\n",
              "   385.2344970703125,\n",
              "   383.4850769042969,\n",
              "   373.3780212402344,\n",
              "   371.5387878417969,\n",
              "   368.8185729980469,\n",
              "   361.7339172363281,\n",
              "   367.85931396484375,\n",
              "   358.8210144042969,\n",
              "   356.54888916015625,\n",
              "   347.5976867675781,\n",
              "   346.222412109375,\n",
              "   342.2188415527344,\n",
              "   337.856689453125,\n",
              "   330.69775390625,\n",
              "   331.7690734863281],\n",
              "  'root_mean_squared_error': [28.360027313232422,\n",
              "   24.77679443359375,\n",
              "   24.02028465270996,\n",
              "   22.875457763671875,\n",
              "   22.114770889282227,\n",
              "   21.662799835205078,\n",
              "   21.545381546020508,\n",
              "   21.30613136291504,\n",
              "   21.173133850097656,\n",
              "   21.079179763793945,\n",
              "   21.077800750732422,\n",
              "   20.967016220092773,\n",
              "   21.03983497619629,\n",
              "   20.934961318969727,\n",
              "   20.926761627197266,\n",
              "   20.951126098632812,\n",
              "   20.876754760742188,\n",
              "   20.837268829345703,\n",
              "   20.795106887817383,\n",
              "   20.782793045043945,\n",
              "   20.773439407348633,\n",
              "   20.772890090942383,\n",
              "   20.692991256713867,\n",
              "   20.68327522277832,\n",
              "   20.72993278503418,\n",
              "   20.65593910217285,\n",
              "   20.667455673217773,\n",
              "   20.601167678833008,\n",
              "   20.60621452331543,\n",
              "   20.548704147338867,\n",
              "   20.518367767333984,\n",
              "   20.503219604492188,\n",
              "   20.440528869628906,\n",
              "   20.383941650390625,\n",
              "   20.4290714263916,\n",
              "   20.31159019470215,\n",
              "   20.210901260375977,\n",
              "   20.109533309936523,\n",
              "   20.086652755737305,\n",
              "   20.032825469970703,\n",
              "   19.918075561523438,\n",
              "   19.73659324645996,\n",
              "   19.62209129333496,\n",
              "   19.557323455810547,\n",
              "   19.50843620300293,\n",
              "   19.31984519958496,\n",
              "   19.270334243774414,\n",
              "   19.00641441345215,\n",
              "   18.959026336669922,\n",
              "   18.886646270751953,\n",
              "   18.696434020996094,\n",
              "   18.85658836364746,\n",
              "   18.61107063293457,\n",
              "   18.559730529785156,\n",
              "   18.312580108642578,\n",
              "   18.27117919921875,\n",
              "   18.15723419189453,\n",
              "   18.042173385620117,\n",
              "   17.842153549194336,\n",
              "   17.8699893951416],\n",
              "  'val_loss': [779.7796020507812,\n",
              "   676.1766967773438,\n",
              "   593.9522705078125,\n",
              "   507.63934326171875,\n",
              "   463.86444091796875,\n",
              "   457.6474304199219,\n",
              "   446.4460754394531,\n",
              "   437.3678283691406,\n",
              "   434.5077209472656,\n",
              "   433.4433288574219,\n",
              "   430.87310791015625,\n",
              "   430.7991027832031,\n",
              "   428.826171875,\n",
              "   429.1296691894531,\n",
              "   428.7757263183594,\n",
              "   429.04193115234375,\n",
              "   429.3440246582031,\n",
              "   426.08099365234375,\n",
              "   432.8857727050781,\n",
              "   429.10137939453125,\n",
              "   426.2980651855469,\n",
              "   428.2368469238281,\n",
              "   429.9275207519531,\n",
              "   425.8922424316406,\n",
              "   425.53887939453125,\n",
              "   426.4158020019531,\n",
              "   433.7961120605469,\n",
              "   432.9589538574219,\n",
              "   429.8051452636719,\n",
              "   429.2532043457031,\n",
              "   429.5375671386719,\n",
              "   431.2261047363281,\n",
              "   431.5452880859375,\n",
              "   432.9524230957031,\n",
              "   428.7832946777344,\n",
              "   430.58856201171875,\n",
              "   436.1217956542969,\n",
              "   444.81451416015625,\n",
              "   435.6260681152344,\n",
              "   437.7894592285156,\n",
              "   438.8381652832031,\n",
              "   437.1029968261719,\n",
              "   457.1868591308594,\n",
              "   443.4967041015625,\n",
              "   445.6976318359375,\n",
              "   444.34796142578125,\n",
              "   446.2195129394531,\n",
              "   478.9062805175781,\n",
              "   457.7483215332031,\n",
              "   451.38226318359375,\n",
              "   487.453369140625,\n",
              "   461.994140625,\n",
              "   464.13385009765625,\n",
              "   514.6404418945312,\n",
              "   448.3945617675781,\n",
              "   530.1728515625,\n",
              "   494.52984619140625,\n",
              "   463.53497314453125,\n",
              "   453.9010925292969,\n",
              "   475.6392517089844],\n",
              "  'val_root_mean_squared_error': [27.042137145996094,\n",
              "   25.218978881835938,\n",
              "   23.772024154663086,\n",
              "   21.955881118774414,\n",
              "   20.9642333984375,\n",
              "   20.875524520874023,\n",
              "   20.651214599609375,\n",
              "   20.394119262695312,\n",
              "   20.395065307617188,\n",
              "   20.404695510864258,\n",
              "   20.35331153869629,\n",
              "   20.37165069580078,\n",
              "   20.35162353515625,\n",
              "   20.371292114257812,\n",
              "   20.3887882232666,\n",
              "   20.388660430908203,\n",
              "   20.41786766052246,\n",
              "   20.34286117553711,\n",
              "   20.498035430908203,\n",
              "   20.427587509155273,\n",
              "   20.360715866088867,\n",
              "   20.427703857421875,\n",
              "   20.46915054321289,\n",
              "   20.36794090270996,\n",
              "   20.371604919433594,\n",
              "   20.390047073364258,\n",
              "   20.561691284179688,\n",
              "   20.52930450439453,\n",
              "   20.460859298706055,\n",
              "   20.449464797973633,\n",
              "   20.475587844848633,\n",
              "   20.482749938964844,\n",
              "   20.49889373779297,\n",
              "   20.548498153686523,\n",
              "   20.461761474609375,\n",
              "   20.496557235717773,\n",
              "   20.640392303466797,\n",
              "   20.839540481567383,\n",
              "   20.57502555847168,\n",
              "   20.668760299682617,\n",
              "   20.690364837646484,\n",
              "   20.651296615600586,\n",
              "   21.12877082824707,\n",
              "   20.746849060058594,\n",
              "   20.841629028320312,\n",
              "   20.781387329101562,\n",
              "   20.82785987854004,\n",
              "   21.60851287841797,\n",
              "   21.121671676635742,\n",
              "   20.948352813720703,\n",
              "   21.822372436523438,\n",
              "   21.232145309448242,\n",
              "   21.285842895507812,\n",
              "   22.428197860717773,\n",
              "   20.903278350830078,\n",
              "   22.766746520996094,\n",
              "   21.978185653686523,\n",
              "   21.2680606842041,\n",
              "   21.03229522705078,\n",
              "   21.546030044555664]}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = 301.0124816894531 + 285.4732360839844 + 234.7637481689453 + 273.5190124511719 + 331.7690734863281\n",
        "val_loss = 517.7337646484375 + 511.9922180175781 + 530.7136840820312 + 505.8594970703125 + 475.6392517089844\n",
        "\n",
        "train_loss_avg = train_loss / 5\n",
        "val_loss_avg = val_loss / 5\n"
      ],
      "metadata": {
        "id": "QJ2ss6_2bVJX"
      },
      "id": "QJ2ss6_2bVJX",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train loss is: {train_loss_avg}')\n",
        "print(f'val loss is: {val_loss_avg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hax9hmb2cVso",
        "outputId": "0de8d787-52dc-4c80-a7ae-9fa68e2b3b91"
      },
      "id": "Hax9hmb2cVso",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss is: 285.30751037597656\n",
            "val loss is: 508.38768310546874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = np.array(np.zeros(2))\n",
        "train_val = np.array(np.zeros(2))\n",
        "test_loss = np.array(np.zeros(2))\n",
        "test_val = np.array(np.zeros(2))\n",
        "\n",
        "for epoch in loss_df.items():\n",
        "  train_loss += epoch[1]['loss']\n",
        "  train_val += epoch[1]['root_mean_squared_error']\n",
        "  test_loss += epoch[1]['val_loss']\n",
        "  test_val += epoch[1]['val_root_mean_squared_error']\n",
        "\n",
        "display(test_val)"
      ],
      "metadata": {
        "id": "DCDlt7aXKX16"
      },
      "id": "DCDlt7aXKX16",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "K_fold_grafiekje.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}