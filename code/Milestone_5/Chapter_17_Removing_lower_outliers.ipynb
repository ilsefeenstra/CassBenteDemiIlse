{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3915ca73",
      "metadata": {
        "id": "3915ca73"
      },
      "source": [
        "# Extra convolutional layers\n",
        "In this chapter we will add more convolutional layers to increase the complexity of the model. In this way the model might learn the data better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vRjBTUzjlmKA",
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras import backend as K\n",
        "from keras import activations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFZWcvRBvYv_",
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fANqjfPxoHI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "9cea62f8-6fdf-412e-e06f-fb871282be97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-28 12:20:48--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-28 12:20:48--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [    <=>             ]   1001M  21.5MB/s    in 48s     \n",
            "\n",
            "2022-01-28 12:21:35 (21.1 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1049813265]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ae10a3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8ae10a3a",
        "outputId": "a7c00d1f-60f9-472f-d66b-1d270ef6948b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21c143e0-45a5-4030-b813-48e0b39519bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21c143e0-45a5-4030-b813-48e0b39519bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21c143e0-45a5-4030-b813-48e0b39519bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21c143e0-45a5-4030-b813-48e0b39519bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "SRYM1P29o8k1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "1bfe2428-76b6-477a-b608-0232a40d37f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfyElEQVR4nO3deZwcVb338c+XsEskLDFCEgxqEMEFMBJQLw/C1Ue2C3qRRZFFNBcNj6CgIG7RK8p9LoIiiEZBQJFVkIgosuhFFNAEEAjBlxGDSQgkBAJJWBN+949z2lSanpmqyfR09/T3/XrNa6pObb+uqalfn1NVpxQRmJmZlbVWqwMwM7PO4sRhZmaVOHGYmVklThxmZlaJE4eZmVXixGFmZpU4cVi/SfqtpI/k4Q9K+vUArnumpN3z8BRJPx7AdZ8i6QcDtb4K232vpLmSlknascT8u0uaNxixNdj2OEkhae1+Lj9H0r8OdFyDtX7rnRNHh8j/KM9IWippiaQ/SDpGUqm/4ZqeCPoSERdHxLtLxHGBpK+WWN/2EfHbNY2r0ck3Ir4WER9Z03X3w+nAsRGxUUTcVT8x/31e24wNSzpS0q3NWHe7a+Z+7VZOHJ1lv4gYDrwKOA04CTivtSENrGYltjbxKmBmq4NoZ0P87z9kOHF0oIh4MiKmAQcDR0h6A4CkfSTdJemp3CQypbDYLfn3ktxUsquk10i6WdJiSY9JuljSiJ62K+ldkh6Q9KSkswEVpv3zG62SMyUtzLHcK+kNkiYBHwQ+k2P4eZ5/jqSTJN0DLJe0doOmiPUlXZZrXHdKenNh26t9o6zVaiS9DPglsGXe3jJJW9Y3fUn6t9w0tiQ3v72+MG2OpBMl3ZM/92WS1u9h/6wl6fOSHsqf/SJJG0taT9IyYBjwZ0l/a7Bs7e/z5xznwYVpJ+T1LZB0VKF8PUmnS/qHpEclfVfSBg3W/Xrgu8Cued1Lcnlvx0vNhyU9nLd9Yv0+Loz32KwmaWdJt+X9u0DS2ZLWLUwPSZMl/RX4aw/r+FDer4slfa7s+hvtV0mbSLpW0iJJT+ThMY22a405cXSwiPgjMA/4l1y0HDgcGAHsA3xM0gF52m7594jcVHIb6cT/dWBL4PXAWGBKo21J2hy4Cvg8sDnwN+DtPYT27ry9bYCNgYOAxRExFbgY+P85hv0KyxyaYx4RESsarHN/4ApgU+AnwM8krdPD9gGIiOXAXsDDeXsbRcTDdZ9rG+AS4HhgJHAd8PPiiS3H/x5ga+BNwJE9bPLI/PNO4NXARsDZEfFcRGyU53lzRLymQay7FaZvFBGX5fFXkvbhaOBo4BxJm+Rpp5H28Q7Aa/M8X2yw7lnAMcBted21Lwe9HS817wTGk/6mJ6l/1xVWAp8kHTe7AnsCH6+b5wBgIrBd/cKStgPOBT5EOlY3A4on+h7X38N+XQv4IakGuBXwDHB2Pz5X13Li6HwPk06mRMRvI+LeiHgxIu4hnRD/T08LRsTsiLghn9gWAWf0Mv/ewMyIuDIiXgC+CTzSw7wvAMOBbQFFxKyIWNDH5zgrIuZGxDM9TJ9R2PYZwPrALn2ss4yDgV/k/fAC6TrEBsDb6mJ7OCIeB35OOlE38kHgjIh4MCKWAZ8FDtGaNb+8AHwlIl6IiOuAZcDrJAmYBHwyIh6PiKXA14BDyq645PHy5YhYHhH3kk62h1b9ABExIyJuj4gVETEH+F6D7Xw9f45Gf/8DgWsj4paIeA74AvBixfUX41kcET+NiKfzfju1t/ntpdye2PlGA48DSJpI+hb6BmBdYD3St/SGJI0CvkWqsQwnfZF4oofZtwTm1kYiIiTNbTRjRNycm7LOAV4l6SrgxIh4qpfP0XBdjaZHxIu5WWTLPpYpY0vgobp1zyXt15pigny6l+2utq48vDYwCpjfz/gW19XAnibVZEYCGwIzUg4BUg1yWNkVlzxein+Xh4A3Vgk+b2cbUrKfkGNeG5jRy3bq1R97yyUtrrj+YjwbAmeSapG12ttwScMiYmXJj9XVXOPoYJLeSjrB1e6W+QkwDRgbERuT2rVrZ5VG3SB/LZe/MSJeDhxWmL/eAlJTVm3bKo7Xi4izIuItpKaHbYBP9xJHb+U1xW2vRWqqqDU7PU06YdS8ssJ6HyY1WdTWXftc/TnRr7YuUjPICuDRfqyrL4+Rmli2j4gR+WfjQpNYvUb7obfjpab4N96KVft8OT3v83rnAg8A4/NxdkqD7fT2d6o/9jYkNVdVWX/RCcDrgIl5/lpzVm/LWIETRweS9HJJ+wKXAj/OzQiQag2PR8SzknYGPlBYbBGpev/qQtlwUtPHk5JGs+rk3sgvgO0lvS83vXyCHk4Wkt4qaWK+BrEceJZVTQuP1sVQ1lsK2z4eeA64PU+7G/iApGGS3sPqzQ6PAptJ2riH9V4O7CNpzxzvCXndf+hHjJcAn5S0taSNSIn5sh6u2TRSet9ExIvA94EzJb0CQNJoSf+3l3WPqbt209vxUvMFSRtK2h44Cqhde7kb2FvSppJeSfqb9GQ48BSwTNK2wMfKfMaCK4F9Jb0jx/8VVj939bX++v06nJR0l0jaFPhSxXi6nhNHZ/m5pKWkavvnSNXzowrTPw58Jc/zRdJJEYCIeJrUlvv7fPfJLsCXgZ2AJ0mJ4aqeNhwRjwHvJzVtLCZdMP19D7O/nHRSe4LUvLEY+O887TxguxzDz8p/dK4hXY94gnSR9H35mgTAccB+wBLSdYZ/rjciHiCd0B/M21ytmSki/kKqaX2b9C1+P9Jtz89XiK3mfOBHpDvY/k5KmP+vwvJTgAtznAeVmP8kYDZwu6SngBtJ36QbuZl0K/Ajkh7LZT0eLwX/k7dxE3B6RNQe8vwR8GdgDvBrViWURk4kJaWlpOOit3lfIiJmApNJNaQFpGOgeAdXX+ufwur79Zuk61iPkb58/KpKPJYuXLY6BjMz6yCucZiZWSVOHGZmVokTh5mZVeLEYWZmlXT0A4Cbb755jBs3rtVhmJl1lBkzZjwWESP7u3xHJ45x48Yxffr0VodhZtZRJD3U91w9c1OVmZlV4sRhZmaVOHGYmVklThxmZlaJE4eZmVXixGFmZpU4cZiZWSVOHGZmVokTh5mZVdLRT47b4Bt38i/+OTzntH1KTzOzocOJw16imADAScDMVuemKjMzq8SJw8zMKnFTlTWFr3eYDV2ucZiZWSVOHGZmVokTh5mZVdK0xCFpfUl/lPRnSTMlfTmXby3pDkmzJV0mad1cvl4en52nj2tWbGZm1n/NvDj+HLBHRCyTtA5wq6RfAp8CzoyISyV9FzgaODf/fiIiXivpEOC/gIObGJ+tofrnPcysOzQtcUREAMvy6Dr5J4A9gA/k8guBKaTEsX8eBrgSOFuS8nqshZwgzKyoqdc4JA2TdDewELgB+BuwJCJW5FnmAaPz8GhgLkCe/iSwWYN1TpI0XdL0RYsWNTN8MzNroKmJIyJWRsQOwBhgZ2DbAVjn1IiYEBETRo4cucYxmplZNYNyV1VELAF+A+wKjJBUayIbA8zPw/OBsQB5+sbA4sGIz8zMymvmXVUjJY3IwxsA7wJmkRLIgXm2I4Br8vC0PE6efrOvb5iZtZ9m3lW1BXChpGGkBHV5RFwr6X7gUklfBe4Czsvznwf8SNJs4HHgkCbGZmZm/dTMu6ruAXZsUP4g6XpHffmzwPubFY+ZmQ0Md3JoTef3e5gNLe5yxMzMKnGNw8ysCwzkg7yucZiZWSWucRjgbkXMrDzXOMzMrBInDjMzq8SJw8zMKnHiMDOzSpw4zMysEicOMzOrxInDzMwqceIwM7NKnDjMzKwSJw4zM6vEicPMzCpx4jAzs0qcOMzMrBInDjMzq8SJw8zMKnHiMDOzSpw4zMysEicOMzOrxInDzMwqado7xyWNBS4CRgEBTI2Ib0maAnwUWJRnPSUirsvLfBY4GlgJfCIirm9WfOb3jJtZ/zQtcQArgBMi4k5Jw4EZkm7I086MiNOLM0vaDjgE2B7YErhR0jYRsbKJMZqZWUVNa6qKiAURcWceXgrMAkb3ssj+wKUR8VxE/B2YDezcrPjMzKx/BuUah6RxwI7AHbnoWEn3SDpf0ia5bDQwt7DYPBokGkmTJE2XNH3RokX1k83MrMma2VQFgKSNgJ8Cx0fEU5LOBf6TdN3jP4FvAB8uu76ImApMBZgwYUIMfMRDl69pmNlAaGrikLQOKWlcHBFXAUTEo4Xp3weuzaPzgbGFxcfkMhvCektmc07bZxAjMbOymtZUJUnAecCsiDijUL5FYbb3Avfl4WnAIZLWk7Q1MB74Y7PiMzOz/mlmjePtwIeAeyXdnctOAQ6VtAOpqWoO8B8AETFT0uXA/aQ7sib7jiozs/bTtMQREbcCajDpul6WORU4tVkxdSNf1zCzgeYnx83MrJKm31VlVs+1ILPO5hqHmZlV4sRhZmaVOHGYmVklThxmZlaJE4eZmVXixGFmZpX4dlxrW8Xbdt1vlVn7cI3DzMwqcY3DOoJrH2btwzUOMzOrxInDzMwqceIwM7NKnDjMzKwSJw4zM6vEicPMzCpx4jAzs0qcOMzMrBInDjMzq8SJw8zMKnHiMDOzSpw4zMyskqYlDkljJf1G0v2SZko6LpdvKukGSX/NvzfJ5ZJ0lqTZku6RtFOzYjMzs/4rlTjySf0wSV/M41tJ2rmPxVYAJ0TEdsAuwGRJ2wEnAzdFxHjgpjwOsBcwPv9MAs6t/GnMzKzpytY4vgPsChyax5cC5/S2QEQsiIg78/BSYBYwGtgfuDDPdiFwQB7eH7goktuBEZK2KPtBzMxscJRNHBMjYjLwLEBEPAGsW3YjksYBOwJ3AKMiYkGe9AgwKg+PBuYWFpuXy8zMrI2UTRwvSBoGBICkkcCLZRaUtBHwU+D4iHiqOC0iorbOsiRNkjRd0vRFixZVWdTMzAZA2cRxFnA18ApJpwK3Al/rayFJ65CSxsURcVUufrTWBJV/L8zl84GxhcXH5LLVRMTUiJgQERNGjhxZMnwzMxsopRJHRFwMfAb4OrAAOCAiruhtGUkCzgNmRcQZhUnTgCPy8BHANYXyw/OF+F2AJwtNWmZm1iZKvXM8n8hnRsQ5efzlkiZGxB29LPZ24EPAvZLuzmWnAKcBl0s6GngIOChPuw7YG5gNPA0cVfXDmJlZ85VKHKRbY4vPVSxrULaaiLgVUA+T92wwfwCTS8ZjZmYtUjZxKJ/YAYiIFyWVXdZs0Iw7+Rf/HJ5z2j4tjMRs6Cp78n9Q0idY9VDex4EHmxOSraniydPMbKCVvavqGOBtpLuc5gETSU93m5lZlylV44iIhcAhTY7FzMw6QNm7qkYCHwXGFZeJiA83JywzM2tXZa9xXAP8DrgRWNm8cMyao/66jy+cm/Vf2cSxYUSc1NRIzMysI5RNHNdK2jsirmtqNGYDyHeXmTVH2cRxHHCKpOeB50kP9kVEvLxpkZn1wAnBrLXK3lU1vNmBmJlZZ6j6BsAv5PGxJd4AaGZmQ1DVNwB+II8vo483AJqZ2dBU9hrHxIjYSdJdkN4AKKn0GwDNzGzoKJs4+v0GQBscvmBsZoOlqW8ANDOzoafPGoektYC/k94AuCfpVtwDImJWk2MzM7M21GfiyO/eOCcidgQeGISYzMysjZVtqrpJ0r/n94ibmVkXK5s4/gO4AnhO0lOSlkp6qolxmZlZm/KT42ZmVknZ93Hs1qg8Im4Z2HDMzKzdlX2O49OF4fWBnYEZwB4DHpHZICg+9+J3c5hVU7apar/iuKSxwDebEpGZmbW1sjWOevOA1w9kINY3f0s2s3ZQ9hrHt8ndjZDuxNoBuLOPZc4H9gUWRsQbctkU0rvLF+XZTqm9HErSZ4GjSa+m/UREXF/pk5iZ2aAoW+OYXhheAVwSEb/vY5kLgLOBi+rKz4yI04sFkrYDDgG2B7YEbpS0TUT4/eZmZm2mbOK4Eni2diKXNEzShhHxdE8LRMQtksaVXP/+wKUR8Rzwd0mzSRfgbyu5vJmZDZLST44DGxTGNwBu7Oc2j5V0j6TzJW2Sy0YDcwvzzMtlLyFpkqTpkqYvWrSo0SxmZtZEZRPH+hGxrDaShzfsx/bOBV5DukayAPhG1RVExNSImBARE0aOHNmPEMzMbE2UTRzLJe1UG5H0FuCZqhuLiEcjYmVEvAh8n9QcBTAfGFuYdUwuMzOzNlP2GsfxwBWSHiZ1q/5K4OCqG5O0RUQsyKPvBe7Lw9OAn0g6g3RxfDzwx6rr7yZ+cZOZtUrZBwD/JGlb4HW56C8R8UJvy0i6BNgd2FzSPOBLwO6SdiDd2juH1HkiETFT0uXA/aS7tib7jiozs/ZU9jmOycDFEXFfHt9E0qER8Z2elomIQxsUn9fL/KcCp5aJx8zMWqfsNY6PRsSS2khEPEF6kM/MzLpM2cQxrPgSJ0nDgHWbE5KZmbWzshfHrwcuk/S9PH4M8KvmhGRmZu2sbOL4Aqlp6uN5/Hp6uV5hZmZDV6+JQ9LawNeAo1j1ZPdWwIOkZi7f+WRm1mX6qnH8NzAceHVELAWQNJz0xPfpwHHNDc9scNU/H9NT9/Vl5zMbivq6OL4v6Y6qpbWCPPwxYO9mBmZmZu2pr8QRERENCley6v0cZmbWRfpKHPdLOry+UNJhwAPNCcnMzNpZX9c4JgNXSfowMCOXTSB1q/7eZgZmZmbtqdfEERHzgYmS9iC9nQ/guoi4qemRmZlZWyrbyeHNwM1NjsXMzDpA2QcAzYas3rqoL07zLbdmSdm+qszMzAAnDjMzq8iJw8zMKvE1jjbnV8S2D/8tzBLXOMzMrBInDjMzq8SJw8zMKnHiMDOzSpw4zMysEicOMzOrxLfjmg0wd1NiQ13TahySzpe0UNJ9hbJNJd0g6a/59ya5XJLOkjRb0j2SdmpWXGZmtmaaWeO4ADgbuKhQdjJwU0ScJunkPH4SsBcwPv9MBM7Nv806gh8OtG7StBpHRNwCPF5XvD9wYR6+EDigUH5RJLcDIyRt0azYzMys/wb74vioiFiQhx8BRuXh0cDcwnzzctlLSJokabqk6YsWLWpepGZm1lDL7qqKiACiH8tNjYgJETFh5MiRTYjMzMx6M9iJ49FaE1T+vTCXzwfGFuYbk8vMzKzNDHbimAYckYePAK4plB+e767aBXiy0KRlZmZtpGl3VUm6BNgd2FzSPOBLwGnA5ZKOBh4CDsqzXwfsDcwGngaOalZcZma2ZpqWOCLi0B4m7dlg3gAmNysWMzMbOF3x5Lif5DUzGzhdkTjM2lFvX2j8ZcfamTs5NDOzSpw4zMysEicOMzOrxNc42oDbs4eu+s4P/fe1ocA1DjMzq8Q1jkFS9punu+c2s3bnGoeZmVUyZGsc/uZu7cjHpQ0FrnGYmVklThxmZlaJE4eZmVUyZK9xmHUSX/uwTuLE0UQ+GZjZUOTEYdah/FS6tYoTh1kXc3c31h9OHGYdpGzzpxOCNZMTR4v4+oeV5WPF2o0Th9kQ4QRjg8XPcZiZWSVOHGZmVombqsy6jJu0bE21JHFImgMsBVYCKyJigqRNgcuAccAc4KCIeKIV8ZmZWc9a2VT1zojYISIm5PGTgZsiYjxwUx43M7M2007XOPYHLszDFwIHtDAWMzPrQauucQTwa0kBfC8ipgKjImJBnv4IMKrRgpImAZMAttpqq8GItRK3H1unchcmVlarEsc7ImK+pFcAN0h6oDgxIiInlZfISWYqwIQJExrOY2Zrzk+fW09akjgiYn7+vVDS1cDOwKOStoiIBZK2ABa2IjYzeyknESsa9MQh6WXAWhGxNA+/G/gKMA04Ajgt/75msGMzs+Zx8hk6WlHjGAVcLam2/Z9ExK8k/Qm4XNLRwEPAQS2IzczM+jDoiSMiHgTe3KB8MbDnYMdjZmbVtNPtuGZm1gHc5Ug/uK3WOolvEbeB5hqHmZlV0nU1jv4+5NTTtzZ/m7Nu4wcFzTUOMzOrpOtqHPV8vcKsOfrzfnTw/2EncI3DzMwq6foah5mtmf5c5+tPbcQ1kfbhxNEDX/Q2a19u3motJw4z6xquwQwMJw4zayu+9b39OXEU+MA063z9qVW46asaJw4z63j+0je4nDjMzAZAN10/ceIwM+unbq3pOHGYmdXpptpDfzhxmNmQNRA1AieRl3LiMDMbREMhETlxmFlXGqyuUqDnBFF2fe2WYJw4zMw6SDs8c+LEYWbW5tqtU0h3q25mZpW4xmFm1mTNfN6jFc+SuMZhZmaVtF2NQ9J7gG8Bw4AfRMRpZZft1qc4zczqNfN82FY1DknDgHOAvYDtgEMlbdfaqMzMrKitEgewMzA7Ih6MiOeBS4H9WxyTmZkVtFtT1WhgbmF8HjCxOIOkScCkPPqcpPsGKbZ2tznwWKuDaBPeF6t4X6zifbHK69Zk4XZLHH2KiKnAVABJ0yNiQotDagveF6t4X6zifbGK98UqkqavyfLt1lQ1HxhbGB+Ty8zMrE20W+L4EzBe0taS1gUOAaa1OCYzMytoq6aqiFgh6VjgetLtuOdHxMxeFpk6OJF1BO+LVbwvVvG+WMX7YpU12heKiIEKxMzMukC7NVWZmVmbc+IwM7NKOjZxSHqPpL9Imi3p5FbHM5gkjZX0G0n3S5op6bhcvqmkGyT9Nf/epNWxDgZJwyTdJenaPL61pDvysXFZvtGiK0gaIelKSQ9ImiVp1248LiR9Mv9v3CfpEknrd9NxIel8SQuLz7n1dBwoOSvvl3sk7dTX+jsycbhrElYAJ0TEdsAuwOT8+U8GboqI8cBNebwbHAfMKoz/F3BmRLwWeAI4uiVRtca3gF9FxLbAm0n7pauOC0mjgU8AEyLiDaQbbQ6hu46LC4D31JX1dBzsBYzPP5OAc/taeUcmDrq8a5KIWBARd+bhpaSTw2jSPrgwz3YhcEBrIhw8ksYA+wA/yOMC9gCuzLN0xX4AkLQxsBtwHkBEPB8RS+jC44J0x+gGktYGNgQW0EXHRUTcAjxeV9zTcbA/cFEktwMjJG3R2/o7NXE06ppkdItiaSlJ44AdgTuAURGxIE96BBjVorAG0zeBzwAv5vHNgCURsSKPd9OxsTWwCPhhbrr7gaSX0WXHRUTMB04H/kFKGE8CM+je46Kmp+Og8vm0UxOHAZI2An4KHB8RTxWnRbrPekjfay1pX2BhRMxodSxtYm1gJ+DciNgRWE5ds1SXHBebkL5Fbw1sCbyMlzbbdLU1PQ46NXF0fdckktYhJY2LI+KqXPxorYqZfy9sVXyD5O3Av0maQ2qu3IPUxj8iN1FAdx0b84B5EXFHHr+SlEi67bj4V+DvEbEoIl4AriIdK916XNT0dBxUPp92auLo6q5Jcjv+ecCsiDijMGkacEQePgK4ZrBjG0wR8dmIGBMR40jHwM0R8UHgN8CBebYhvx9qIuIRYK6kWs+newL302XHBamJahdJG+b/ldp+6MrjoqCn42AacHi+u2oX4MlCk1ZDHfvkuKS9Se3bta5JTm1xSING0juA3wH3sqpt/xTSdY7Lga2Ah4CDIqL+AtmQJGl34MSI2FfSq0k1kE2Bu4DDIuK5VsY3WCTtQLpRYF3gQeAo0hfErjouJH0ZOJh0B+JdwEdI7fZdcVxIugTYndSV/KPAl4Cf0eA4yMn1bFJz3tPAURHRa++5HZs4zMysNTq1qcrMzFrEicPMzCpx4jAzs0qcOMzMrBInDjMzq8SJwzqKpJWS7s69nl4hacNB3v4Fkg7se87VljlG0uF5+EhJWzYnOrPB4cRhneaZiNgh93r6PHBMqwPqjaS1I+K7EXFRLjqS1A1Gq+KRJP/f2xrxAWSd7HfAayXtl9+zcJekGyWNApB0b34/hSQtLnzrv0jSu/K3/2sk/Ta/o+BLefq4uvcYnChpSv3GJX1R0p9y7WdqfpCKvL5vSpoOHCdpSl7HgcAE4OJca9pH0s8K63uXpKsbbOc0pXev3CPp9Fw2StLVkv6cf96Wyz+V47lP0vGFz/MXSRcB9wFjJX06x35PfljOrDQnDutIuc+hvUhPz98K7JI79ruU1FsuwO9JfRRtT3qK+l9y+a7AH/LwzsC/A28C3i9pQoUwzo6It+bazwbAvoVp60bEhIj4Rq0gIq4EpgMfjIgdgOuAbSWNzLMcBZxf9zk3A94LbB8RbwK+miedBfxPRLyZ1B/VTElvyeuYSHpPy0cl7ZjnHw98JyK2B16Xx3cGdgDeImm3Cp/bupwTh3WaDSTdTToB/4PUZ9cY4HpJ9wKfJiUKSDWS3fLPucAblV7y80RELM/z3BARiyPiGVJneO+oEMs7c03nXlIHi9sXpl3W18K5h9IfAYdJGkFKaL+sm+1J4FngPEnvI3UJQd7euXk9KyPiyRz71RGxPCKW5c9TS5YP5XctALw7/9wF3AlsS0okZqWs3fcsZm3lmfxt/Z8kfRs4IyKm5T6rpuRJtwCTSX3zfI70zf1AUkKpqe9zJ0j9GxW/VK1fH4Sk9YHvkN4yNzc3ZRXnW16/TA9+CPyclByuKLwvIgUTsULSzqSO+g4EjiUljaqK8Qj4ekR8rx/rMXONw4aEjVnVDXSt908iYi6pk7fxEfEgqUnrRFJCqXmX0ruYNyC9Ee33pE7hXiFpM0nrsXoTVE0tSTym9F6UsndaLQWGF2J8GHgY+Dwpiawmr3vjiLgO+CTpdbCQXv35sTzPMKW3//0OOCD3CvsyUqL8Xf06geuBD+d1I2m0pFeUjN/MNQ4bEqYAV0h6AriZ9AKfmjtIPShDOol+nZRAav5Ieq/JGODHtV5BJX0lT5sPPFC/wYhYIun7pIvNj5C6+i/jAuC7kp4Bds1NZBcDIyNiVoP5hwPX5BqOgE/l8uOAqZKOBlYCH4uI2yRdkOMG+EFE3KX0lshi7L+W9Hrgtnw9fxlwGEP/PR02QNw7rnUtSUeSmpqObXEcZwN3RcR5rYzDrCzXOMxaSNIM0vWHE1odi1lZrnGYmVklvjhuZmaVOHGYmVklThxmZlaJE4eZmVXixGFmZpX8L/PpWaUzne0EAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99"
      },
      "outputs": [],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "CxecT9dhMfbF",
      "metadata": {
        "id": "CxecT9dhMfbF"
      },
      "outputs": [],
      "source": [
        "# Remove samples with pawpularity score of 100\n",
        "indexNames = train_data_sorted[train_data_sorted['Pawpularity'] == 100].index | train_data_sorted[train_data_sorted['Pawpularity'] < 5].index\n",
        "train_data_new = train_data_sorted.drop(indexNames)\n",
        "train_imgs_new = np.delete(train_imgs, indexNames, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Agl1YxFwNcKo",
      "metadata": {
        "id": "Agl1YxFwNcKo"
      },
      "outputs": [],
      "source": [
        "# Select x-values (the 12 input features) and y-values from training data\n",
        "x_tabular = train_data_new.iloc[:,1:13].to_numpy()\n",
        "y = train_data_new.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
        "\n",
        "# Create numpy array of image data \n",
        "x_images = np.array(train_imgs_new)\n",
        "test_imgs_array = np.array(test_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RNE8NWL7xgmp",
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99"
      },
      "outputs": [],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtZpIRuAue4B",
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ZKkweNdcNXLl",
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "outputs": [],
      "source": [
        "def linear_limit(x):\n",
        "    \"\"\"\n",
        "    Create a linear activation function that clips the output at 0 and 100.\n",
        "    \"\"\"\n",
        "    activation_x = activations.linear(x)\n",
        "    activation_x_new = K.clip(activation_x, 0, 100)\n",
        "\n",
        "    return activation_x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "DZ58i65PvawJ",
      "metadata": {
        "id": "DZ58i65PvawJ"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "    \"\"\"\n",
        "    This function trains and evaluated a model. It first compiles the model with \n",
        "    the loss and metrics. It then makes a train and validation generator for the \n",
        "    image data, based on the preprocess and augment input. \n",
        "    It then trains the model on both the image and tabular data for epochs times. \n",
        "    The values of the loss and metric are plotted and printed.\n",
        "    \"\"\"\n",
        "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Preprocess the image data\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(image_x)\n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(image_x)\n",
        "\n",
        "    # Train the model by fitting both tabular and image data at the same time\n",
        "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs = epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7eJp3actWxsB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7eJp3actWxsB",
        "outputId": "1b29ac9d-d015-401f-abce-c40fc57bd09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "236/236 [==============================] - 25s 52ms/step - loss: 887.8549 - root_mean_squared_error: 26.4918 - val_loss: 1075.3942 - val_root_mean_squared_error: 27.0892\n",
            "Epoch 2/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 608.9845 - root_mean_squared_error: 22.4891 - val_loss: 580.0870 - val_root_mean_squared_error: 23.1747\n",
            "Epoch 3/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 519.9633 - root_mean_squared_error: 21.2791 - val_loss: 524.0371 - val_root_mean_squared_error: 21.2832\n",
            "Epoch 4/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 459.6881 - root_mean_squared_error: 20.2832 - val_loss: 412.5911 - val_root_mean_squared_error: 19.6249\n",
            "Epoch 5/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 404.2963 - root_mean_squared_error: 19.2245 - val_loss: 380.4998 - val_root_mean_squared_error: 18.8309\n",
            "Epoch 6/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 369.0088 - root_mean_squared_error: 18.5382 - val_loss: 332.6757 - val_root_mean_squared_error: 17.6515\n",
            "Epoch 7/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 351.3968 - root_mean_squared_error: 18.1583 - val_loss: 326.6170 - val_root_mean_squared_error: 17.5024\n",
            "Epoch 8/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 344.3481 - root_mean_squared_error: 18.0215 - val_loss: 323.8941 - val_root_mean_squared_error: 17.4894\n",
            "Epoch 9/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 332.1858 - root_mean_squared_error: 17.7152 - val_loss: 325.9435 - val_root_mean_squared_error: 17.5763\n",
            "Epoch 10/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 335.1300 - root_mean_squared_error: 17.8351 - val_loss: 321.2769 - val_root_mean_squared_error: 17.4588\n",
            "Epoch 11/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 329.5667 - root_mean_squared_error: 17.7008 - val_loss: 320.2343 - val_root_mean_squared_error: 17.4495\n",
            "Epoch 12/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 328.3448 - root_mean_squared_error: 17.6974 - val_loss: 318.2870 - val_root_mean_squared_error: 17.4237\n",
            "Epoch 13/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 325.7837 - root_mean_squared_error: 17.6487 - val_loss: 317.9956 - val_root_mean_squared_error: 17.4365\n",
            "Epoch 14/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 323.1229 - root_mean_squared_error: 17.5864 - val_loss: 317.9937 - val_root_mean_squared_error: 17.4516\n",
            "Epoch 15/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 321.4432 - root_mean_squared_error: 17.5529 - val_loss: 317.1674 - val_root_mean_squared_error: 17.4463\n",
            "Epoch 16/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 318.8506 - root_mean_squared_error: 17.4901 - val_loss: 317.7756 - val_root_mean_squared_error: 17.4778\n",
            "Epoch 17/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 318.9219 - root_mean_squared_error: 17.5068 - val_loss: 315.7740 - val_root_mean_squared_error: 17.4249\n",
            "Epoch 18/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 316.6429 - root_mean_squared_error: 17.4535 - val_loss: 315.2389 - val_root_mean_squared_error: 17.4198\n",
            "Epoch 19/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 316.8615 - root_mean_squared_error: 17.4685 - val_loss: 315.4185 - val_root_mean_squared_error: 17.4378\n",
            "Epoch 20/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 315.7721 - root_mean_squared_error: 17.4471 - val_loss: 315.1955 - val_root_mean_squared_error: 17.4397\n",
            "Epoch 21/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.8710 - root_mean_squared_error: 17.3745 - val_loss: 318.7069 - val_root_mean_squared_error: 17.5313\n",
            "Epoch 22/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 313.0283 - root_mean_squared_error: 17.3883 - val_loss: 314.3224 - val_root_mean_squared_error: 17.4352\n",
            "Epoch 23/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.6366 - root_mean_squared_error: 17.3824 - val_loss: 313.3333 - val_root_mean_squared_error: 17.4108\n",
            "Epoch 24/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.5779 - root_mean_squared_error: 17.3854 - val_loss: 313.1638 - val_root_mean_squared_error: 17.4050\n",
            "Epoch 25/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 310.5561 - root_mean_squared_error: 17.3354 - val_loss: 313.6289 - val_root_mean_squared_error: 17.4270\n",
            "Epoch 26/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.0422 - root_mean_squared_error: 17.3573 - val_loss: 313.2697 - val_root_mean_squared_error: 17.4300\n",
            "Epoch 27/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 310.6124 - root_mean_squared_error: 17.3496 - val_loss: 313.2021 - val_root_mean_squared_error: 17.4240\n",
            "Epoch 28/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 308.9611 - root_mean_squared_error: 17.3035 - val_loss: 314.0265 - val_root_mean_squared_error: 17.4572\n",
            "Epoch 29/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 309.9073 - root_mean_squared_error: 17.3354 - val_loss: 313.9806 - val_root_mean_squared_error: 17.4506\n",
            "Epoch 30/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 309.1959 - root_mean_squared_error: 17.3186 - val_loss: 312.7570 - val_root_mean_squared_error: 17.4222\n",
            "Epoch 31/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.7917 - root_mean_squared_error: 17.3128 - val_loss: 315.6570 - val_root_mean_squared_error: 17.4891\n",
            "Epoch 32/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.0189 - root_mean_squared_error: 17.2950 - val_loss: 312.9893 - val_root_mean_squared_error: 17.4326\n",
            "Epoch 33/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.1788 - root_mean_squared_error: 17.3037 - val_loss: 311.7019 - val_root_mean_squared_error: 17.4127\n",
            "Epoch 34/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.1483 - root_mean_squared_error: 17.2774 - val_loss: 315.1790 - val_root_mean_squared_error: 17.5025\n",
            "Epoch 35/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.5221 - root_mean_squared_error: 17.3151 - val_loss: 311.6425 - val_root_mean_squared_error: 17.4124\n",
            "Epoch 36/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 307.4617 - root_mean_squared_error: 17.2906 - val_loss: 314.3322 - val_root_mean_squared_error: 17.4474\n",
            "Epoch 37/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 307.4234 - root_mean_squared_error: 17.2938 - val_loss: 311.4127 - val_root_mean_squared_error: 17.4153\n",
            "Epoch 38/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.3112 - root_mean_squared_error: 17.2651 - val_loss: 313.3204 - val_root_mean_squared_error: 17.4550\n",
            "Epoch 39/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.4425 - root_mean_squared_error: 17.2981 - val_loss: 312.0260 - val_root_mean_squared_error: 17.4414\n",
            "Epoch 40/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 306.6194 - root_mean_squared_error: 17.2827 - val_loss: 311.1281 - val_root_mean_squared_error: 17.3952\n",
            "Epoch 41/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.3039 - root_mean_squared_error: 17.2756 - val_loss: 312.0912 - val_root_mean_squared_error: 17.4379\n",
            "Epoch 42/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.8781 - root_mean_squared_error: 17.2991 - val_loss: 311.3691 - val_root_mean_squared_error: 17.4299\n",
            "Epoch 43/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 306.3506 - root_mean_squared_error: 17.2867 - val_loss: 312.2896 - val_root_mean_squared_error: 17.4486\n",
            "Epoch 44/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.9367 - root_mean_squared_error: 17.2780 - val_loss: 310.5993 - val_root_mean_squared_error: 17.4114\n",
            "Epoch 45/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.9134 - root_mean_squared_error: 17.2773 - val_loss: 311.1046 - val_root_mean_squared_error: 17.4351\n",
            "Epoch 46/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.7036 - root_mean_squared_error: 17.2769 - val_loss: 311.2391 - val_root_mean_squared_error: 17.4404\n",
            "Epoch 47/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 305.7882 - root_mean_squared_error: 17.2827 - val_loss: 309.8118 - val_root_mean_squared_error: 17.4034\n",
            "Epoch 48/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.3380 - root_mean_squared_error: 17.2721 - val_loss: 311.4402 - val_root_mean_squared_error: 17.4459\n",
            "Epoch 49/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.1944 - root_mean_squared_error: 17.2678 - val_loss: 309.7141 - val_root_mean_squared_error: 17.3987\n",
            "Epoch 50/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.4204 - root_mean_squared_error: 17.2782 - val_loss: 309.7739 - val_root_mean_squared_error: 17.4104\n",
            "Epoch 51/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.3217 - root_mean_squared_error: 17.2782 - val_loss: 310.5915 - val_root_mean_squared_error: 17.4136\n",
            "Epoch 52/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 305.5842 - root_mean_squared_error: 17.2900 - val_loss: 310.3402 - val_root_mean_squared_error: 17.4315\n",
            "Epoch 53/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.1032 - root_mean_squared_error: 17.2477 - val_loss: 310.0323 - val_root_mean_squared_error: 17.4169\n",
            "Epoch 54/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.4447 - root_mean_squared_error: 17.2566 - val_loss: 311.3022 - val_root_mean_squared_error: 17.4511\n",
            "Epoch 55/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 304.4541 - root_mean_squared_error: 17.2586 - val_loss: 312.0963 - val_root_mean_squared_error: 17.4708\n",
            "Epoch 56/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.4244 - root_mean_squared_error: 17.2578 - val_loss: 311.9911 - val_root_mean_squared_error: 17.4747\n",
            "Epoch 57/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.3552 - root_mean_squared_error: 17.2545 - val_loss: 312.3068 - val_root_mean_squared_error: 17.4578\n",
            "Epoch 58/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.0195 - root_mean_squared_error: 17.2456 - val_loss: 310.7136 - val_root_mean_squared_error: 17.4358\n",
            "Epoch 59/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 303.7122 - root_mean_squared_error: 17.2400 - val_loss: 311.0163 - val_root_mean_squared_error: 17.4454\n",
            "Epoch 60/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 304.0175 - root_mean_squared_error: 17.2457 - val_loss: 308.8332 - val_root_mean_squared_error: 17.3850\n",
            "Epoch 1/60\n",
            "236/236 [==============================] - 14s 48ms/step - loss: 836.0854 - root_mean_squared_error: 25.9903 - val_loss: 606.4010 - val_root_mean_squared_error: 23.4462\n",
            "Epoch 2/60\n",
            "236/236 [==============================] - 11s 46ms/step - loss: 581.7112 - root_mean_squared_error: 22.1914 - val_loss: 565.9918 - val_root_mean_squared_error: 23.0742\n",
            "Epoch 3/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 508.0828 - root_mean_squared_error: 21.1200 - val_loss: 524.0125 - val_root_mean_squared_error: 22.3383\n",
            "Epoch 4/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 465.7007 - root_mean_squared_error: 20.5267 - val_loss: 384.9446 - val_root_mean_squared_error: 18.9599\n",
            "Epoch 5/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 423.0875 - root_mean_squared_error: 19.7463 - val_loss: 333.0591 - val_root_mean_squared_error: 17.6017\n",
            "Epoch 6/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 377.1607 - root_mean_squared_error: 18.7452 - val_loss: 322.1877 - val_root_mean_squared_error: 17.3756\n",
            "Epoch 7/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 356.9131 - root_mean_squared_error: 18.3063 - val_loss: 307.3440 - val_root_mean_squared_error: 16.9537\n",
            "Epoch 8/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 343.2723 - root_mean_squared_error: 17.9861 - val_loss: 305.7097 - val_root_mean_squared_error: 16.9592\n",
            "Epoch 9/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 344.6238 - root_mean_squared_error: 18.0593 - val_loss: 303.9129 - val_root_mean_squared_error: 16.9253\n",
            "Epoch 10/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 337.9613 - root_mean_squared_error: 17.9091 - val_loss: 303.0743 - val_root_mean_squared_error: 16.9189\n",
            "Epoch 11/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 339.2171 - root_mean_squared_error: 17.9652 - val_loss: 302.8608 - val_root_mean_squared_error: 16.9405\n",
            "Epoch 12/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 332.4689 - root_mean_squared_error: 17.7979 - val_loss: 301.3013 - val_root_mean_squared_error: 16.9173\n",
            "Epoch 13/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 330.4112 - root_mean_squared_error: 17.7529 - val_loss: 302.1859 - val_root_mean_squared_error: 16.9632\n",
            "Epoch 14/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 328.0242 - root_mean_squared_error: 17.7074 - val_loss: 300.4556 - val_root_mean_squared_error: 16.9217\n",
            "Epoch 15/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 330.8094 - root_mean_squared_error: 17.8007 - val_loss: 300.0814 - val_root_mean_squared_error: 16.9223\n",
            "Epoch 16/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 326.4684 - root_mean_squared_error: 17.6930 - val_loss: 301.8795 - val_root_mean_squared_error: 16.9916\n",
            "Epoch 17/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 324.8998 - root_mean_squared_error: 17.6632 - val_loss: 298.7318 - val_root_mean_squared_error: 16.9211\n",
            "Epoch 18/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 324.3656 - root_mean_squared_error: 17.6594 - val_loss: 298.7305 - val_root_mean_squared_error: 16.9298\n",
            "Epoch 19/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 320.9751 - root_mean_squared_error: 17.5771 - val_loss: 298.5096 - val_root_mean_squared_error: 16.9244\n",
            "Epoch 20/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 320.2943 - root_mean_squared_error: 17.5634 - val_loss: 299.6860 - val_root_mean_squared_error: 16.9781\n",
            "Epoch 21/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 320.2085 - root_mean_squared_error: 17.5675 - val_loss: 298.6971 - val_root_mean_squared_error: 16.9596\n",
            "Epoch 22/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 319.9100 - root_mean_squared_error: 17.5692 - val_loss: 297.1898 - val_root_mean_squared_error: 16.9197\n",
            "Epoch 23/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 317.2617 - root_mean_squared_error: 17.5052 - val_loss: 297.9237 - val_root_mean_squared_error: 16.9597\n",
            "Epoch 24/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 317.6088 - root_mean_squared_error: 17.5181 - val_loss: 297.0634 - val_root_mean_squared_error: 16.9250\n",
            "Epoch 25/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 317.0945 - root_mean_squared_error: 17.5141 - val_loss: 299.9606 - val_root_mean_squared_error: 17.0068\n",
            "Epoch 26/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 315.9261 - root_mean_squared_error: 17.4810 - val_loss: 297.0217 - val_root_mean_squared_error: 16.9420\n",
            "Epoch 27/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 316.2047 - root_mean_squared_error: 17.4967 - val_loss: 296.6066 - val_root_mean_squared_error: 16.9269\n",
            "Epoch 28/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 314.8008 - root_mean_squared_error: 17.4612 - val_loss: 297.3151 - val_root_mean_squared_error: 16.9503\n",
            "Epoch 29/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 314.5752 - root_mean_squared_error: 17.4587 - val_loss: 297.3229 - val_root_mean_squared_error: 16.9478\n",
            "Epoch 30/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 314.9409 - root_mean_squared_error: 17.4717 - val_loss: 295.6681 - val_root_mean_squared_error: 16.9165\n",
            "Epoch 31/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 315.1791 - root_mean_squared_error: 17.4847 - val_loss: 295.9777 - val_root_mean_squared_error: 16.9257\n",
            "Epoch 32/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 313.7477 - root_mean_squared_error: 17.4463 - val_loss: 297.4203 - val_root_mean_squared_error: 16.9786\n",
            "Epoch 33/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 313.3031 - root_mean_squared_error: 17.4431 - val_loss: 297.4509 - val_root_mean_squared_error: 16.9821\n",
            "Epoch 34/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 313.9527 - root_mean_squared_error: 17.4634 - val_loss: 294.9388 - val_root_mean_squared_error: 16.9133\n",
            "Epoch 35/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 313.8303 - root_mean_squared_error: 17.4646 - val_loss: 295.1028 - val_root_mean_squared_error: 16.9200\n",
            "Epoch 36/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.9819 - root_mean_squared_error: 17.4428 - val_loss: 295.2571 - val_root_mean_squared_error: 16.9301\n",
            "Epoch 37/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.3226 - root_mean_squared_error: 17.4271 - val_loss: 296.5278 - val_root_mean_squared_error: 16.9681\n",
            "Epoch 38/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.7253 - root_mean_squared_error: 17.4437 - val_loss: 294.5262 - val_root_mean_squared_error: 16.9122\n",
            "Epoch 39/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.1265 - root_mean_squared_error: 17.4320 - val_loss: 294.8869 - val_root_mean_squared_error: 16.9334\n",
            "Epoch 40/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.2651 - root_mean_squared_error: 17.4374 - val_loss: 294.4197 - val_root_mean_squared_error: 16.9199\n",
            "Epoch 41/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 312.0918 - root_mean_squared_error: 17.4349 - val_loss: 296.3150 - val_root_mean_squared_error: 16.9693\n",
            "Epoch 42/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.2086 - root_mean_squared_error: 17.4104 - val_loss: 295.0645 - val_root_mean_squared_error: 16.9470\n",
            "Epoch 43/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.5717 - root_mean_squared_error: 17.4227 - val_loss: 294.0109 - val_root_mean_squared_error: 16.9209\n",
            "Epoch 44/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.3597 - root_mean_squared_error: 17.4216 - val_loss: 293.7777 - val_root_mean_squared_error: 16.9131\n",
            "Epoch 45/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.7471 - root_mean_squared_error: 17.4344 - val_loss: 293.7527 - val_root_mean_squared_error: 16.9117\n",
            "Epoch 46/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 310.8220 - root_mean_squared_error: 17.4088 - val_loss: 293.0318 - val_root_mean_squared_error: 16.8986\n",
            "Epoch 47/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 310.9268 - root_mean_squared_error: 17.4153 - val_loss: 294.4083 - val_root_mean_squared_error: 16.9307\n",
            "Epoch 48/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 311.2870 - root_mean_squared_error: 17.4276 - val_loss: 293.5727 - val_root_mean_squared_error: 16.9200\n",
            "Epoch 49/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.9028 - root_mean_squared_error: 17.3921 - val_loss: 295.5395 - val_root_mean_squared_error: 16.9752\n",
            "Epoch 50/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 310.4855 - root_mean_squared_error: 17.4126 - val_loss: 294.3018 - val_root_mean_squared_error: 16.9406\n",
            "Epoch 51/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 309.7219 - root_mean_squared_error: 17.3894 - val_loss: 295.6057 - val_root_mean_squared_error: 16.9762\n",
            "Epoch 52/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 310.2061 - root_mean_squared_error: 17.4074 - val_loss: 293.1037 - val_root_mean_squared_error: 16.9082\n",
            "Epoch 53/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 310.2878 - root_mean_squared_error: 17.4126 - val_loss: 294.0657 - val_root_mean_squared_error: 16.9342\n",
            "Epoch 54/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 310.0024 - root_mean_squared_error: 17.4090 - val_loss: 294.0963 - val_root_mean_squared_error: 16.9481\n",
            "Epoch 55/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.8355 - root_mean_squared_error: 17.3783 - val_loss: 294.7790 - val_root_mean_squared_error: 16.9616\n",
            "Epoch 56/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 309.5970 - root_mean_squared_error: 17.4021 - val_loss: 293.7207 - val_root_mean_squared_error: 16.9416\n",
            "Epoch 57/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 310.1460 - root_mean_squared_error: 17.4209 - val_loss: 293.0724 - val_root_mean_squared_error: 16.9249\n",
            "Epoch 58/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.3343 - root_mean_squared_error: 17.3995 - val_loss: 292.9350 - val_root_mean_squared_error: 16.9217\n",
            "Epoch 59/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 309.5436 - root_mean_squared_error: 17.4109 - val_loss: 292.9048 - val_root_mean_squared_error: 16.9254\n",
            "Epoch 60/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 308.2641 - root_mean_squared_error: 17.3738 - val_loss: 293.6113 - val_root_mean_squared_error: 16.9454\n",
            "Epoch 1/60\n",
            "236/236 [==============================] - 15s 53ms/step - loss: 848.9970 - root_mean_squared_error: 25.9680 - val_loss: 1186.8535 - val_root_mean_squared_error: 29.2816\n",
            "Epoch 2/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 574.5330 - root_mean_squared_error: 21.8734 - val_loss: 537.7922 - val_root_mean_squared_error: 22.3569\n",
            "Epoch 3/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 489.0074 - root_mean_squared_error: 20.6256 - val_loss: 413.5158 - val_root_mean_squared_error: 19.3576\n",
            "Epoch 4/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 440.3999 - root_mean_squared_error: 19.9413 - val_loss: 392.4020 - val_root_mean_squared_error: 19.1627\n",
            "Epoch 5/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 394.1079 - root_mean_squared_error: 19.0696 - val_loss: 359.1813 - val_root_mean_squared_error: 18.3920\n",
            "Epoch 6/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 361.9300 - root_mean_squared_error: 18.3882 - val_loss: 328.0242 - val_root_mean_squared_error: 17.5699\n",
            "Epoch 7/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 348.5616 - root_mean_squared_error: 18.1144 - val_loss: 318.4449 - val_root_mean_squared_error: 17.2894\n",
            "Epoch 8/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 338.3664 - root_mean_squared_error: 17.8732 - val_loss: 319.0384 - val_root_mean_squared_error: 17.3279\n",
            "Epoch 9/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 336.1508 - root_mean_squared_error: 17.8450 - val_loss: 315.5183 - val_root_mean_squared_error: 17.2692\n",
            "Epoch 10/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 332.7027 - root_mean_squared_error: 17.7757 - val_loss: 315.0480 - val_root_mean_squared_error: 17.2983\n",
            "Epoch 11/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 334.7542 - root_mean_squared_error: 17.8635 - val_loss: 314.1772 - val_root_mean_squared_error: 17.2672\n",
            "Epoch 12/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 328.3936 - root_mean_squared_error: 17.7093 - val_loss: 313.9338 - val_root_mean_squared_error: 17.3106\n",
            "Epoch 13/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 328.0026 - root_mean_squared_error: 17.7194 - val_loss: 312.0682 - val_root_mean_squared_error: 17.2753\n",
            "Epoch 14/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 324.6513 - root_mean_squared_error: 17.6440 - val_loss: 312.2681 - val_root_mean_squared_error: 17.2964\n",
            "Epoch 15/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 322.8542 - root_mean_squared_error: 17.6082 - val_loss: 312.4432 - val_root_mean_squared_error: 17.3050\n",
            "Epoch 16/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 320.9296 - root_mean_squared_error: 17.5628 - val_loss: 311.6848 - val_root_mean_squared_error: 17.3140\n",
            "Epoch 17/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 318.2318 - root_mean_squared_error: 17.5005 - val_loss: 310.1334 - val_root_mean_squared_error: 17.2749\n",
            "Epoch 18/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 316.4624 - root_mean_squared_error: 17.4591 - val_loss: 309.6954 - val_root_mean_squared_error: 17.2709\n",
            "Epoch 19/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 316.5433 - root_mean_squared_error: 17.4735 - val_loss: 310.1830 - val_root_mean_squared_error: 17.2875\n",
            "Epoch 20/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 317.0045 - root_mean_squared_error: 17.4924 - val_loss: 309.2851 - val_root_mean_squared_error: 17.2782\n",
            "Epoch 21/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 316.7111 - root_mean_squared_error: 17.4951 - val_loss: 309.3270 - val_root_mean_squared_error: 17.2846\n",
            "Epoch 22/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 314.2247 - root_mean_squared_error: 17.4316 - val_loss: 309.1044 - val_root_mean_squared_error: 17.2840\n",
            "Epoch 23/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 313.6903 - root_mean_squared_error: 17.4226 - val_loss: 309.4704 - val_root_mean_squared_error: 17.3008\n",
            "Epoch 24/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 313.3136 - root_mean_squared_error: 17.4182 - val_loss: 309.1904 - val_root_mean_squared_error: 17.2977\n",
            "Epoch 25/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 312.9229 - root_mean_squared_error: 17.4122 - val_loss: 308.6080 - val_root_mean_squared_error: 17.2912\n",
            "Epoch 26/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 312.0893 - root_mean_squared_error: 17.3925 - val_loss: 308.0770 - val_root_mean_squared_error: 17.2877\n",
            "Epoch 27/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 311.7755 - root_mean_squared_error: 17.3926 - val_loss: 307.5659 - val_root_mean_squared_error: 17.2745\n",
            "Epoch 28/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 311.3746 - root_mean_squared_error: 17.3817 - val_loss: 307.4494 - val_root_mean_squared_error: 17.2729\n",
            "Epoch 29/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 309.9872 - root_mean_squared_error: 17.3451 - val_loss: 308.0545 - val_root_mean_squared_error: 17.2974\n",
            "Epoch 30/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 309.8065 - root_mean_squared_error: 17.3451 - val_loss: 307.8693 - val_root_mean_squared_error: 17.2906\n",
            "Epoch 31/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 310.3216 - root_mean_squared_error: 17.3644 - val_loss: 307.2895 - val_root_mean_squared_error: 17.2732\n",
            "Epoch 32/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 309.8265 - root_mean_squared_error: 17.3553 - val_loss: 307.1236 - val_root_mean_squared_error: 17.2807\n",
            "Epoch 33/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 309.8312 - root_mean_squared_error: 17.3609 - val_loss: 306.9692 - val_root_mean_squared_error: 17.2819\n",
            "Epoch 34/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 309.7740 - root_mean_squared_error: 17.3616 - val_loss: 306.9861 - val_root_mean_squared_error: 17.2852\n",
            "Epoch 35/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 309.1651 - root_mean_squared_error: 17.3496 - val_loss: 305.9967 - val_root_mean_squared_error: 17.2597\n",
            "Epoch 36/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 308.4962 - root_mean_squared_error: 17.3332 - val_loss: 305.2136 - val_root_mean_squared_error: 17.2398\n",
            "Epoch 37/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 308.5613 - root_mean_squared_error: 17.3396 - val_loss: 307.4822 - val_root_mean_squared_error: 17.3070\n",
            "Epoch 38/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 308.3431 - root_mean_squared_error: 17.3330 - val_loss: 306.6946 - val_root_mean_squared_error: 17.2875\n",
            "Epoch 39/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 308.3219 - root_mean_squared_error: 17.3396 - val_loss: 306.0007 - val_root_mean_squared_error: 17.2769\n",
            "Epoch 40/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 307.6380 - root_mean_squared_error: 17.3225 - val_loss: 306.7791 - val_root_mean_squared_error: 17.2994\n",
            "Epoch 41/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.6949 - root_mean_squared_error: 17.3276 - val_loss: 306.4073 - val_root_mean_squared_error: 17.2906\n",
            "Epoch 42/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 307.8051 - root_mean_squared_error: 17.3299 - val_loss: 307.1022 - val_root_mean_squared_error: 17.2986\n",
            "Epoch 43/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 307.9066 - root_mean_squared_error: 17.3374 - val_loss: 306.1288 - val_root_mean_squared_error: 17.2802\n",
            "Epoch 44/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 308.0815 - root_mean_squared_error: 17.3461 - val_loss: 305.3323 - val_root_mean_squared_error: 17.2775\n",
            "Epoch 45/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.2264 - root_mean_squared_error: 17.3304 - val_loss: 305.8545 - val_root_mean_squared_error: 17.2957\n",
            "Epoch 46/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.5795 - root_mean_squared_error: 17.3463 - val_loss: 305.2907 - val_root_mean_squared_error: 17.2854\n",
            "Epoch 47/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 307.1741 - root_mean_squared_error: 17.3356 - val_loss: 305.0492 - val_root_mean_squared_error: 17.2736\n",
            "Epoch 48/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 307.1939 - root_mean_squared_error: 17.3377 - val_loss: 306.2017 - val_root_mean_squared_error: 17.3077\n",
            "Epoch 49/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.8757 - root_mean_squared_error: 17.3315 - val_loss: 304.4857 - val_root_mean_squared_error: 17.2685\n",
            "Epoch 50/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.3210 - root_mean_squared_error: 17.3188 - val_loss: 305.1733 - val_root_mean_squared_error: 17.2827\n",
            "Epoch 51/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.6889 - root_mean_squared_error: 17.3281 - val_loss: 305.5685 - val_root_mean_squared_error: 17.2993\n",
            "Epoch 52/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.5257 - root_mean_squared_error: 17.3267 - val_loss: 305.0683 - val_root_mean_squared_error: 17.2886\n",
            "Epoch 53/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.7795 - root_mean_squared_error: 17.3360 - val_loss: 304.4285 - val_root_mean_squared_error: 17.2714\n",
            "Epoch 54/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.5368 - root_mean_squared_error: 17.3286 - val_loss: 304.8227 - val_root_mean_squared_error: 17.2826\n",
            "Epoch 55/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.2963 - root_mean_squared_error: 17.3242 - val_loss: 304.1761 - val_root_mean_squared_error: 17.2645\n",
            "Epoch 56/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.1446 - root_mean_squared_error: 17.3193 - val_loss: 304.6490 - val_root_mean_squared_error: 17.2791\n",
            "Epoch 57/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 306.0268 - root_mean_squared_error: 17.3187 - val_loss: 305.8287 - val_root_mean_squared_error: 17.3047\n",
            "Epoch 58/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 305.9604 - root_mean_squared_error: 17.3135 - val_loss: 304.9935 - val_root_mean_squared_error: 17.2891\n",
            "Epoch 59/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.2509 - root_mean_squared_error: 17.3264 - val_loss: 305.2755 - val_root_mean_squared_error: 17.3031\n",
            "Epoch 60/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 305.9819 - root_mean_squared_error: 17.3170 - val_loss: 304.2845 - val_root_mean_squared_error: 17.2711\n",
            "Epoch 1/60\n",
            "236/236 [==============================] - 14s 49ms/step - loss: 869.9561 - root_mean_squared_error: 26.5023 - val_loss: 654.2574 - val_root_mean_squared_error: 22.2958\n",
            "Epoch 2/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 613.8747 - root_mean_squared_error: 22.7400 - val_loss: 562.4756 - val_root_mean_squared_error: 22.8595\n",
            "Epoch 3/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 507.8210 - root_mean_squared_error: 21.0477 - val_loss: 427.3712 - val_root_mean_squared_error: 19.4184\n",
            "Epoch 4/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 446.3072 - root_mean_squared_error: 20.0858 - val_loss: 380.2134 - val_root_mean_squared_error: 18.7332\n",
            "Epoch 5/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 396.4281 - root_mean_squared_error: 19.1295 - val_loss: 359.2780 - val_root_mean_squared_error: 18.3666\n",
            "Epoch 6/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 368.2675 - root_mean_squared_error: 18.5294 - val_loss: 342.0660 - val_root_mean_squared_error: 17.9444\n",
            "Epoch 7/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 355.1273 - root_mean_squared_error: 18.2671 - val_loss: 333.3606 - val_root_mean_squared_error: 17.7285\n",
            "Epoch 8/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 344.5773 - root_mean_squared_error: 18.0321 - val_loss: 325.5016 - val_root_mean_squared_error: 17.5114\n",
            "Epoch 9/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 337.5005 - root_mean_squared_error: 17.8714 - val_loss: 324.7407 - val_root_mean_squared_error: 17.5390\n",
            "Epoch 10/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 333.0618 - root_mean_squared_error: 17.7747 - val_loss: 323.9110 - val_root_mean_squared_error: 17.5444\n",
            "Epoch 11/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 329.6098 - root_mean_squared_error: 17.7108 - val_loss: 321.8079 - val_root_mean_squared_error: 17.5103\n",
            "Epoch 12/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 328.2573 - root_mean_squared_error: 17.6965 - val_loss: 322.0587 - val_root_mean_squared_error: 17.5398\n",
            "Epoch 13/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 326.6794 - root_mean_squared_error: 17.6743 - val_loss: 320.3526 - val_root_mean_squared_error: 17.4902\n",
            "Epoch 14/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 324.0522 - root_mean_squared_error: 17.6171 - val_loss: 320.6852 - val_root_mean_squared_error: 17.5416\n",
            "Epoch 15/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 322.0592 - root_mean_squared_error: 17.5810 - val_loss: 320.9682 - val_root_mean_squared_error: 17.5684\n",
            "Epoch 16/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 321.2211 - root_mean_squared_error: 17.5730 - val_loss: 318.7429 - val_root_mean_squared_error: 17.5110\n",
            "Epoch 17/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 318.1429 - root_mean_squared_error: 17.4966 - val_loss: 317.7935 - val_root_mean_squared_error: 17.4838\n",
            "Epoch 18/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 317.4266 - root_mean_squared_error: 17.4858 - val_loss: 317.1636 - val_root_mean_squared_error: 17.4783\n",
            "Epoch 19/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 314.7864 - root_mean_squared_error: 17.4200 - val_loss: 317.1604 - val_root_mean_squared_error: 17.4825\n",
            "Epoch 20/60\n",
            "236/236 [==============================] - 11s 47ms/step - loss: 314.0366 - root_mean_squared_error: 17.4036 - val_loss: 316.5054 - val_root_mean_squared_error: 17.4795\n",
            "Epoch 21/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 313.7386 - root_mean_squared_error: 17.4072 - val_loss: 316.5659 - val_root_mean_squared_error: 17.4943\n",
            "Epoch 22/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 313.1396 - root_mean_squared_error: 17.3955 - val_loss: 320.6834 - val_root_mean_squared_error: 17.6204\n",
            "Epoch 23/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 310.4651 - root_mean_squared_error: 17.3242 - val_loss: 316.6974 - val_root_mean_squared_error: 17.5075\n",
            "Epoch 24/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 310.9647 - root_mean_squared_error: 17.3457 - val_loss: 315.8555 - val_root_mean_squared_error: 17.4878\n",
            "Epoch 25/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.9098 - root_mean_squared_error: 17.3194 - val_loss: 316.9431 - val_root_mean_squared_error: 17.5322\n",
            "Epoch 26/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.9373 - root_mean_squared_error: 17.3258 - val_loss: 317.2260 - val_root_mean_squared_error: 17.5467\n",
            "Epoch 27/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 310.1455 - root_mean_squared_error: 17.3369 - val_loss: 315.1787 - val_root_mean_squared_error: 17.4803\n",
            "Epoch 28/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.7314 - root_mean_squared_error: 17.3270 - val_loss: 316.6703 - val_root_mean_squared_error: 17.5286\n",
            "Epoch 29/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.7975 - root_mean_squared_error: 17.3369 - val_loss: 315.2281 - val_root_mean_squared_error: 17.4900\n",
            "Epoch 30/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 309.2581 - root_mean_squared_error: 17.3277 - val_loss: 314.7879 - val_root_mean_squared_error: 17.4807\n",
            "Epoch 31/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 309.0065 - root_mean_squared_error: 17.3244 - val_loss: 315.2059 - val_root_mean_squared_error: 17.5021\n",
            "Epoch 32/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 308.5966 - root_mean_squared_error: 17.3142 - val_loss: 314.3492 - val_root_mean_squared_error: 17.4828\n",
            "Epoch 33/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 307.3992 - root_mean_squared_error: 17.2873 - val_loss: 314.4543 - val_root_mean_squared_error: 17.4968\n",
            "Epoch 34/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 308.0708 - root_mean_squared_error: 17.3130 - val_loss: 314.1583 - val_root_mean_squared_error: 17.4779\n",
            "Epoch 35/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.2222 - root_mean_squared_error: 17.2896 - val_loss: 314.6883 - val_root_mean_squared_error: 17.5066\n",
            "Epoch 36/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 307.8236 - root_mean_squared_error: 17.3126 - val_loss: 314.1751 - val_root_mean_squared_error: 17.4936\n",
            "Epoch 37/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.0084 - root_mean_squared_error: 17.2892 - val_loss: 315.6409 - val_root_mean_squared_error: 17.5316\n",
            "Epoch 38/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.0864 - root_mean_squared_error: 17.2931 - val_loss: 320.9213 - val_root_mean_squared_error: 17.5866\n",
            "Epoch 39/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.4715 - root_mean_squared_error: 17.2800 - val_loss: 313.6245 - val_root_mean_squared_error: 17.4887\n",
            "Epoch 40/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.9475 - root_mean_squared_error: 17.2997 - val_loss: 313.8622 - val_root_mean_squared_error: 17.4874\n",
            "Epoch 41/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.4093 - root_mean_squared_error: 17.2834 - val_loss: 313.3377 - val_root_mean_squared_error: 17.4837\n",
            "Epoch 42/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.9001 - root_mean_squared_error: 17.2988 - val_loss: 313.7146 - val_root_mean_squared_error: 17.5004\n",
            "Epoch 43/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.4841 - root_mean_squared_error: 17.2902 - val_loss: 312.9679 - val_root_mean_squared_error: 17.4775\n",
            "Epoch 44/60\n",
            "236/236 [==============================] - 11s 48ms/step - loss: 306.0665 - root_mean_squared_error: 17.2835 - val_loss: 313.1770 - val_root_mean_squared_error: 17.4889\n",
            "Epoch 45/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.0157 - root_mean_squared_error: 17.2843 - val_loss: 313.3106 - val_root_mean_squared_error: 17.4943\n",
            "Epoch 46/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.9448 - root_mean_squared_error: 17.2859 - val_loss: 312.6989 - val_root_mean_squared_error: 17.4708\n",
            "Epoch 47/60\n",
            "236/236 [==============================] - 14s 60ms/step - loss: 306.0698 - root_mean_squared_error: 17.2915 - val_loss: 312.8173 - val_root_mean_squared_error: 17.4837\n",
            "Epoch 48/60\n",
            "236/236 [==============================] - 24s 103ms/step - loss: 305.8767 - root_mean_squared_error: 17.2888 - val_loss: 312.9531 - val_root_mean_squared_error: 17.4910\n",
            "Epoch 49/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.3073 - root_mean_squared_error: 17.2760 - val_loss: 312.3444 - val_root_mean_squared_error: 17.4797\n",
            "Epoch 50/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.1036 - root_mean_squared_error: 17.2741 - val_loss: 312.2615 - val_root_mean_squared_error: 17.4811\n",
            "Epoch 51/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.0820 - root_mean_squared_error: 17.2747 - val_loss: 311.8840 - val_root_mean_squared_error: 17.4689\n",
            "Epoch 52/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.2705 - root_mean_squared_error: 17.2835 - val_loss: 312.0560 - val_root_mean_squared_error: 17.4841\n",
            "Epoch 53/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.2600 - root_mean_squared_error: 17.2887 - val_loss: 311.8311 - val_root_mean_squared_error: 17.4801\n",
            "Epoch 54/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.0367 - root_mean_squared_error: 17.2838 - val_loss: 311.7274 - val_root_mean_squared_error: 17.4808\n",
            "Epoch 55/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 304.9763 - root_mean_squared_error: 17.2842 - val_loss: 311.4015 - val_root_mean_squared_error: 17.4709\n",
            "Epoch 56/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 304.7446 - root_mean_squared_error: 17.2808 - val_loss: 311.5199 - val_root_mean_squared_error: 17.4775\n",
            "Epoch 57/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 304.5475 - root_mean_squared_error: 17.2779 - val_loss: 311.4545 - val_root_mean_squared_error: 17.4789\n",
            "Epoch 58/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 304.1729 - root_mean_squared_error: 17.2699 - val_loss: 312.8030 - val_root_mean_squared_error: 17.5176\n",
            "Epoch 59/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 304.7267 - root_mean_squared_error: 17.2879 - val_loss: 312.5301 - val_root_mean_squared_error: 17.4952\n",
            "Epoch 60/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 304.0178 - root_mean_squared_error: 17.2672 - val_loss: 312.5895 - val_root_mean_squared_error: 17.5111\n",
            "Epoch 1/60\n",
            "236/236 [==============================] - 15s 52ms/step - loss: 863.5568 - root_mean_squared_error: 26.7197 - val_loss: 628.3052 - val_root_mean_squared_error: 23.6240\n",
            "Epoch 2/60\n",
            "236/236 [==============================] - 11s 49ms/step - loss: 586.6855 - root_mean_squared_error: 22.3335 - val_loss: 1089.1287 - val_root_mean_squared_error: 29.8322\n",
            "Epoch 3/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 510.0465 - root_mean_squared_error: 21.1977 - val_loss: 489.0240 - val_root_mean_squared_error: 21.4647\n",
            "Epoch 4/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 452.1068 - root_mean_squared_error: 20.2238 - val_loss: 387.6099 - val_root_mean_squared_error: 18.9582\n",
            "Epoch 5/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 406.5545 - root_mean_squared_error: 19.3910 - val_loss: 382.8969 - val_root_mean_squared_error: 19.0579\n",
            "Epoch 6/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 370.2234 - root_mean_squared_error: 18.6213 - val_loss: 337.4923 - val_root_mean_squared_error: 17.8271\n",
            "Epoch 7/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 348.9065 - root_mean_squared_error: 18.1297 - val_loss: 330.0183 - val_root_mean_squared_error: 17.6554\n",
            "Epoch 8/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 343.5802 - root_mean_squared_error: 18.0268 - val_loss: 332.0472 - val_root_mean_squared_error: 17.7418\n",
            "Epoch 9/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 334.4467 - root_mean_squared_error: 17.8053 - val_loss: 326.1773 - val_root_mean_squared_error: 17.5965\n",
            "Epoch 10/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 331.0094 - root_mean_squared_error: 17.7335 - val_loss: 326.4113 - val_root_mean_squared_error: 17.6359\n",
            "Epoch 11/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 329.4319 - root_mean_squared_error: 17.7206 - val_loss: 323.1012 - val_root_mean_squared_error: 17.5593\n",
            "Epoch 12/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 327.0196 - root_mean_squared_error: 17.6809 - val_loss: 321.5971 - val_root_mean_squared_error: 17.5327\n",
            "Epoch 13/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 323.0124 - root_mean_squared_error: 17.5878 - val_loss: 320.7215 - val_root_mean_squared_error: 17.5298\n",
            "Epoch 14/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 321.8809 - root_mean_squared_error: 17.5715 - val_loss: 321.6890 - val_root_mean_squared_error: 17.5799\n",
            "Epoch 15/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 320.4738 - root_mean_squared_error: 17.5456 - val_loss: 319.9964 - val_root_mean_squared_error: 17.5436\n",
            "Epoch 16/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 320.0443 - root_mean_squared_error: 17.5484 - val_loss: 319.7781 - val_root_mean_squared_error: 17.5468\n",
            "Epoch 17/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 318.2145 - root_mean_squared_error: 17.5065 - val_loss: 318.6349 - val_root_mean_squared_error: 17.5214\n",
            "Epoch 18/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 316.8296 - root_mean_squared_error: 17.4785 - val_loss: 319.1048 - val_root_mean_squared_error: 17.5512\n",
            "Epoch 19/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 314.3675 - root_mean_squared_error: 17.4189 - val_loss: 318.7791 - val_root_mean_squared_error: 17.5556\n",
            "Epoch 20/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 313.3636 - root_mean_squared_error: 17.3979 - val_loss: 317.7774 - val_root_mean_squared_error: 17.5259\n",
            "Epoch 21/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 313.1126 - root_mean_squared_error: 17.3968 - val_loss: 317.6660 - val_root_mean_squared_error: 17.5280\n",
            "Epoch 22/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 313.3673 - root_mean_squared_error: 17.4110 - val_loss: 317.6320 - val_root_mean_squared_error: 17.5361\n",
            "Epoch 23/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 311.9398 - root_mean_squared_error: 17.3759 - val_loss: 317.1062 - val_root_mean_squared_error: 17.5220\n",
            "Epoch 24/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 310.3506 - root_mean_squared_error: 17.3364 - val_loss: 317.4019 - val_root_mean_squared_error: 17.5423\n",
            "Epoch 25/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 310.6336 - root_mean_squared_error: 17.3485 - val_loss: 318.5853 - val_root_mean_squared_error: 17.5873\n",
            "Epoch 26/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 310.1183 - root_mean_squared_error: 17.3372 - val_loss: 320.9925 - val_root_mean_squared_error: 17.6614\n",
            "Epoch 27/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 309.6129 - root_mean_squared_error: 17.3296 - val_loss: 316.7599 - val_root_mean_squared_error: 17.5344\n",
            "Epoch 28/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 308.8350 - root_mean_squared_error: 17.3102 - val_loss: 320.1536 - val_root_mean_squared_error: 17.6242\n",
            "Epoch 29/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 308.9604 - root_mean_squared_error: 17.3195 - val_loss: 316.5935 - val_root_mean_squared_error: 17.5281\n",
            "Epoch 30/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 308.2292 - root_mean_squared_error: 17.3028 - val_loss: 316.8183 - val_root_mean_squared_error: 17.5566\n",
            "Epoch 31/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.5535 - root_mean_squared_error: 17.2861 - val_loss: 315.7834 - val_root_mean_squared_error: 17.5192\n",
            "Epoch 32/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 307.6643 - root_mean_squared_error: 17.2960 - val_loss: 315.2384 - val_root_mean_squared_error: 17.5123\n",
            "Epoch 33/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.4389 - root_mean_squared_error: 17.2942 - val_loss: 315.2655 - val_root_mean_squared_error: 17.5156\n",
            "Epoch 34/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 307.7351 - root_mean_squared_error: 17.3054 - val_loss: 315.1205 - val_root_mean_squared_error: 17.5190\n",
            "Epoch 35/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 306.5754 - root_mean_squared_error: 17.2742 - val_loss: 315.1302 - val_root_mean_squared_error: 17.5233\n",
            "Epoch 36/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.9956 - root_mean_squared_error: 17.2885 - val_loss: 315.1964 - val_root_mean_squared_error: 17.5293\n",
            "Epoch 37/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 306.3384 - root_mean_squared_error: 17.2731 - val_loss: 315.3657 - val_root_mean_squared_error: 17.5340\n",
            "Epoch 38/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 306.1198 - root_mean_squared_error: 17.2700 - val_loss: 314.1645 - val_root_mean_squared_error: 17.4980\n",
            "Epoch 39/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 305.5791 - root_mean_squared_error: 17.2562 - val_loss: 314.9854 - val_root_mean_squared_error: 17.5272\n",
            "Epoch 40/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 306.0756 - root_mean_squared_error: 17.2683 - val_loss: 315.0245 - val_root_mean_squared_error: 17.5248\n",
            "Epoch 41/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 305.6326 - root_mean_squared_error: 17.2570 - val_loss: 314.2771 - val_root_mean_squared_error: 17.5141\n",
            "Epoch 42/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.4913 - root_mean_squared_error: 17.2601 - val_loss: 315.0838 - val_root_mean_squared_error: 17.5374\n",
            "Epoch 43/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 305.2035 - root_mean_squared_error: 17.2572 - val_loss: 313.7584 - val_root_mean_squared_error: 17.5042\n",
            "Epoch 44/60\n",
            "236/236 [==============================] - 12s 49ms/step - loss: 304.7623 - root_mean_squared_error: 17.2408 - val_loss: 313.5253 - val_root_mean_squared_error: 17.4941\n",
            "Epoch 45/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 306.0224 - root_mean_squared_error: 17.2774 - val_loss: 315.3687 - val_root_mean_squared_error: 17.5549\n",
            "Epoch 46/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 305.4893 - root_mean_squared_error: 17.2700 - val_loss: 315.6313 - val_root_mean_squared_error: 17.5540\n",
            "Epoch 47/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 305.3729 - root_mean_squared_error: 17.2681 - val_loss: 313.9870 - val_root_mean_squared_error: 17.5182\n",
            "Epoch 48/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 305.1183 - root_mean_squared_error: 17.2653 - val_loss: 313.5779 - val_root_mean_squared_error: 17.5112\n",
            "Epoch 49/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 304.9533 - root_mean_squared_error: 17.2649 - val_loss: 314.1099 - val_root_mean_squared_error: 17.5307\n",
            "Epoch 50/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 304.6845 - root_mean_squared_error: 17.2583 - val_loss: 315.0414 - val_root_mean_squared_error: 17.5484\n",
            "Epoch 51/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 304.7006 - root_mean_squared_error: 17.2606 - val_loss: 312.9672 - val_root_mean_squared_error: 17.5034\n",
            "Epoch 52/60\n",
            "236/236 [==============================] - 12s 50ms/step - loss: 304.2668 - root_mean_squared_error: 17.2497 - val_loss: 313.1107 - val_root_mean_squared_error: 17.5052\n",
            "Epoch 53/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 303.4108 - root_mean_squared_error: 17.2281 - val_loss: 313.2208 - val_root_mean_squared_error: 17.5102\n",
            "Epoch 54/60\n",
            "236/236 [==============================] - 13s 53ms/step - loss: 304.0958 - root_mean_squared_error: 17.2505 - val_loss: 313.5875 - val_root_mean_squared_error: 17.5230\n",
            "Epoch 55/60\n",
            "236/236 [==============================] - 12s 53ms/step - loss: 303.9227 - root_mean_squared_error: 17.2455 - val_loss: 313.7823 - val_root_mean_squared_error: 17.5260\n",
            "Epoch 56/60\n",
            "236/236 [==============================] - 12s 52ms/step - loss: 304.2824 - root_mean_squared_error: 17.2568 - val_loss: 313.9687 - val_root_mean_squared_error: 17.5342\n",
            "Epoch 57/60\n",
            "236/236 [==============================] - 12s 52ms/step - loss: 304.0521 - root_mean_squared_error: 17.2546 - val_loss: 311.7626 - val_root_mean_squared_error: 17.4783\n",
            "Epoch 58/60\n",
            "236/236 [==============================] - 12s 51ms/step - loss: 303.4513 - root_mean_squared_error: 17.2384 - val_loss: 311.9152 - val_root_mean_squared_error: 17.4865\n",
            "Epoch 59/60\n",
            "236/236 [==============================] - 12s 53ms/step - loss: 303.6509 - root_mean_squared_error: 17.2456 - val_loss: 313.6795 - val_root_mean_squared_error: 17.5362\n",
            "Epoch 60/60\n",
            "236/236 [==============================] - 12s 52ms/step - loss: 303.1110 - root_mean_squared_error: 17.2304 - val_loss: 316.1473 - val_root_mean_squared_error: 17.5983\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train MSE is 305.0784545898438\n",
            "The train RMSE is 17.286812210083006\n",
            "The validation MSE is 307.0931762695312\n",
            "The validation RMSE is 17.342193603515625\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
        "    \"\"\"\n",
        "    Train and evaluate the data for num-folds times, and return the average \n",
        "    training and validation loss. First the data is split in num-folds batches\n",
        "    and then the model is trained on the data, where a different batch is the \n",
        "    validation data each time.\n",
        "    \"\"\"\n",
        "    # Create kfold object to later split the data\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "    x_indices = np.array(range(len(x_tabular)))\n",
        "    y_indices = np.array(range(len(y)))\n",
        "\n",
        "    # Pre allocate variables to store the MSE (loss) and RMSE (accuracy)\n",
        "    train_loss = np.array(np.zeros(epochs))\n",
        "    train_acc = np.array(np.zeros(epochs))\n",
        "    val_loss = np.array(np.zeros(epochs))\n",
        "    val_acc = np.array(np.zeros(epochs))\n",
        "    \n",
        "    # Train and evaluate the model for num-fold times on a different training \n",
        "    # and validation set each time\n",
        "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
        "        \n",
        "        # Make Neural Networks before concatenation\n",
        "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "        image_size = (64, 64, 3)\n",
        "        image_NN = build_convol_net(image_size, hidden_nodes=20)\n",
        "\n",
        "        # Create subset training and validation data\n",
        "        x_tabular_train = x_tabular[id_train]\n",
        "        x_imgs_train = x_imgs[id_train]\n",
        "        y_train = y[id_train]\n",
        "        \n",
        "        x_tabular_val = x_tabular[id_val]\n",
        "        x_imgs_val = x_imgs[id_val]\n",
        "        y_val_2 = y[id_val]\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=20)\n",
        "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
        "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs, preprocess=preprocess, augment=augment)\n",
        "\n",
        "        # Add all the losses and metrics\n",
        "        train_loss += history.history['loss']\n",
        "        train_acc += history.history['root_mean_squared_error']\n",
        "        val_loss += history.history['val_loss']\n",
        "        val_acc += history.history['val_root_mean_squared_error']\n",
        "\n",
        "    # Calculate average loss and metric\n",
        "    avg_train_loss = train_loss / num_folds\n",
        "    avg_val_loss = val_loss / num_folds\n",
        "    avg_train_acc = train_acc / num_folds\n",
        "    avg_val_acc = val_acc / num_folds\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Plot MSE\n",
        "    axs[0].plot(avg_train_loss)\n",
        "    axs[0].plot(avg_val_loss)\n",
        "    axs[0].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[0].set_title('Model MSE')\n",
        "    axs[0].set_ylabel('MSE')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "    axs[0].set_ylim([0, 1000])\n",
        "\n",
        "    # Plot RMSE\n",
        "    axs[1].plot(avg_train_acc)\n",
        "    axs[1].plot(avg_val_acc)\n",
        "    axs[1].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[1].set_title('Model RMSE')\n",
        "    axs[1].set_ylabel('RMSE')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    axs[1].set_ylim([0, 30])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return avg_train_loss[-1], avg_val_loss[-1], avg_train_acc[-1], avg_val_acc[-1]\n",
        "\n",
        "# Use k-fold cross-validation to train and evaluate concatenated network\n",
        "avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc = k_fold(5, x_tabular, y, x_images, epochs=60, \n",
        "                                               preprocess={'featurewise_center': True, 'featurewise_std_normalization': True},\n",
        "                                               augment={'rotation_range': 90, 'horizontal_flip': True, 'shear_range': 0.2})\n",
        "\n",
        "print(f'The train MSE is {avg_train_loss}')\n",
        "print(f'The train RMSE is {avg_train_acc}')\n",
        "print(f'The validation MSE is {avg_val_loss}')\n",
        "print(f'The validation RMSE is {avg_val_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UiMunH5vM8wU",
      "metadata": {
        "id": "UiMunH5vM8wU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chapter_17_Removing_lower_outliers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}