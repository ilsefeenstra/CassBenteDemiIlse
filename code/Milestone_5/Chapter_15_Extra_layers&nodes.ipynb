{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3915ca73",
   "metadata": {
    "id": "3915ca73"
   },
   "source": [
    "# Combining extra layers with extra hidden nodes\n",
    "In this chapter we will combine adding extra layers and increasing the number of hidden nodes. In this way the model becomes more complex and might be able to better learn the data.\n",
    "\n",
    "We will add one convolutional layer after each convolutional layer. Moreover, we increase the hidden nodes from the dense layers of the convolutional neural network to 100 and the dense layers of the concatenated network to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vRjBTUzjlmKA",
   "metadata": {
    "id": "vRjBTUzjlmKA"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from os import chdir, listdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from keras import backend as K\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFZWcvRBvYv_",
   "metadata": {
    "id": "LFZWcvRBvYv_"
   },
   "source": [
    "# Import zip with the data\n",
    "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fANqjfPxoHI7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fANqjfPxoHI7",
    "outputId": "3cf2152a-d132-4a18-d962-0afb2a4ab711"
   },
   "outputs": [],
   "source": [
    "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
    "\n",
    "# Get zip file from Github URL\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
    "    -O \"/tmp/pawpularity_data.zip\"\n",
    "\n",
    "# Opens the zip file in read mode and extract files into /tmp folder\n",
    "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae29a8e",
   "metadata": {
    "id": "0ae29a8e"
   },
   "source": [
    "# Import tabular data\n",
    "\n",
    "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae10a3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8ae10a3a",
    "outputId": "df74b29e-e902-470f-f876-e773dc646c79"
   },
   "outputs": [],
   "source": [
    "# Import the CSV tables\n",
    "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
    "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
    "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "csv_train_data.head()\n",
    "\n",
    "# Drop rows with missing values (if NaN values are in dataframe)\n",
    "# No missing values present, so no samples dropped\n",
    "csv_train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRYM1P29o8k1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "SRYM1P29o8k1",
    "outputId": "d33a8c26-9f97-438e-ad74-f3f828ebabf8"
   },
   "outputs": [],
   "source": [
    "# Create a plot that shows the distribution of the output of the training samples\n",
    "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
    "plt.title(\"Data distribution of the tabular data\")\n",
    "plt.xlabel(\"Pawpularity score\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccde6f",
   "metadata": {
    "id": "5eccde6f"
   },
   "source": [
    "# Import image data\n",
    "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8970b3",
   "metadata": {
    "id": "6a8970b3"
   },
   "outputs": [],
   "source": [
    "def reshape_images(path, n):\n",
    "    \"\"\"\n",
    "    This function returns a list of images, which are reshaped to 64 x 64 \n",
    "    and a list with the names of the images.\n",
    "    \"\"\"\n",
    "    # Set the current path\n",
    "    chdir(path)\n",
    "    \n",
    "    # Preset the lists\n",
    "    images = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Go over all the files in the path\n",
    "    for i in listdir():\n",
    "        \n",
    "        # Get the name of the image, without .jpg\n",
    "        image_names.append(i[:-4])\n",
    "        \n",
    "        # Get the image and reshape to n x n\n",
    "        file = cv2.imread(i)\n",
    "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Rescale the pixels and store in the list\n",
    "        images.append(file/255)\n",
    "        \n",
    "    return images, image_names\n",
    "\n",
    "# Reshape train and test images\n",
    "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
    "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b818ae9",
   "metadata": {
    "id": "8b818ae9"
   },
   "source": [
    "# Combine tabular data with images\n",
    "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85185f99",
   "metadata": {
    "id": "85185f99"
   },
   "outputs": [],
   "source": [
    "def sort_dataframe(data, images, names):\n",
    "    \"\"\"\n",
    "    This function sorts the dataframe of the csv data according to the image names.\n",
    "    \"\"\"\n",
    "    data_sorted = pd.DataFrame()\n",
    "\n",
    "    # Iterate over images and get index of each image\n",
    "    for img, name in zip(images, names):\n",
    "        location = data[data['Id'] == name].index[0]\n",
    "\n",
    "        # Sort dataframe according to index of images\n",
    "        data_sorted = data_sorted.append([data.loc[location]])\n",
    "\n",
    "        # Reset the index of the dataframe\n",
    "        data_sorted = data_sorted.reset_index().drop(['index'], axis=1)\n",
    "        \n",
    "    return data_sorted\n",
    "\n",
    "# Sort training and testing data\n",
    "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
    "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
    "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9206b4b",
   "metadata": {
    "id": "e9206b4b"
   },
   "source": [
    "# Processing data\n",
    "First we remove the outliers with a Pawpularity score of 100. The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CxecT9dhMfbF",
   "metadata": {
    "id": "CxecT9dhMfbF"
   },
   "outputs": [],
   "source": [
    "# Remove samples with pawpularity score of 100\n",
    "indexNames = train_data_sorted[train_data_sorted['Pawpularity'] == 100].index\n",
    "train_data_new = train_data_sorted.drop(indexNames)\n",
    "train_imgs_new = np.delete(train_imgs, indexNames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Agl1YxFwNcKo",
   "metadata": {
    "id": "Agl1YxFwNcKo"
   },
   "outputs": [],
   "source": [
    "# Select x-values (the 12 input features) and y-values from training data\n",
    "x_tabular = train_data_new.iloc[:,1:13].to_numpy()\n",
    "y = train_data_new.iloc[:,13].to_numpy()\n",
    "\n",
    "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
    "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
    "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
    "\n",
    "# Create numpy array of image data \n",
    "x_images = np.array(train_imgs_new)\n",
    "test_imgs_array = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNE8NWL7xgmp",
   "metadata": {
    "id": "RNE8NWL7xgmp"
   },
   "source": [
    "# Create seperate neural networks\n",
    "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1cb99",
   "metadata": {
    "id": "ccf1cb99"
   },
   "outputs": [],
   "source": [
    "def build_neural_net(input_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number of \n",
    "    hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Create hidden layer \n",
    "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
    "\n",
    "    # Create hidden layer \n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "\n",
    "    # Create hidden layer \n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18b2f9",
   "metadata": {
    "id": "bd18b2f9"
   },
   "outputs": [],
   "source": [
    "def build_convol_net(image_size, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Build neural network with an input size and a hidden layer with a number \n",
    "    of hidden nodes.\n",
    "    \"\"\"\n",
    "    # Create a sequential model object\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Create convolutional layers \n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Create convolutional layers \n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Create convolutional layers\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # Create a flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Create a dense layer \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
    "              kernel_regularizer=regularizers.l2(1e-3),\n",
    "              bias_regularizer=regularizers.l2(1e-3),\n",
    "              activity_regularizer=regularizers.l2(1e-3)))\n",
    "\n",
    "    # Create a dense layer \n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
    "              kernel_regularizer=regularizers.l2(1e-3),\n",
    "              bias_regularizer=regularizers.l2(1e-3),\n",
    "              activity_regularizer=regularizers.l2(1e-3)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vtZpIRuAue4B",
   "metadata": {
    "id": "vtZpIRuAue4B"
   },
   "source": [
    "## Concatenate tabular and image data models\n",
    "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZKkweNdcNXLl",
   "metadata": {
    "id": "ZKkweNdcNXLl"
   },
   "outputs": [],
   "source": [
    "def linear_limit(x):\n",
    "    \"\"\"\n",
    "    Create a linear activation function that clips the output at 0 and 100.\n",
    "    \"\"\"\n",
    "    activation_x = activations.linear(x)\n",
    "    activation_x_new = K.clip(activation_x, 0, 100)\n",
    "\n",
    "    return activation_x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441c455",
   "metadata": {
    "id": "1441c455"
   },
   "outputs": [],
   "source": [
    "def concatenate_models(model1, model2, hidden_nodes):\n",
    "    \"\"\"\n",
    "    Concatenate two neural network models, model1 and model2, and create\n",
    "    a concatenated model with dense layers with some hidden nodes.\n",
    "    \"\"\"\n",
    "    # Input for concatenated model is retrieved by concatenating the output\n",
    "    # of both models\n",
    "    concat_input = layers.concatenate([model1.output, model2.output])\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
    "              kernel_regularizer=regularizers.l2(1e-1),\n",
    "              bias_regularizer=regularizers.l2(1e-1),\n",
    "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
    "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
    "              kernel_regularizer=regularizers.l2(1e-1),\n",
    "              bias_regularizer=regularizers.l2(1e-1),\n",
    "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
    "\n",
    "    # Create hidden layer with relu activation\n",
    "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
    "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
    "              kernel_regularizer=regularizers.l2(1e-1),\n",
    "              bias_regularizer=regularizers.l2(1e-1),\n",
    "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
    "\n",
    "    # Create output layer\n",
    "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
    "\n",
    "    # Create concatenated model with inputs of both models and output of the\n",
    "    # concatenated model\n",
    "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
    "\n",
    "    return concat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b87e0",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Train the concatenated model and plot the MSE and RMSE of the training and validation data for each epoch. We do this with k-fold cross-validation to obtain a more reliable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DZ58i65PvawJ",
   "metadata": {
    "id": "DZ58i65PvawJ"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
    "    \"\"\"\n",
    "    This function trains and evaluated a model. It first compiles the model with \n",
    "    the loss and metrics. It then makes a train and validation generator for the \n",
    "    image data, based on the preprocess and augment input. \n",
    "    It then trains the model on both the image and tabular data for epochs times. \n",
    "    The values of the loss and metric are plotted.\n",
    "    \"\"\"\n",
    "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
    "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "    # Preprocess the image data\n",
    "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
    "    train_gen.fit(image_x)\n",
    "\n",
    "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
    "    val_gen.fit(image_x)\n",
    "\n",
    "    # Train the model by fitting both tabular and image data at the same time\n",
    "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs=epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eJp3actWxsB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7eJp3actWxsB",
    "outputId": "25ac8fae-407e-4aa3-fee6-64430e24725b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
    "    \"\"\"\n",
    "    Train and evaluate the data for num-folds times, and return the average \n",
    "    training and validation loss. First the data is split in num-folds batches\n",
    "    and then the model is trained on the data, where a different batch is the \n",
    "    validation data each time.\n",
    "    \"\"\"\n",
    "    # Create kfold object to later split the data\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    x_indices = np.array(range(len(x_tabular)))\n",
    "    y_indices = np.array(range(len(y)))\n",
    "\n",
    "    # Pre allocate variables to store the MSE (loss) and RMSE (accuracy)\n",
    "    train_loss = np.array(np.zeros(epochs))\n",
    "    train_acc = np.array(np.zeros(epochs))\n",
    "    val_loss = np.array(np.zeros(epochs))\n",
    "    val_acc = np.array(np.zeros(epochs))\n",
    "    \n",
    "    # Train and evaluate the model for num-fold times on a different training \n",
    "    # and validation set each time\n",
    "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
    "        \n",
    "        # Make Neural Networks before concatenation\n",
    "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
    "        image_size = (64, 64, 3)\n",
    "        image_NN = build_convol_net(image_size, hidden_nodes=100)\n",
    "\n",
    "        # Create subset training and validation data\n",
    "        x_tabular_train = x_tabular[id_train]\n",
    "        x_imgs_train = x_imgs[id_train]\n",
    "        y_train = y[id_train]\n",
    "        \n",
    "        x_tabular_val = x_tabular[id_val]\n",
    "        x_imgs_val = x_imgs[id_val]\n",
    "        y_val_2 = y[id_val]\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=40)\n",
    "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
    "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs, preprocess=preprocess, augment=augment)\n",
    "\n",
    "        # Add all the losses and metrics\n",
    "        train_loss += history.history['loss']\n",
    "        train_acc += history.history['root_mean_squared_error']\n",
    "        val_loss += history.history['val_loss']\n",
    "        val_acc += history.history['val_root_mean_squared_error']\n",
    "\n",
    "    # Calculate average loss and metric\n",
    "    avg_train_loss = train_loss / num_folds\n",
    "    avg_val_loss = val_loss / num_folds\n",
    "    avg_train_acc = train_acc / num_folds\n",
    "    avg_val_acc = val_acc / num_folds\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
    "\n",
    "    # Plot MSE\n",
    "    axs[0].plot(avg_train_loss)\n",
    "    axs[0].plot(avg_val_loss)\n",
    "    axs[0].legend(['training', 'validation'], loc='best')\n",
    "    \n",
    "    axs[0].set_title('Model MSE')\n",
    "    axs[0].set_ylabel('MSE')\n",
    "    axs[0].set_xlabel('epoch')\n",
    "    axs[0].set_ylim([0, 1000])\n",
    "\n",
    "    # Plot RMSE\n",
    "    axs[1].plot(avg_train_acc)\n",
    "    axs[1].plot(avg_val_acc)\n",
    "    axs[1].legend(['training', 'validation'], loc='best')\n",
    "    \n",
    "    axs[1].set_title('Model RMSE')\n",
    "    axs[1].set_ylabel('RMSE')\n",
    "    axs[1].set_xlabel('epoch')\n",
    "    axs[1].set_ylim([0, 30])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return avg_train_loss[-1], avg_val_loss[-1], avg_train_acc[-1], avg_val_acc[-1]\n",
    "\n",
    "# Use k-fold cross-validation to train and evaluate concatenated network\n",
    "avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc=k_fold(5, x_tabular, y, x_images, epochs=60, \n",
    "                                               preprocess={'featurewise_center': True, 'featurewise_std_normalization': True},\n",
    "                                               augment={'rotation_range': 90, 'horizontal_flip': True, 'shear_range': 0.2})\n",
    "\n",
    "print(f'The train MSE is {avg_train_loss}')\n",
    "print(f'The train RMSE is {avg_train_acc}')\n",
    "print(f'The validation MSE is {avg_val_loss}')\n",
    "print(f'The validation RMSE is {avg_val_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chapter_15_Extra layers&nodes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
