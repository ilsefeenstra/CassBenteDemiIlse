{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3915ca73",
      "metadata": {
        "id": "3915ca73"
      },
      "source": [
        "# Combining extra layers with extra hidden nodes\n",
        "In this chapter we will combine adding extra layers and increasing the number of hidden nodes. In this way the model becomes more complex and might be able to better learn the data.\n",
        "\n",
        "We will add one convolutional layer after each convolutional layer. Moreover, we increase the hidden nodes from the dense layers of the convolutional neural network to 100 and the dense layers of the concatenated network to 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "vRjBTUzjlmKA",
      "metadata": {
        "id": "vRjBTUzjlmKA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import chdir, listdir\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, preprocessing, regularizers\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from keras import backend as K\n",
        "from keras import activations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFZWcvRBvYv_",
      "metadata": {
        "id": "LFZWcvRBvYv_"
      },
      "source": [
        "# Import zip with the data\n",
        "The data is imported as a zip from the github of our project group. The zip is unpacked in the google colab, so the data is accesible. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fANqjfPxoHI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANqjfPxoHI7",
        "outputId": "3cf2152a-d132-4a18-d962-0afb2a4ab711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-27 10:10:59--  https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main [following]\n",
            "--2022-01-27 10:10:59--  https://codeload.github.com/ilsefeenstra/Fitgirls0011/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/pawpularity_data.zip’\n",
            "\n",
            "/tmp/pawpularity_da     [        <=>         ]   1001M  22.4MB/s    in 46s     \n",
            "\n",
            "2022-01-27 10:11:46 (21.5 MB/s) - ‘/tmp/pawpularity_data.zip’ saved [1049332223]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Code from: https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e\n",
        "\n",
        "# Get zip file from Github URL\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/ilsefeenstra/Fitgirls0011/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/pawpularity_data.zip\"\n",
        "\n",
        "# Opens the zip file in read mode and extract files into /tmp folder\n",
        "zip_ref = zipfile.ZipFile('/tmp/pawpularity_data.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae29a8e",
      "metadata": {
        "id": "0ae29a8e"
      },
      "source": [
        "# Import tabular data\n",
        "\n",
        "The tabular data is imported. This contains information on whether several elements are present in the image, such as blur, a human, a group, etc. Also the pawpularity score of the training data is in the table. For the test data only the image ID and the features are in the table. There is also a sample submission table, which contains the pawpularity score for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ae10a3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8ae10a3a",
        "outputId": "df74b29e-e902-470f-f876-e773dc646c79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b5c02e0c-6db5-4b12-a298-dc73dff79d16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Subject Focus</th>\n",
              "      <th>Eyes</th>\n",
              "      <th>Face</th>\n",
              "      <th>Near</th>\n",
              "      <th>Action</th>\n",
              "      <th>Accessory</th>\n",
              "      <th>Group</th>\n",
              "      <th>Collage</th>\n",
              "      <th>Human</th>\n",
              "      <th>Occlusion</th>\n",
              "      <th>Info</th>\n",
              "      <th>Blur</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9907</th>\n",
              "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9908</th>\n",
              "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9909</th>\n",
              "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9910</th>\n",
              "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9911</th>\n",
              "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9912 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5c02e0c-6db5-4b12-a298-dc73dff79d16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5c02e0c-6db5-4b12-a298-dc73dff79d16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5c02e0c-6db5-4b12-a298-dc73dff79d16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Id  Subject Focus  ...  Blur  Pawpularity\n",
              "0     0007de18844b0dbbb5e1f607da0606e0              0  ...     0           63\n",
              "1     0009c66b9439883ba2750fb825e1d7db              0  ...     0           42\n",
              "2     0013fd999caf9a3efe1352ca1b0d937e              0  ...     0           28\n",
              "3     0018df346ac9c1d8413cfcc888ca8246              0  ...     0           15\n",
              "4     001dc955e10590d3ca4673f034feeef2              0  ...     0           72\n",
              "...                                ...            ...  ...   ...          ...\n",
              "9907  ffbfa0383c34dc513c95560d6e1fdb57              0  ...     1           15\n",
              "9908  ffcc8532d76436fc79e50eb2e5238e45              0  ...     0           70\n",
              "9909  ffdf2e8673a1da6fb80342fa3b119a20              0  ...     0           20\n",
              "9910  fff19e2ce11718548fa1c5d039a5192a              0  ...     0           20\n",
              "9911  fff8e47c766799c9e12f3cb3d66ad228              0  ...     0           30\n",
              "\n",
              "[9912 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import the CSV tables\n",
        "csv_train_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train.csv\")\n",
        "csv_test_data = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/sample_submission.csv\")\n",
        "csv_train_data.head()\n",
        "\n",
        "# Drop rows with missing values (if NaN values are in dataframe)\n",
        "# No missing values present, so no samples dropped\n",
        "csv_train_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "SRYM1P29o8k1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SRYM1P29o8k1",
        "outputId": "d33a8c26-9f97-438e-ad74-f3f828ebabf8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create a plot that shows the distribution of the output of the training samples\n",
        "plt.hist(csv_train_data['Pawpularity'], bins=100)\n",
        "plt.title(\"Data distribution of the tabular data\")\n",
        "plt.xlabel(\"Pawpularity score\")\n",
        "plt.ylabel(\"Occurence\")\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eccde6f",
      "metadata": {
        "id": "5eccde6f"
      },
      "source": [
        "# Import image data\n",
        "The images are imported from the folders. Each image is reshaped to a 64x64 image. In this way all the images have the same shape and we do not use much memory, to speed up analysis. After the images are imported, the images and their names are shuffled. This is done, so we can later take a validation sample containing a random subsample of the dataset. It could be that the images in the dataset contain some order, so by shuffling we ensure that the subset for the validation data is random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a8970b3",
      "metadata": {
        "id": "6a8970b3"
      },
      "outputs": [],
      "source": [
        "def reshape_images(path, n):\n",
        "    \"\"\"\n",
        "    This function returns a list of images, which are reshaped to 64 x 64 \n",
        "    and a list with the names of the images.\n",
        "    \"\"\"\n",
        "    # Set the current path\n",
        "    chdir(path)\n",
        "    \n",
        "    # Preset the lists\n",
        "    images = []\n",
        "    image_names = []\n",
        "    \n",
        "    # Go over all the files in the path\n",
        "    for i in listdir():\n",
        "        \n",
        "        # Get the name of the image, without .jpg\n",
        "        image_names.append(i[:-4])\n",
        "        \n",
        "        # Get the image and reshape to n x n\n",
        "        file = cv2.imread(i)\n",
        "        file = cv2.resize(file,(n, n), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rescale the pixels and store in the list\n",
        "        images.append(file/255)\n",
        "        \n",
        "    return images, image_names\n",
        "\n",
        "# Reshape train and test images\n",
        "train_imgs, train_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/train\", 64)\n",
        "test_imgs, test_names = reshape_images(\"/tmp/Fitgirls0011-main/petfinder-pawpularity-score/test\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b818ae9",
      "metadata": {
        "id": "8b818ae9"
      },
      "source": [
        "# Combine tabular data with images\n",
        "To ensure that the dataframe has the same order as the images in the list, we sort the dataframe based on the names of the images. If this would not be the case, it could be that you learn incorrectly, as the output of an image perhaps is not the real output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85185f99",
      "metadata": {
        "id": "85185f99"
      },
      "outputs": [],
      "source": [
        "def sort_dataframe(data, images, names):\n",
        "    \"\"\"\n",
        "    This function sorts the dataframe of the csv data according to the image names.\n",
        "    \"\"\"\n",
        "    data_sorted = pd.DataFrame()\n",
        "\n",
        "    # Iterate over images and get index of each image\n",
        "    for img, name in zip(images, names):\n",
        "        location = data[data['Id'] == name].index[0]\n",
        "\n",
        "        # Sort dataframe according to index of images\n",
        "        data_sorted = data_sorted.append([data.loc[location]])\n",
        "\n",
        "        # Reset the index of the dataframe\n",
        "        data_sorted = data_sorted.reset_index().drop(['index'],axis=1)\n",
        "        \n",
        "    return data_sorted\n",
        "\n",
        "# Sort training and testing data\n",
        "train_data_sorted = sort_dataframe(csv_train_data, train_imgs, train_names)\n",
        "test_data_sorted = sort_dataframe(csv_test_data, test_imgs, test_names)\n",
        "sample_submission_sorted = sort_dataframe(sample_submission, test_imgs, test_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9206b4b",
      "metadata": {
        "id": "e9206b4b"
      },
      "source": [
        "# Processing data\n",
        "The tabular data is split in x and y values and converted to numpy arrays, so the neural network can handle the data. Moreover, the image data is converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "CxecT9dhMfbF",
      "metadata": {
        "id": "CxecT9dhMfbF"
      },
      "outputs": [],
      "source": [
        "# Remove samples with pawpularity score of 100\n",
        "indexNames = train_data_sorted[train_data_sorted['Pawpularity'] == 100].index\n",
        "train_data_new = train_data_sorted.drop(indexNames)\n",
        "train_imgs_new = np.delete(train_imgs, indexNames, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Agl1YxFwNcKo",
      "metadata": {
        "id": "Agl1YxFwNcKo"
      },
      "outputs": [],
      "source": [
        "# Select x-values (the 12 input features) and y-values from training data\n",
        "x_tabular = train_data_new.iloc[:,1:13].to_numpy()\n",
        "y = train_data_new.iloc[:,13].to_numpy()\n",
        "\n",
        "# Select x (the 12 input features) and y (pawpularity) values from testing data\n",
        "x_test_tabular = test_data_sorted.iloc[:,1:13].to_numpy()\n",
        "y_test = sample_submission_sorted.iloc[:,1].to_numpy()\n",
        "\n",
        "# Create numpy array of image data \n",
        "x_images = np.array(train_imgs_new)\n",
        "test_imgs_array = np.array(test_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RNE8NWL7xgmp",
      "metadata": {
        "id": "RNE8NWL7xgmp"
      },
      "source": [
        "# Create seperate neural networks\n",
        "We create a tabular neural network to handle the data in the csv. Then we create a convolutional neural network to handle the image data. Both neural networks have no output layer, since they will be concatenated to one neural network, which will give the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ccf1cb99",
      "metadata": {
        "id": "ccf1cb99"
      },
      "outputs": [],
      "source": [
        "def build_neural_net(input_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number of \n",
        "    hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation='relu', input_shape=(input_size,)))    \n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    # Create hidden layer with relu activations\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bd18b2f9",
      "metadata": {
        "id": "bd18b2f9"
      },
      "outputs": [],
      "source": [
        "def build_convol_net(image_size, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Build neural network with an input size and a hidden layer with a number \n",
        "    of hidden nodes.\n",
        "    \"\"\"\n",
        "    # Create a sequential model object\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=image_size, padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Create a convolutional layer with relu activation\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    \n",
        "    # Create a flattening layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "\n",
        "    # Create a dense layer with relu activations\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(units=hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-3),\n",
        "              bias_regularizer=regularizers.l2(1e-3),\n",
        "              activity_regularizer=regularizers.l2(1e-3)))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vtZpIRuAue4B",
      "metadata": {
        "id": "vtZpIRuAue4B"
      },
      "source": [
        "## Concatenate tabular and image data models\n",
        "Concatenate the tabular and image models to create one neural network that can handle both types of data. This neural network will give the prediction of the pawpularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ZKkweNdcNXLl",
      "metadata": {
        "id": "ZKkweNdcNXLl"
      },
      "outputs": [],
      "source": [
        "def linear_limit(x):\n",
        "    \"\"\"\n",
        "    Create a linear activation function that clips the output at 0 and 100.\n",
        "    \"\"\"\n",
        "    activation_x = activations.linear(x)\n",
        "    activation_x_new = K.clip(activation_x, 0, 100)\n",
        "\n",
        "    return activation_x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1441c455",
      "metadata": {
        "id": "1441c455"
      },
      "outputs": [],
      "source": [
        "def concatenate_models(model1, model2, hidden_nodes):\n",
        "    \"\"\"\n",
        "    Concatenate two neural network models, model1 and model2, and create\n",
        "    a concatenated model with dense layers with some hidden nodes.\n",
        "    \"\"\"\n",
        "    # Input for concatenated model is retrieved by concatenating the output\n",
        "    # of both models\n",
        "    concat_input = layers.concatenate([model1.output, model2.output])\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    hidden_layer_1 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(concat_input)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_1 = layers.Dropout(0.4)(hidden_layer_1)    \n",
        "    hidden_layer_2 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_1)\n",
        "\n",
        "    # Create hidden layer with relu activation\n",
        "    drop_out_2 = layers.Dropout(0.4)(hidden_layer_2)\n",
        "    hidden_layer_3 = layers.Dense(hidden_nodes, activation=\"relu\", \n",
        "              kernel_regularizer=regularizers.l2(1e-1),\n",
        "              bias_regularizer=regularizers.l2(1e-1),\n",
        "              activity_regularizer=regularizers.l2(1e-1))(drop_out_2)\n",
        "\n",
        "    # Create output layer\n",
        "    output_layer = layers.Dense(1, activation=linear_limit)(hidden_layer_3)\n",
        "\n",
        "    # Create concatenated model with inputs of both models and output of the\n",
        "    # concatenated model\n",
        "    concat_model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer)\n",
        "\n",
        "    return concat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "DZ58i65PvawJ",
      "metadata": {
        "id": "DZ58i65PvawJ"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, image_x, tabular_x, train_y, x_val_tabular, x_val_imgs, val_y, epochs=20, preprocess = {}, augment={}):\n",
        "    \"\"\"\n",
        "    This function trains and evaluated a model. It first compiles the model with \n",
        "    the loss and metrics. It then makes a train and validation generator for the \n",
        "    image data, based on the preprocess and augment input. \n",
        "    It then trains the model on both the image and tabular data for epochs times. \n",
        "    The values of the loss and metric are plotted and printed.\n",
        "    \"\"\"\n",
        "    # Compile model and use mean squared error as loss and root mean squared error as metric\n",
        "    model.compile(loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    # Preprocess the image data\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(image_x)\n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(image_x)\n",
        "\n",
        "    # Train the model by fitting both tabular and image data at the same time\n",
        "    history = model.fit(train_gen.flow([image_x, tabular_x], train_y), epochs = epochs, validation_data=val_gen.flow([x_val_imgs, x_val_tabular], val_y))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7eJp3actWxsB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7eJp3actWxsB",
        "outputId": "25ac8fae-407e-4aa3-fee6-64430e24725b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "241/241 [==============================] - 14s 48ms/step - loss: 765.0609 - root_mean_squared_error: 24.1855 - val_loss: 1785.8248 - val_root_mean_squared_error: 35.4236\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 552.2705 - root_mean_squared_error: 21.4167 - val_loss: 442.3497 - val_root_mean_squared_error: 19.5586\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 479.2785 - root_mean_squared_error: 20.3973 - val_loss: 390.0230 - val_root_mean_squared_error: 18.5572\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 435.1508 - root_mean_squared_error: 19.7309 - val_loss: 406.1000 - val_root_mean_squared_error: 19.4682\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 400.8665 - root_mean_squared_error: 19.1451 - val_loss: 347.1284 - val_root_mean_squared_error: 17.8728\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 371.8977 - root_mean_squared_error: 18.5552 - val_loss: 333.9356 - val_root_mean_squared_error: 17.5892\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 360.2016 - root_mean_squared_error: 18.3249 - val_loss: 331.5534 - val_root_mean_squared_error: 17.5335\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 355.2196 - root_mean_squared_error: 18.2425 - val_loss: 327.5223 - val_root_mean_squared_error: 17.5063\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 352.3249 - root_mean_squared_error: 18.2355 - val_loss: 326.5508 - val_root_mean_squared_error: 17.5527\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 350.8770 - root_mean_squared_error: 18.2344 - val_loss: 325.5328 - val_root_mean_squared_error: 17.5444\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 349.1158 - root_mean_squared_error: 18.2232 - val_loss: 323.1730 - val_root_mean_squared_error: 17.5247\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 345.7863 - root_mean_squared_error: 18.1604 - val_loss: 322.1551 - val_root_mean_squared_error: 17.5218\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 346.7080 - root_mean_squared_error: 18.2154 - val_loss: 322.5305 - val_root_mean_squared_error: 17.5439\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 341.6938 - root_mean_squared_error: 18.1054 - val_loss: 321.3998 - val_root_mean_squared_error: 17.5677\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 341.9055 - root_mean_squared_error: 18.1375 - val_loss: 318.4147 - val_root_mean_squared_error: 17.4945\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 339.7571 - root_mean_squared_error: 18.0970 - val_loss: 318.7969 - val_root_mean_squared_error: 17.5329\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 340.0209 - root_mean_squared_error: 18.1247 - val_loss: 317.3719 - val_root_mean_squared_error: 17.5001\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 336.9560 - root_mean_squared_error: 18.0522 - val_loss: 317.2173 - val_root_mean_squared_error: 17.5008\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 337.8714 - root_mean_squared_error: 18.0905 - val_loss: 316.5986 - val_root_mean_squared_error: 17.4993\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 334.6670 - root_mean_squared_error: 18.0113 - val_loss: 316.6152 - val_root_mean_squared_error: 17.5096\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 335.2755 - root_mean_squared_error: 18.0360 - val_loss: 318.5119 - val_root_mean_squared_error: 17.5793\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 335.0258 - root_mean_squared_error: 18.0375 - val_loss: 318.4040 - val_root_mean_squared_error: 17.5823\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 333.8640 - root_mean_squared_error: 18.0142 - val_loss: 315.7138 - val_root_mean_squared_error: 17.5043\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 334.1313 - root_mean_squared_error: 18.0280 - val_loss: 315.6925 - val_root_mean_squared_error: 17.5074\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 332.1624 - root_mean_squared_error: 17.9779 - val_loss: 319.6039 - val_root_mean_squared_error: 17.6074\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 333.4023 - root_mean_squared_error: 18.0121 - val_loss: 317.5712 - val_root_mean_squared_error: 17.5759\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 331.3086 - root_mean_squared_error: 17.9618 - val_loss: 314.2776 - val_root_mean_squared_error: 17.4835\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 331.8075 - root_mean_squared_error: 17.9796 - val_loss: 314.8639 - val_root_mean_squared_error: 17.4925\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 330.9187 - root_mean_squared_error: 17.9587 - val_loss: 314.3548 - val_root_mean_squared_error: 17.5065\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 331.7622 - root_mean_squared_error: 17.9891 - val_loss: 315.0474 - val_root_mean_squared_error: 17.5186\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 330.4477 - root_mean_squared_error: 17.9559 - val_loss: 316.3909 - val_root_mean_squared_error: 17.5572\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 329.0939 - root_mean_squared_error: 17.9172 - val_loss: 313.5016 - val_root_mean_squared_error: 17.4839\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 329.4844 - root_mean_squared_error: 17.9335 - val_loss: 316.5280 - val_root_mean_squared_error: 17.5596\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 328.7550 - root_mean_squared_error: 17.9152 - val_loss: 315.7072 - val_root_mean_squared_error: 17.5465\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 329.4163 - root_mean_squared_error: 17.9356 - val_loss: 313.7814 - val_root_mean_squared_error: 17.4969\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 329.0045 - root_mean_squared_error: 17.9266 - val_loss: 315.3364 - val_root_mean_squared_error: 17.5446\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.7815 - root_mean_squared_error: 17.9005 - val_loss: 314.8011 - val_root_mean_squared_error: 17.5360\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 328.0470 - root_mean_squared_error: 17.9104 - val_loss: 314.0829 - val_root_mean_squared_error: 17.5133\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.2274 - root_mean_squared_error: 17.8913 - val_loss: 313.9599 - val_root_mean_squared_error: 17.5125\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.8117 - root_mean_squared_error: 17.9119 - val_loss: 312.8074 - val_root_mean_squared_error: 17.4936\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.4127 - root_mean_squared_error: 17.9031 - val_loss: 314.0208 - val_root_mean_squared_error: 17.5273\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.9304 - root_mean_squared_error: 17.8881 - val_loss: 313.8762 - val_root_mean_squared_error: 17.5052\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.1989 - root_mean_squared_error: 17.9000 - val_loss: 312.2722 - val_root_mean_squared_error: 17.4864\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 327.0719 - root_mean_squared_error: 17.9007 - val_loss: 311.9324 - val_root_mean_squared_error: 17.4815\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.2203 - root_mean_squared_error: 17.9088 - val_loss: 313.6040 - val_root_mean_squared_error: 17.5178\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.8771 - root_mean_squared_error: 17.8656 - val_loss: 314.1962 - val_root_mean_squared_error: 17.5406\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.6310 - root_mean_squared_error: 17.8895 - val_loss: 311.7196 - val_root_mean_squared_error: 17.4755\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.7965 - root_mean_squared_error: 17.8701 - val_loss: 313.8115 - val_root_mean_squared_error: 17.5293\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.2311 - root_mean_squared_error: 17.8774 - val_loss: 313.2934 - val_root_mean_squared_error: 17.5212\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.9976 - root_mean_squared_error: 17.8755 - val_loss: 313.0483 - val_root_mean_squared_error: 17.5171\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 326.4827 - root_mean_squared_error: 17.8956 - val_loss: 312.9629 - val_root_mean_squared_error: 17.5154\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.8982 - root_mean_squared_error: 17.8792 - val_loss: 314.4527 - val_root_mean_squared_error: 17.5581\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.8914 - root_mean_squared_error: 17.8791 - val_loss: 314.0335 - val_root_mean_squared_error: 17.5409\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.8253 - root_mean_squared_error: 17.8788 - val_loss: 311.9443 - val_root_mean_squared_error: 17.4904\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.3720 - root_mean_squared_error: 17.8651 - val_loss: 312.3853 - val_root_mean_squared_error: 17.4988\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.4741 - root_mean_squared_error: 17.8674 - val_loss: 311.5150 - val_root_mean_squared_error: 17.4794\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.3777 - root_mean_squared_error: 17.8721 - val_loss: 314.6681 - val_root_mean_squared_error: 17.5647\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.8489 - root_mean_squared_error: 17.8880 - val_loss: 313.7087 - val_root_mean_squared_error: 17.5453\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 325.4204 - root_mean_squared_error: 17.8749 - val_loss: 312.3475 - val_root_mean_squared_error: 17.5010\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 324.8134 - root_mean_squared_error: 17.8540 - val_loss: 312.9267 - val_root_mean_squared_error: 17.5172\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 14s 49ms/step - loss: 779.1670 - root_mean_squared_error: 24.3564 - val_loss: 669.5722 - val_root_mean_squared_error: 24.4691\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 555.0203 - root_mean_squared_error: 21.3834 - val_loss: 518.8839 - val_root_mean_squared_error: 19.9951\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 483.8044 - root_mean_squared_error: 20.4553 - val_loss: 401.5890 - val_root_mean_squared_error: 18.7145\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 420.8083 - root_mean_squared_error: 19.3920 - val_loss: 417.9620 - val_root_mean_squared_error: 19.7743\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 387.8256 - root_mean_squared_error: 18.8634 - val_loss: 363.6076 - val_root_mean_squared_error: 18.3662\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 363.7606 - root_mean_squared_error: 18.3710 - val_loss: 351.2849 - val_root_mean_squared_error: 17.9705\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 354.6241 - root_mean_squared_error: 18.2026 - val_loss: 345.5956 - val_root_mean_squared_error: 18.0052\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 350.4677 - root_mean_squared_error: 18.1624 - val_loss: 344.2747 - val_root_mean_squared_error: 18.0126\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 347.4782 - root_mean_squared_error: 18.1304 - val_loss: 342.6869 - val_root_mean_squared_error: 18.0331\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 345.4305 - root_mean_squared_error: 18.1095 - val_loss: 343.4160 - val_root_mean_squared_error: 18.0783\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 343.0851 - root_mean_squared_error: 18.0793 - val_loss: 341.9319 - val_root_mean_squared_error: 18.0856\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 340.9000 - root_mean_squared_error: 18.0566 - val_loss: 336.0438 - val_root_mean_squared_error: 17.9407\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 339.8539 - root_mean_squared_error: 18.0584 - val_loss: 336.8952 - val_root_mean_squared_error: 17.9913\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 338.5535 - root_mean_squared_error: 18.0444 - val_loss: 334.5417 - val_root_mean_squared_error: 17.9303\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 337.3163 - root_mean_squared_error: 18.0262 - val_loss: 337.1024 - val_root_mean_squared_error: 18.0395\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 334.4431 - root_mean_squared_error: 17.9660 - val_loss: 338.4660 - val_root_mean_squared_error: 18.0979\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 335.2375 - root_mean_squared_error: 18.0032 - val_loss: 333.0238 - val_root_mean_squared_error: 17.9480\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 331.6975 - root_mean_squared_error: 17.9152 - val_loss: 332.0773 - val_root_mean_squared_error: 17.9270\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 331.3234 - root_mean_squared_error: 17.9150 - val_loss: 335.3271 - val_root_mean_squared_error: 18.0412\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 332.7179 - root_mean_squared_error: 17.9659 - val_loss: 335.4730 - val_root_mean_squared_error: 18.0535\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 331.3775 - root_mean_squared_error: 17.9382 - val_loss: 331.7955 - val_root_mean_squared_error: 17.9565\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 328.9735 - root_mean_squared_error: 17.8807 - val_loss: 331.2491 - val_root_mean_squared_error: 17.9479\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 329.4141 - root_mean_squared_error: 17.8992 - val_loss: 331.0132 - val_root_mean_squared_error: 17.9468\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 329.3317 - root_mean_squared_error: 17.9025 - val_loss: 331.7271 - val_root_mean_squared_error: 17.9740\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 327.8223 - root_mean_squared_error: 17.8631 - val_loss: 333.3217 - val_root_mean_squared_error: 18.0212\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 328.1691 - root_mean_squared_error: 17.8794 - val_loss: 331.8387 - val_root_mean_squared_error: 17.9858\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 327.5139 - root_mean_squared_error: 17.8664 - val_loss: 330.6096 - val_root_mean_squared_error: 17.9526\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.9149 - root_mean_squared_error: 17.8526 - val_loss: 330.3220 - val_root_mean_squared_error: 17.9491\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.6677 - root_mean_squared_error: 17.8476 - val_loss: 332.0844 - val_root_mean_squared_error: 18.0007\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.6760 - root_mean_squared_error: 17.8544 - val_loss: 332.9254 - val_root_mean_squared_error: 18.0305\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.3793 - root_mean_squared_error: 17.8507 - val_loss: 334.7896 - val_root_mean_squared_error: 18.0791\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.4368 - root_mean_squared_error: 17.8510 - val_loss: 330.5297 - val_root_mean_squared_error: 17.9628\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.7535 - root_mean_squared_error: 17.8647 - val_loss: 328.9142 - val_root_mean_squared_error: 17.9249\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 325.5859 - root_mean_squared_error: 17.8371 - val_loss: 329.0125 - val_root_mean_squared_error: 17.9305\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.9898 - root_mean_squared_error: 17.8215 - val_loss: 330.5799 - val_root_mean_squared_error: 17.9693\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 325.7323 - root_mean_squared_error: 17.8429 - val_loss: 329.3385 - val_root_mean_squared_error: 17.9548\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 324.4768 - root_mean_squared_error: 17.8185 - val_loss: 328.6027 - val_root_mean_squared_error: 17.9294\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.4526 - root_mean_squared_error: 17.8147 - val_loss: 331.7625 - val_root_mean_squared_error: 18.0061\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.9047 - root_mean_squared_error: 17.8021 - val_loss: 329.9383 - val_root_mean_squared_error: 17.9708\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.4677 - root_mean_squared_error: 17.7900 - val_loss: 332.2555 - val_root_mean_squared_error: 18.0335\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.1392 - root_mean_squared_error: 17.8139 - val_loss: 327.7018 - val_root_mean_squared_error: 17.9185\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.3434 - root_mean_squared_error: 17.7945 - val_loss: 332.4862 - val_root_mean_squared_error: 17.9751\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.6364 - root_mean_squared_error: 17.8024 - val_loss: 328.2458 - val_root_mean_squared_error: 17.9435\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.6681 - root_mean_squared_error: 17.7803 - val_loss: 328.1893 - val_root_mean_squared_error: 17.9413\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.1502 - root_mean_squared_error: 17.7965 - val_loss: 332.9076 - val_root_mean_squared_error: 18.0512\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.8349 - root_mean_squared_error: 17.7903 - val_loss: 329.0460 - val_root_mean_squared_error: 17.9702\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.2008 - root_mean_squared_error: 17.8057 - val_loss: 328.8110 - val_root_mean_squared_error: 17.9636\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.9802 - root_mean_squared_error: 17.7747 - val_loss: 331.4514 - val_root_mean_squared_error: 18.0362\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.7041 - root_mean_squared_error: 17.7945 - val_loss: 330.1974 - val_root_mean_squared_error: 18.0067\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.5830 - root_mean_squared_error: 17.7943 - val_loss: 338.1771 - val_root_mean_squared_error: 18.2021\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.7848 - root_mean_squared_error: 17.8028 - val_loss: 328.6080 - val_root_mean_squared_error: 17.9656\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.7258 - root_mean_squared_error: 17.8011 - val_loss: 328.8813 - val_root_mean_squared_error: 17.9657\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.7606 - root_mean_squared_error: 17.8005 - val_loss: 328.5984 - val_root_mean_squared_error: 17.9740\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.9330 - root_mean_squared_error: 17.7829 - val_loss: 327.5414 - val_root_mean_squared_error: 17.9400\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.2621 - root_mean_squared_error: 17.7894 - val_loss: 329.4843 - val_root_mean_squared_error: 17.9878\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.1607 - root_mean_squared_error: 17.7896 - val_loss: 331.6012 - val_root_mean_squared_error: 18.0493\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.0066 - root_mean_squared_error: 17.7892 - val_loss: 338.2037 - val_root_mean_squared_error: 18.2190\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.4186 - root_mean_squared_error: 17.7702 - val_loss: 328.6109 - val_root_mean_squared_error: 17.9724\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.2275 - root_mean_squared_error: 17.7929 - val_loss: 327.4061 - val_root_mean_squared_error: 17.9437\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.6644 - root_mean_squared_error: 17.7778 - val_loss: 328.5295 - val_root_mean_squared_error: 17.9680\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 14s 49ms/step - loss: 754.7271 - root_mean_squared_error: 24.0656 - val_loss: 536.2481 - val_root_mean_squared_error: 20.2250\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 542.0701 - root_mean_squared_error: 21.1788 - val_loss: 454.5036 - val_root_mean_squared_error: 19.9650\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 477.9023 - root_mean_squared_error: 20.3428 - val_loss: 504.1045 - val_root_mean_squared_error: 21.7950\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 432.0120 - root_mean_squared_error: 19.6705 - val_loss: 396.6859 - val_root_mean_squared_error: 19.1788\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 393.1344 - root_mean_squared_error: 18.9713 - val_loss: 363.2978 - val_root_mean_squared_error: 18.4093\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 365.1566 - root_mean_squared_error: 18.4080 - val_loss: 348.2461 - val_root_mean_squared_error: 17.9838\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 353.3189 - root_mean_squared_error: 18.1647 - val_loss: 346.5858 - val_root_mean_squared_error: 17.9964\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 350.0810 - root_mean_squared_error: 18.1403 - val_loss: 342.6823 - val_root_mean_squared_error: 17.9615\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 348.8717 - root_mean_squared_error: 18.1672 - val_loss: 341.7464 - val_root_mean_squared_error: 17.9832\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 11s 48ms/step - loss: 346.2021 - root_mean_squared_error: 18.1338 - val_loss: 338.7830 - val_root_mean_squared_error: 17.9564\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 342.7336 - root_mean_squared_error: 18.0765 - val_loss: 337.4356 - val_root_mean_squared_error: 17.9448\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 339.8312 - root_mean_squared_error: 18.0250 - val_loss: 337.1069 - val_root_mean_squared_error: 17.9625\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 339.6278 - root_mean_squared_error: 18.0478 - val_loss: 335.7401 - val_root_mean_squared_error: 17.9547\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 337.6387 - root_mean_squared_error: 18.0107 - val_loss: 334.8464 - val_root_mean_squared_error: 17.9409\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 338.4001 - root_mean_squared_error: 18.0526 - val_loss: 334.6047 - val_root_mean_squared_error: 17.9619\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 11s 47ms/step - loss: 336.1115 - root_mean_squared_error: 18.0050 - val_loss: 336.1411 - val_root_mean_squared_error: 18.0052\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 334.7159 - root_mean_squared_error: 17.9828 - val_loss: 335.0833 - val_root_mean_squared_error: 17.9877\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 332.5225 - root_mean_squared_error: 17.9307 - val_loss: 335.1763 - val_root_mean_squared_error: 17.9943\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 333.5827 - root_mean_squared_error: 17.9708 - val_loss: 333.5663 - val_root_mean_squared_error: 17.9706\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 331.0636 - root_mean_squared_error: 17.9079 - val_loss: 335.1913 - val_root_mean_squared_error: 18.0446\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 330.7077 - root_mean_squared_error: 17.9072 - val_loss: 334.0206 - val_root_mean_squared_error: 17.9991\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 331.0359 - root_mean_squared_error: 17.9247 - val_loss: 330.9771 - val_root_mean_squared_error: 17.9324\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 330.2352 - root_mean_squared_error: 17.9107 - val_loss: 332.4272 - val_root_mean_squared_error: 17.9698\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 328.9500 - root_mean_squared_error: 17.8804 - val_loss: 334.4276 - val_root_mean_squared_error: 18.0277\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 329.0677 - root_mean_squared_error: 17.8906 - val_loss: 331.8297 - val_root_mean_squared_error: 17.9725\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 328.8152 - root_mean_squared_error: 17.8976 - val_loss: 329.2377 - val_root_mean_squared_error: 17.9044\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.8233 - root_mean_squared_error: 17.8459 - val_loss: 331.2321 - val_root_mean_squared_error: 17.9690\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.5031 - root_mean_squared_error: 17.8688 - val_loss: 329.6229 - val_root_mean_squared_error: 17.9301\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 327.3672 - root_mean_squared_error: 17.8669 - val_loss: 329.8157 - val_root_mean_squared_error: 17.9429\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.3174 - root_mean_squared_error: 17.8405 - val_loss: 329.5056 - val_root_mean_squared_error: 17.9337\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 326.7187 - root_mean_squared_error: 17.8567 - val_loss: 332.9084 - val_root_mean_squared_error: 18.0270\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 326.4321 - root_mean_squared_error: 17.8507 - val_loss: 328.9909 - val_root_mean_squared_error: 17.9330\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.7029 - root_mean_squared_error: 17.8347 - val_loss: 329.0813 - val_root_mean_squared_error: 17.9358\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 324.7085 - root_mean_squared_error: 17.8094 - val_loss: 333.7435 - val_root_mean_squared_error: 18.0596\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 325.4576 - root_mean_squared_error: 17.8334 - val_loss: 332.5453 - val_root_mean_squared_error: 18.0278\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 325.4309 - root_mean_squared_error: 17.8332 - val_loss: 329.8401 - val_root_mean_squared_error: 17.9608\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 324.2983 - root_mean_squared_error: 17.8084 - val_loss: 330.1978 - val_root_mean_squared_error: 17.9759\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 324.4298 - root_mean_squared_error: 17.8149 - val_loss: 330.4932 - val_root_mean_squared_error: 17.9799\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.6699 - root_mean_squared_error: 17.8005 - val_loss: 331.7594 - val_root_mean_squared_error: 18.0090\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 323.4204 - root_mean_squared_error: 17.7956 - val_loss: 328.8632 - val_root_mean_squared_error: 17.9500\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 323.8164 - root_mean_squared_error: 17.8080 - val_loss: 328.3591 - val_root_mean_squared_error: 17.9338\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.0988 - root_mean_squared_error: 17.7905 - val_loss: 328.2330 - val_root_mean_squared_error: 17.9401\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.4431 - root_mean_squared_error: 17.8024 - val_loss: 328.8564 - val_root_mean_squared_error: 17.9501\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 322.5976 - root_mean_squared_error: 17.7777 - val_loss: 329.4660 - val_root_mean_squared_error: 17.9702\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 323.2456 - root_mean_squared_error: 17.7964 - val_loss: 330.9085 - val_root_mean_squared_error: 18.0116\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.2234 - root_mean_squared_error: 17.7965 - val_loss: 331.5725 - val_root_mean_squared_error: 18.0176\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 322.4908 - root_mean_squared_error: 17.7782 - val_loss: 330.8668 - val_root_mean_squared_error: 18.0137\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 323.3651 - root_mean_squared_error: 17.8033 - val_loss: 327.4409 - val_root_mean_squared_error: 17.9145\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 322.4620 - root_mean_squared_error: 17.7803 - val_loss: 326.8745 - val_root_mean_squared_error: 17.9106\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 322.2608 - root_mean_squared_error: 17.7783 - val_loss: 330.2484 - val_root_mean_squared_error: 18.0006\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 322.2955 - root_mean_squared_error: 17.7786 - val_loss: 327.4287 - val_root_mean_squared_error: 17.9257\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 321.7054 - root_mean_squared_error: 17.7648 - val_loss: 327.3666 - val_root_mean_squared_error: 17.9275\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 322.4051 - root_mean_squared_error: 17.7868 - val_loss: 328.0067 - val_root_mean_squared_error: 17.9420\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.1606 - root_mean_squared_error: 17.7803 - val_loss: 329.4303 - val_root_mean_squared_error: 17.9739\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 321.8713 - root_mean_squared_error: 17.7726 - val_loss: 330.3625 - val_root_mean_squared_error: 18.0056\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.5262 - root_mean_squared_error: 17.7621 - val_loss: 327.6258 - val_root_mean_squared_error: 17.9385\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 320.6876 - root_mean_squared_error: 17.7373 - val_loss: 328.2618 - val_root_mean_squared_error: 17.9502\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 321.3783 - root_mean_squared_error: 17.7585 - val_loss: 327.5947 - val_root_mean_squared_error: 17.9369\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 321.4741 - root_mean_squared_error: 17.7633 - val_loss: 329.9321 - val_root_mean_squared_error: 17.9954\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.2819 - root_mean_squared_error: 17.7573 - val_loss: 331.9412 - val_root_mean_squared_error: 18.0288\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 24s 80ms/step - loss: 705.5399 - root_mean_squared_error: 23.3077 - val_loss: 524.2364 - val_root_mean_squared_error: 20.4341\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 538.3938 - root_mean_squared_error: 21.2122 - val_loss: 481.8380 - val_root_mean_squared_error: 20.4629\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 473.4796 - root_mean_squared_error: 20.3409 - val_loss: 443.8576 - val_root_mean_squared_error: 19.9715\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 424.3298 - root_mean_squared_error: 19.5060 - val_loss: 405.8258 - val_root_mean_squared_error: 19.3232\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 399.2742 - root_mean_squared_error: 19.1336 - val_loss: 383.6259 - val_root_mean_squared_error: 18.8883\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 366.5835 - root_mean_squared_error: 18.4382 - val_loss: 350.1021 - val_root_mean_squared_error: 18.0465\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 353.8505 - root_mean_squared_error: 18.1792 - val_loss: 347.2182 - val_root_mean_squared_error: 18.0209\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 351.5297 - root_mean_squared_error: 18.1732 - val_loss: 346.6531 - val_root_mean_squared_error: 18.0716\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 347.1685 - root_mean_squared_error: 18.0967 - val_loss: 359.9390 - val_root_mean_squared_error: 18.4471\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 345.0872 - root_mean_squared_error: 18.0719 - val_loss: 352.9685 - val_root_mean_squared_error: 18.3029\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 344.9018 - root_mean_squared_error: 18.1026 - val_loss: 343.2160 - val_root_mean_squared_error: 18.0843\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 341.4573 - root_mean_squared_error: 18.0385 - val_loss: 340.4554 - val_root_mean_squared_error: 18.0010\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 339.5661 - root_mean_squared_error: 18.0088 - val_loss: 339.4015 - val_root_mean_squared_error: 18.0158\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 336.6043 - root_mean_squared_error: 17.9506 - val_loss: 337.8463 - val_root_mean_squared_error: 17.9940\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 337.2206 - root_mean_squared_error: 17.9955 - val_loss: 337.0759 - val_root_mean_squared_error: 18.0034\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 335.1195 - root_mean_squared_error: 17.9634 - val_loss: 336.5694 - val_root_mean_squared_error: 18.0138\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 333.3951 - root_mean_squared_error: 17.9313 - val_loss: 336.1501 - val_root_mean_squared_error: 18.0214\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 332.2710 - root_mean_squared_error: 17.9209 - val_loss: 336.4686 - val_root_mean_squared_error: 18.0475\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 333.1420 - root_mean_squared_error: 17.9554 - val_loss: 335.0403 - val_root_mean_squared_error: 18.0023\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 330.9303 - root_mean_squared_error: 17.9019 - val_loss: 335.2639 - val_root_mean_squared_error: 18.0312\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 329.9600 - root_mean_squared_error: 17.8869 - val_loss: 333.9379 - val_root_mean_squared_error: 17.9974\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 328.8503 - root_mean_squared_error: 17.8639 - val_loss: 333.5100 - val_root_mean_squared_error: 17.9937\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 329.6438 - root_mean_squared_error: 17.8912 - val_loss: 335.0124 - val_root_mean_squared_error: 18.0460\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 12s 48ms/step - loss: 328.5102 - root_mean_squared_error: 17.8655 - val_loss: 333.6601 - val_root_mean_squared_error: 18.0132\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 327.5551 - root_mean_squared_error: 17.8437 - val_loss: 333.9032 - val_root_mean_squared_error: 18.0146\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.9288 - root_mean_squared_error: 17.8323 - val_loss: 332.9118 - val_root_mean_squared_error: 17.9999\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 327.5951 - root_mean_squared_error: 17.8570 - val_loss: 334.9645 - val_root_mean_squared_error: 18.0687\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 327.3051 - root_mean_squared_error: 17.8534 - val_loss: 333.0395 - val_root_mean_squared_error: 18.0105\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 325.7917 - root_mean_squared_error: 17.8192 - val_loss: 332.9032 - val_root_mean_squared_error: 18.0158\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 325.9793 - root_mean_squared_error: 17.8288 - val_loss: 346.0530 - val_root_mean_squared_error: 18.3278\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 326.0749 - root_mean_squared_error: 17.8347 - val_loss: 332.0036 - val_root_mean_squared_error: 18.0018\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.9421 - root_mean_squared_error: 17.8105 - val_loss: 331.9497 - val_root_mean_squared_error: 18.0004\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 324.8517 - root_mean_squared_error: 17.8144 - val_loss: 332.7608 - val_root_mean_squared_error: 18.0409\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 324.7524 - root_mean_squared_error: 17.8157 - val_loss: 333.6995 - val_root_mean_squared_error: 18.0729\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.6862 - root_mean_squared_error: 17.7887 - val_loss: 333.6520 - val_root_mean_squared_error: 18.0729\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.0455 - root_mean_squared_error: 17.8029 - val_loss: 331.1180 - val_root_mean_squared_error: 17.9986\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.5370 - root_mean_squared_error: 17.7901 - val_loss: 331.9947 - val_root_mean_squared_error: 18.0202\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 323.7621 - root_mean_squared_error: 17.7996 - val_loss: 331.9810 - val_root_mean_squared_error: 18.0246\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 324.1386 - root_mean_squared_error: 17.8095 - val_loss: 333.2424 - val_root_mean_squared_error: 18.0608\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 12s 49ms/step - loss: 323.6227 - root_mean_squared_error: 17.8020 - val_loss: 331.4237 - val_root_mean_squared_error: 18.0246\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 323.0265 - root_mean_squared_error: 17.7879 - val_loss: 332.7778 - val_root_mean_squared_error: 18.0658\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.9162 - root_mean_squared_error: 17.7889 - val_loss: 331.4386 - val_root_mean_squared_error: 18.0241\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 323.1969 - root_mean_squared_error: 17.7961 - val_loss: 338.0799 - val_root_mean_squared_error: 18.1482\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 322.6794 - root_mean_squared_error: 17.7819 - val_loss: 331.0909 - val_root_mean_squared_error: 18.0178\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 322.3495 - root_mean_squared_error: 17.7746 - val_loss: 329.8025 - val_root_mean_squared_error: 17.9885\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 322.3339 - root_mean_squared_error: 17.7770 - val_loss: 330.7332 - val_root_mean_squared_error: 18.0104\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 322.1628 - root_mean_squared_error: 17.7789 - val_loss: 330.5488 - val_root_mean_squared_error: 18.0142\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 322.2689 - root_mean_squared_error: 17.7843 - val_loss: 329.3976 - val_root_mean_squared_error: 17.9843\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.4034 - root_mean_squared_error: 17.7595 - val_loss: 329.4299 - val_root_mean_squared_error: 17.9854\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.2860 - root_mean_squared_error: 17.7580 - val_loss: 331.0338 - val_root_mean_squared_error: 18.0361\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.6876 - root_mean_squared_error: 17.7709 - val_loss: 329.7739 - val_root_mean_squared_error: 17.9958\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.6626 - root_mean_squared_error: 17.7716 - val_loss: 329.3525 - val_root_mean_squared_error: 17.9865\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.4747 - root_mean_squared_error: 17.7672 - val_loss: 329.7145 - val_root_mean_squared_error: 17.9981\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 320.5861 - root_mean_squared_error: 17.7389 - val_loss: 333.1097 - val_root_mean_squared_error: 18.0921\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 321.0831 - root_mean_squared_error: 17.7567 - val_loss: 339.0625 - val_root_mean_squared_error: 18.2076\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 321.0260 - root_mean_squared_error: 17.7547 - val_loss: 328.7899 - val_root_mean_squared_error: 17.9732\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 320.7000 - root_mean_squared_error: 17.7444 - val_loss: 329.6876 - val_root_mean_squared_error: 17.9963\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 320.2730 - root_mean_squared_error: 17.7339 - val_loss: 328.7065 - val_root_mean_squared_error: 17.9707\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 319.9232 - root_mean_squared_error: 17.7258 - val_loss: 330.3562 - val_root_mean_squared_error: 18.0158\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 320.6019 - root_mean_squared_error: 17.7433 - val_loss: 329.4282 - val_root_mean_squared_error: 17.9884\n",
            "Epoch 1/60\n",
            "241/241 [==============================] - 16s 55ms/step - loss: 719.5895 - root_mean_squared_error: 23.5431 - val_loss: 537.5997 - val_root_mean_squared_error: 21.4070\n",
            "Epoch 2/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 543.7041 - root_mean_squared_error: 21.4314 - val_loss: 450.5883 - val_root_mean_squared_error: 19.8682\n",
            "Epoch 3/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 480.7942 - root_mean_squared_error: 20.5113 - val_loss: 443.0836 - val_root_mean_squared_error: 19.6982\n",
            "Epoch 4/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 432.1200 - root_mean_squared_error: 19.7348 - val_loss: 381.9421 - val_root_mean_squared_error: 18.6800\n",
            "Epoch 5/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 388.9765 - root_mean_squared_error: 18.8822 - val_loss: 352.8671 - val_root_mean_squared_error: 18.0345\n",
            "Epoch 6/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 368.5370 - root_mean_squared_error: 18.4968 - val_loss: 346.8979 - val_root_mean_squared_error: 17.9334\n",
            "Epoch 7/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 355.2431 - root_mean_squared_error: 18.2259 - val_loss: 339.2878 - val_root_mean_squared_error: 17.8245\n",
            "Epoch 8/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 350.2071 - root_mean_squared_error: 18.1575 - val_loss: 337.2293 - val_root_mean_squared_error: 17.8416\n",
            "Epoch 9/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 347.2833 - root_mean_squared_error: 18.1357 - val_loss: 337.5100 - val_root_mean_squared_error: 17.8576\n",
            "Epoch 10/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 347.8178 - root_mean_squared_error: 18.1815 - val_loss: 335.0972 - val_root_mean_squared_error: 17.8623\n",
            "Epoch 11/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 344.6243 - root_mean_squared_error: 18.1288 - val_loss: 336.8549 - val_root_mean_squared_error: 17.9081\n",
            "Epoch 12/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 342.0005 - root_mean_squared_error: 18.0834 - val_loss: 334.5396 - val_root_mean_squared_error: 17.9081\n",
            "Epoch 13/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 341.1985 - root_mean_squared_error: 18.0830 - val_loss: 331.4896 - val_root_mean_squared_error: 17.8359\n",
            "Epoch 14/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 337.2425 - root_mean_squared_error: 17.9950 - val_loss: 330.5634 - val_root_mean_squared_error: 17.8226\n",
            "Epoch 15/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 335.3959 - root_mean_squared_error: 17.9696 - val_loss: 329.5135 - val_root_mean_squared_error: 17.8187\n",
            "Epoch 16/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 336.6101 - root_mean_squared_error: 18.0187 - val_loss: 329.7401 - val_root_mean_squared_error: 17.8354\n",
            "Epoch 17/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 333.2492 - root_mean_squared_error: 17.9432 - val_loss: 328.8183 - val_root_mean_squared_error: 17.8362\n",
            "Epoch 18/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 333.4083 - root_mean_squared_error: 17.9606 - val_loss: 328.4252 - val_root_mean_squared_error: 17.8300\n",
            "Epoch 19/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 333.1257 - root_mean_squared_error: 17.9619 - val_loss: 331.1283 - val_root_mean_squared_error: 17.9173\n",
            "Epoch 20/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 331.7695 - root_mean_squared_error: 17.9349 - val_loss: 328.2228 - val_root_mean_squared_error: 17.8388\n",
            "Epoch 21/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 330.9720 - root_mean_squared_error: 17.9230 - val_loss: 327.4005 - val_root_mean_squared_error: 17.8257\n",
            "Epoch 22/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 328.6646 - root_mean_squared_error: 17.8644 - val_loss: 338.2571 - val_root_mean_squared_error: 18.1524\n",
            "Epoch 23/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 330.1718 - root_mean_squared_error: 17.9139 - val_loss: 327.8299 - val_root_mean_squared_error: 17.8431\n",
            "Epoch 24/60\n",
            "241/241 [==============================] - 12s 52ms/step - loss: 330.1924 - root_mean_squared_error: 17.9179 - val_loss: 326.5309 - val_root_mean_squared_error: 17.8182\n",
            "Epoch 25/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 329.3141 - root_mean_squared_error: 17.9018 - val_loss: 327.4150 - val_root_mean_squared_error: 17.8474\n",
            "Epoch 26/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 329.7122 - root_mean_squared_error: 17.9175 - val_loss: 326.1798 - val_root_mean_squared_error: 17.8278\n",
            "Epoch 27/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 328.9806 - root_mean_squared_error: 17.9067 - val_loss: 327.0622 - val_root_mean_squared_error: 17.8471\n",
            "Epoch 28/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 328.5745 - root_mean_squared_error: 17.8978 - val_loss: 327.4339 - val_root_mean_squared_error: 17.8743\n",
            "Epoch 29/60\n",
            "241/241 [==============================] - 12s 50ms/step - loss: 328.0315 - root_mean_squared_error: 17.8863 - val_loss: 325.7809 - val_root_mean_squared_error: 17.8287\n",
            "Epoch 30/60\n",
            "241/241 [==============================] - 12s 52ms/step - loss: 328.1926 - root_mean_squared_error: 17.8957 - val_loss: 327.4998 - val_root_mean_squared_error: 17.8699\n",
            "Epoch 31/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 327.4064 - root_mean_squared_error: 17.8771 - val_loss: 327.0949 - val_root_mean_squared_error: 17.8633\n",
            "Epoch 32/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 327.5158 - root_mean_squared_error: 17.8831 - val_loss: 325.4435 - val_root_mean_squared_error: 17.8302\n",
            "Epoch 33/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 327.1573 - root_mean_squared_error: 17.8735 - val_loss: 325.0067 - val_root_mean_squared_error: 17.8217\n",
            "Epoch 34/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 326.0082 - root_mean_squared_error: 17.8485 - val_loss: 325.3694 - val_root_mean_squared_error: 17.8299\n",
            "Epoch 35/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 326.2533 - root_mean_squared_error: 17.8568 - val_loss: 326.9291 - val_root_mean_squared_error: 17.8565\n",
            "Epoch 36/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 325.5652 - root_mean_squared_error: 17.8373 - val_loss: 325.3888 - val_root_mean_squared_error: 17.8381\n",
            "Epoch 37/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 325.8375 - root_mean_squared_error: 17.8507 - val_loss: 324.3195 - val_root_mean_squared_error: 17.8065\n",
            "Epoch 38/60\n",
            "241/241 [==============================] - 13s 54ms/step - loss: 325.0476 - root_mean_squared_error: 17.8331 - val_loss: 324.7208 - val_root_mean_squared_error: 17.8180\n",
            "Epoch 39/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 324.8309 - root_mean_squared_error: 17.8293 - val_loss: 324.4629 - val_root_mean_squared_error: 17.8262\n",
            "Epoch 40/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 324.9369 - root_mean_squared_error: 17.8398 - val_loss: 326.7381 - val_root_mean_squared_error: 17.8557\n",
            "Epoch 41/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 325.0395 - root_mean_squared_error: 17.8383 - val_loss: 325.4419 - val_root_mean_squared_error: 17.8566\n",
            "Epoch 42/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 325.0337 - root_mean_squared_error: 17.8451 - val_loss: 324.1984 - val_root_mean_squared_error: 17.8300\n",
            "Epoch 43/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 324.7373 - root_mean_squared_error: 17.8407 - val_loss: 323.6837 - val_root_mean_squared_error: 17.8116\n",
            "Epoch 44/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 325.1107 - root_mean_squared_error: 17.8535 - val_loss: 323.2654 - val_root_mean_squared_error: 17.8062\n",
            "Epoch 45/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 324.3232 - root_mean_squared_error: 17.8353 - val_loss: 323.8635 - val_root_mean_squared_error: 17.8247\n",
            "Epoch 46/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 324.1908 - root_mean_squared_error: 17.8326 - val_loss: 323.5123 - val_root_mean_squared_error: 17.8146\n",
            "Epoch 47/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 323.9862 - root_mean_squared_error: 17.8295 - val_loss: 324.6042 - val_root_mean_squared_error: 17.8487\n",
            "Epoch 48/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.7596 - root_mean_squared_error: 17.8198 - val_loss: 322.8592 - val_root_mean_squared_error: 17.7936\n",
            "Epoch 49/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.6981 - root_mean_squared_error: 17.8156 - val_loss: 322.8546 - val_root_mean_squared_error: 17.7945\n",
            "Epoch 50/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.9425 - root_mean_squared_error: 17.8228 - val_loss: 324.0782 - val_root_mean_squared_error: 17.8223\n",
            "Epoch 51/60\n",
            "241/241 [==============================] - 12s 51ms/step - loss: 323.8877 - root_mean_squared_error: 17.8246 - val_loss: 323.1248 - val_root_mean_squared_error: 17.8043\n",
            "Epoch 52/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.4291 - root_mean_squared_error: 17.8139 - val_loss: 325.4676 - val_root_mean_squared_error: 17.8762\n",
            "Epoch 53/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 324.0490 - root_mean_squared_error: 17.8335 - val_loss: 323.4500 - val_root_mean_squared_error: 17.8080\n",
            "Epoch 54/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.7041 - root_mean_squared_error: 17.8232 - val_loss: 323.7232 - val_root_mean_squared_error: 17.8313\n",
            "Epoch 55/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 323.3160 - root_mean_squared_error: 17.8156 - val_loss: 323.4337 - val_root_mean_squared_error: 17.8211\n",
            "Epoch 56/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 323.0738 - root_mean_squared_error: 17.8106 - val_loss: 321.9662 - val_root_mean_squared_error: 17.7831\n",
            "Epoch 57/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 323.8593 - root_mean_squared_error: 17.8349 - val_loss: 323.2807 - val_root_mean_squared_error: 17.8225\n",
            "Epoch 58/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 323.7565 - root_mean_squared_error: 17.8339 - val_loss: 323.0009 - val_root_mean_squared_error: 17.8125\n",
            "Epoch 59/60\n",
            "241/241 [==============================] - 13s 53ms/step - loss: 322.3272 - root_mean_squared_error: 17.7947 - val_loss: 321.6414 - val_root_mean_squared_error: 17.7757\n",
            "Epoch 60/60\n",
            "241/241 [==============================] - 13s 52ms/step - loss: 322.6886 - root_mean_squared_error: 17.8037 - val_loss: 323.3876 - val_root_mean_squared_error: 17.8203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train MSE is 322.21002807617185\n",
            "The train RMSE is 17.787219619750978\n",
            "The validation MSE is 325.2426391601563\n",
            "The validation RMSE is 17.864534759521483\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold(num_folds, x_tabular, y, x_imgs, epochs=20, preprocess={}, augment={}):\n",
        "    \"\"\"\n",
        "    Train and evaluate the data for num-folds times, and return the average \n",
        "    training and validation loss. First the data is split in num-folds batches\n",
        "    and then the model is trained on the data, where a different batch is the \n",
        "    validation data each time.\n",
        "    \"\"\"\n",
        "    # Create kfold object to later split the data\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "    x_indices = np.array(range(len(x_tabular)))\n",
        "    y_indices = np.array(range(len(y)))\n",
        "\n",
        "    # Pre allocate variables to store the MSE (loss) and RMSE (accuracy)\n",
        "    train_loss = np.array(np.zeros(epochs))\n",
        "    train_acc = np.array(np.zeros(epochs))\n",
        "    val_loss = np.array(np.zeros(epochs))\n",
        "    val_acc = np.array(np.zeros(epochs))\n",
        "    \n",
        "    # Train and evaluate the model for num-fold times on a different training \n",
        "    # and validation set each time\n",
        "    for id_train, id_val in kfold.split(x_indices, y_indices):\n",
        "        \n",
        "        # Make Neural Networks before concatenation\n",
        "        tabular_NN = build_neural_net(12, hidden_nodes=20)\n",
        "        image_size = (64, 64, 3)\n",
        "        image_NN = build_convol_net(image_size, hidden_nodes=100)\n",
        "\n",
        "        # Create subset training and validation data\n",
        "        x_tabular_train = x_tabular[id_train]\n",
        "        x_imgs_train = x_imgs[id_train]\n",
        "        y_train = y[id_train]\n",
        "        \n",
        "        x_tabular_val = x_tabular[id_val]\n",
        "        x_imgs_val = x_imgs[id_val]\n",
        "        y_val_2 = y[id_val]\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        concat_model = concatenate_models(image_NN, tabular_NN, hidden_nodes=40)\n",
        "        history = train_and_evaluate(concat_model, x_imgs_train, x_tabular_train, \n",
        "                           y_train, x_tabular_val, x_imgs_val, y_val_2, epochs=epochs, preprocess=preprocess, augment=augment)\n",
        "\n",
        "        # Add all the losses and metrics\n",
        "        train_loss += history.history['loss']\n",
        "        train_acc += history.history['root_mean_squared_error']\n",
        "        val_loss += history.history['val_loss']\n",
        "        val_acc += history.history['val_root_mean_squared_error']\n",
        "\n",
        "    # Calculate average loss and metric\n",
        "    avg_train_loss = train_loss / num_folds\n",
        "    avg_val_loss = val_loss / num_folds\n",
        "    avg_train_acc = train_acc / num_folds\n",
        "    avg_val_acc = val_acc / num_folds\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    # Plot MSE\n",
        "    axs[0].plot(avg_train_loss)\n",
        "    axs[0].plot(avg_val_loss)\n",
        "    axs[0].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[0].set_title('Model MSE')\n",
        "    axs[0].set_ylabel('MSE')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "    axs[0].set_ylim([0, 1000])\n",
        "\n",
        "    # Plot RMSE\n",
        "    axs[1].plot(avg_train_acc)\n",
        "    axs[1].plot(avg_val_acc)\n",
        "    axs[1].legend(['training', 'validation'], loc='best')\n",
        "    \n",
        "    axs[1].set_title('Model RMSE')\n",
        "    axs[1].set_ylabel('RMSE')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    axs[1].set_ylim([0, 30])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return avg_train_loss[-1], avg_val_loss[-1], avg_train_acc[-1], avg_val_acc[-1]\n",
        "\n",
        "# Use k-fold cross-validation to train and evaluate concatenated network\n",
        "avg_train_loss, avg_val_loss, avg_train_acc, avg_val_acc = k_fold(5, x_tabular, y, x_images, epochs=60, \n",
        "                                               preprocess={'featurewise_center': True, 'featurewise_std_normalization': True},\n",
        "                                               augment={'rotation_range': 90, 'horizontal_flip': True, 'shear_range': 0.2})\n",
        "\n",
        "print(f'The train MSE is {avg_train_loss}')\n",
        "print(f'The train RMSE is {avg_train_acc}')\n",
        "print(f'The validation MSE is {avg_val_loss}')\n",
        "print(f'The validation RMSE is {avg_val_acc}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chapter_15_Extra layers&nodes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}